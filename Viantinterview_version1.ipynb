{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Viantinterview_version1.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNXE5MN+I+O3aBZXXgfw0LU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/afrojaakter/100-days-of-code/blob/master/Viantinterview_version1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vMX9ApGq8Ztn"
      },
      "source": [
        "### Model 1: One Hot **Encoding**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8i5QF8kSroQx"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F4yTZAUzrqlB",
        "outputId": "96573872-a479-4ed4-cd1c-f3c1c6d8902e"
      },
      "source": [
        "#Generating Data\n",
        "df_inputs = np.arange(2000)\n",
        "np.random.shuffle(df_inputs)\n",
        "\n",
        "def modular_fn(X):\n",
        "  ''' Takes input as integers and returns modular the input as: x % 500'''\n",
        "  return X % 500\n",
        "\n",
        "df_labels = modular_fn(df_inputs)\n",
        "print('Input data shapre {}, Output data shape {}'.format(df_inputs.shape, df_labels.shape))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shapre (2000,), Output data shape (2000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "UZGoznQ2rrYJ",
        "outputId": "5cdb1a79-6a2d-4936-83c7-451e60db05bf"
      },
      "source": [
        "plt.plot(np.arange(2000), modular_fn(np.arange(2000)),'.')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7fba315205d0>]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FBr7m_dNrwXZ",
        "outputId": "63d24ef3-3734-4f2e-ead8-a032323ae1bd"
      },
      "source": [
        "#some data population\n",
        "np.random.seed(42) # to prevent dataset not from changing in every run\n",
        "print('Input dataset {} \\nOutput dataset {}'.format(df_inputs, df_labels))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input dataset [1986  437 1033 ...  482  389  231] \n",
            "Output dataset [486 437  33 ... 482 389 231]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 240
        },
        "id": "kHROh6p3scb8",
        "outputId": "84358584-34fa-42bf-d0be-69b96324b9bd"
      },
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "ohe = OneHotEncoder()\n",
        "df_ohe_input = ohe.fit_transform(df_inputs.reshape(-1,1))\n",
        "df_labels = modular_fn(df_inputs.reshape(-1,1))\n",
        "\n",
        "df_ohe_labels = ohe.fit_transform(df_labels.reshape(-1,1))\n",
        "print(df_ohe_input.shape, df_ohe_labels.shape)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-f11952fe68c3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mohe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOneHotEncoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mdf_ohe_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mohe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_inputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mdf_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodular_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_inputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'df_inputs' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cWhFY77AtNyD",
        "outputId": "ed61c1aa-8809-4774-8ed9-092ef2e25852"
      },
      "source": [
        "#creating train and test dataset\n",
        "train_data_size = int(2000*0.7) # 70% is for training \n",
        "\n",
        "# training data\n",
        "train_inputs = df_ohe_input[:train_data_size]\n",
        "train_labels = df_labels[:train_data_size]\n",
        "\n",
        "# validation data\n",
        "valid_data_size = int(train_data_size*0.2)\n",
        "valid_inputs = train_inputs[:valid_data_size]\n",
        "valid_labels = train_labels[:valid_data_size]\n",
        "\n",
        "train_inputs = train_inputs[valid_data_size:]\n",
        "train_labels = train_labels[valid_data_size:]\n",
        "\n",
        "# test data\n",
        "test_inputs = df_ohe_input[train_data_size:]\n",
        "test_labels = df_labels[train_data_size:]\n",
        "\n",
        "print('Train data size {} \\nValidation data size {}\\ntest data size {}'\n",
        "      .format(train_inputs.shape, valid_inputs.shape, test_inputs.shape))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train data size (1120, 2000) \n",
            "Validation data size (280, 2000)\n",
            "test data size (600, 2000)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tdzvec9P1oAG",
        "outputId": "d8db965b-a483-49eb-e844-a1fc85c075b0"
      },
      "source": [
        "train_labels.shape, valid_labels.shape, test_labels.shape"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((1120, 1), (280, 1), (600, 1))"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UWHtjECisPLh",
        "outputId": "cb191502-ead2-4b65-c06b-d64f6bd5c635"
      },
      "source": [
        "model = keras.models.Sequential([\n",
        "            keras.layers.Dense(20, activation='relu', input_dim=2000),\n",
        "            keras.layers.Dense(20, activation='relu'),\n",
        "            keras.layers.Dense(500, activation='softmax')\n",
        "    ])\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(train_inputs, \n",
        "                    train_labels,\n",
        "                    epochs=50,\n",
        "                    batch_size=32,\n",
        "                    validation_data= (valid_inputs, valid_labels))\n",
        "                    \n"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:449: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_2/dense_6/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_2/dense_6/embedding_lookup_sparse/Reshape:0\", shape=(None, 20), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_2/dense_6/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "35/35 [==============================] - 1s 8ms/step - loss: 6.2170 - accuracy: 0.0027 - val_loss: 6.2186 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/50\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 6.2083 - accuracy: 0.0045 - val_loss: 6.2242 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/50\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 6.1970 - accuracy: 0.0054 - val_loss: 6.2386 - val_accuracy: 0.0000e+00\n",
            "Epoch 4/50\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 6.1727 - accuracy: 0.0071 - val_loss: 6.2774 - val_accuracy: 0.0000e+00\n",
            "Epoch 5/50\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 6.1320 - accuracy: 0.0080 - val_loss: 6.3496 - val_accuracy: 0.0000e+00\n",
            "Epoch 6/50\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 6.0848 - accuracy: 0.0071 - val_loss: 6.4489 - val_accuracy: 0.0000e+00\n",
            "Epoch 7/50\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 6.0343 - accuracy: 0.0054 - val_loss: 6.5100 - val_accuracy: 0.0000e+00\n",
            "Epoch 8/50\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 5.9838 - accuracy: 0.0036 - val_loss: 6.5740 - val_accuracy: 0.0000e+00\n",
            "Epoch 9/50\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 5.9235 - accuracy: 0.0063 - val_loss: 6.6098 - val_accuracy: 0.0000e+00\n",
            "Epoch 10/50\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 5.8569 - accuracy: 0.0098 - val_loss: 6.6679 - val_accuracy: 0.0000e+00\n",
            "Epoch 11/50\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 5.7789 - accuracy: 0.0134 - val_loss: 6.7379 - val_accuracy: 0.0000e+00\n",
            "Epoch 12/50\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 5.6923 - accuracy: 0.0188 - val_loss: 6.8144 - val_accuracy: 0.0000e+00\n",
            "Epoch 13/50\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 5.5952 - accuracy: 0.0312 - val_loss: 6.8934 - val_accuracy: 0.0000e+00\n",
            "Epoch 14/50\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 5.4890 - accuracy: 0.0455 - val_loss: 6.9853 - val_accuracy: 0.0000e+00\n",
            "Epoch 15/50\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 5.3730 - accuracy: 0.0562 - val_loss: 7.0802 - val_accuracy: 0.0000e+00\n",
            "Epoch 16/50\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 5.2451 - accuracy: 0.0920 - val_loss: 7.1772 - val_accuracy: 0.0000e+00\n",
            "Epoch 17/50\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 5.1068 - accuracy: 0.1089 - val_loss: 7.2727 - val_accuracy: 0.0000e+00\n",
            "Epoch 18/50\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 4.9584 - accuracy: 0.1241 - val_loss: 7.3570 - val_accuracy: 0.0000e+00\n",
            "Epoch 19/50\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 4.7980 - accuracy: 0.1464 - val_loss: 7.4586 - val_accuracy: 0.0000e+00\n",
            "Epoch 20/50\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 4.6265 - accuracy: 0.1750 - val_loss: 7.5650 - val_accuracy: 0.0000e+00\n",
            "Epoch 21/50\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 4.4464 - accuracy: 0.2152 - val_loss: 7.6292 - val_accuracy: 0.0000e+00\n",
            "Epoch 22/50\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 4.2542 - accuracy: 0.2473 - val_loss: 7.7283 - val_accuracy: 0.0000e+00\n",
            "Epoch 23/50\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 4.0576 - accuracy: 0.2946 - val_loss: 7.7991 - val_accuracy: 0.0000e+00\n",
            "Epoch 24/50\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 3.8585 - accuracy: 0.3464 - val_loss: 7.8532 - val_accuracy: 0.0000e+00\n",
            "Epoch 25/50\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 3.6518 - accuracy: 0.4027 - val_loss: 7.9773 - val_accuracy: 0.0000e+00\n",
            "Epoch 26/50\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 3.4473 - accuracy: 0.4429 - val_loss: 8.0443 - val_accuracy: 0.0000e+00\n",
            "Epoch 27/50\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 3.2400 - accuracy: 0.5080 - val_loss: 8.1125 - val_accuracy: 0.0000e+00\n",
            "Epoch 28/50\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 3.0366 - accuracy: 0.5714 - val_loss: 8.2085 - val_accuracy: 0.0000e+00\n",
            "Epoch 29/50\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 2.8384 - accuracy: 0.6420 - val_loss: 8.2912 - val_accuracy: 0.0000e+00\n",
            "Epoch 30/50\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 2.6430 - accuracy: 0.7036 - val_loss: 8.3647 - val_accuracy: 0.0000e+00\n",
            "Epoch 31/50\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 2.4482 - accuracy: 0.7563 - val_loss: 8.4969 - val_accuracy: 0.0000e+00\n",
            "Epoch 32/50\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 2.2646 - accuracy: 0.7902 - val_loss: 8.6080 - val_accuracy: 0.0000e+00\n",
            "Epoch 33/50\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 2.0840 - accuracy: 0.8116 - val_loss: 8.7446 - val_accuracy: 0.0000e+00\n",
            "Epoch 34/50\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 1.9169 - accuracy: 0.8500 - val_loss: 8.8746 - val_accuracy: 0.0000e+00\n",
            "Epoch 35/50\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 1.7529 - accuracy: 0.8536 - val_loss: 9.0761 - val_accuracy: 0.0000e+00\n",
            "Epoch 36/50\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 1.6051 - accuracy: 0.8920 - val_loss: 9.2027 - val_accuracy: 0.0000e+00\n",
            "Epoch 37/50\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 1.4519 - accuracy: 0.8911 - val_loss: 9.4226 - val_accuracy: 0.0000e+00\n",
            "Epoch 38/50\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 1.3226 - accuracy: 0.9170 - val_loss: 9.5511 - val_accuracy: 0.0000e+00\n",
            "Epoch 39/50\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 1.1985 - accuracy: 0.9366 - val_loss: 9.7423 - val_accuracy: 0.0036\n",
            "Epoch 40/50\n",
            "35/35 [==============================] - 0s 5ms/step - loss: 1.0885 - accuracy: 0.9402 - val_loss: 9.9380 - val_accuracy: 0.0000e+00\n",
            "Epoch 41/50\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.9802 - accuracy: 0.9536 - val_loss: 10.1777 - val_accuracy: 0.0000e+00\n",
            "Epoch 42/50\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.8890 - accuracy: 0.9670 - val_loss: 10.3399 - val_accuracy: 0.0000e+00\n",
            "Epoch 43/50\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.7993 - accuracy: 0.9732 - val_loss: 10.5370 - val_accuracy: 0.0036\n",
            "Epoch 44/50\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.7209 - accuracy: 0.9795 - val_loss: 10.7643 - val_accuracy: 0.0036\n",
            "Epoch 45/50\n",
            "35/35 [==============================] - 0s 5ms/step - loss: 0.6494 - accuracy: 0.9884 - val_loss: 10.9476 - val_accuracy: 0.0000e+00\n",
            "Epoch 46/50\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.5849 - accuracy: 0.9884 - val_loss: 11.1268 - val_accuracy: 0.0036\n",
            "Epoch 47/50\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.5276 - accuracy: 0.9955 - val_loss: 11.3682 - val_accuracy: 0.0036\n",
            "Epoch 48/50\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.4755 - accuracy: 0.9982 - val_loss: 11.5370 - val_accuracy: 0.0036\n",
            "Epoch 49/50\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.4283 - accuracy: 0.9982 - val_loss: 11.6849 - val_accuracy: 0.0036\n",
            "Epoch 50/50\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.3893 - accuracy: 0.9991 - val_loss: 11.8997 - val_accuracy: 0.0036\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        },
        "id": "u-gEUmXf4sS0",
        "outputId": "8dc0746f-52d2-4a1f-d97e-7f0f943231af"
      },
      "source": [
        "#plotting loss and accuracy\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = 50\n",
        "epochs_range = range(epochs)\n",
        "plt.figure(figsize=(8,5))\n",
        "plt.subplot(1,2,1)\n",
        "plt.plot(epochs_range, acc, label='train accuracy')\n",
        "plt.plot(epochs_range, val_acc, label='validatoin accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "plt.plot(epochs_range, loss, label='train loss')\n",
        "plt.plot(epochs_range, val_loss, label='validatoin loss')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('training and Validation Loss')"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'training and Validation Loss')"
            ]
          },
          "metadata": {},
          "execution_count": 23
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x360 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0m7pfHoW4M5C",
        "outputId": "b348cfc2-4af9-4619-8471-45e1d57263d5"
      },
      "source": [
        "# few true test_labels and predicted labels\n",
        "test_labels[:10].T, preds[:10]"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[ 48, 219,  46, 482, 211, 131, 383,   7, 255, 349]]),\n",
              " [268, 483, 483, 483, 483, 483, 483, 483, 483, 483])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8yoxsNIz5GVF"
      },
      "source": [
        "As we see the model performs poorly. The model memorize the train data but don't generalize on validation data at all. \n",
        "\n",
        "This is an underfittiing situation and this happens when we don't have eoungh data to train the model or we the number of features are more than the number of example in the training data, which is waht happening here. After applying one hot encodding to the data we have 1120 train exaples and 2000 features per example. Which is a clear indication that model might not learn all the patterns in the dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1jna3lKJ8dZe"
      },
      "source": [
        "### Model 2: COnverting input data to Bit-wise\n",
        "The input data has 11 features now and we are trying to develop a model to classifiy 500 different categories. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pXiuPbz2nmlf",
        "outputId": "49507ad9-710d-4eee-f8e2-0a9827003a7a"
      },
      "source": [
        "!pip install python_toolbox"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting python_toolbox\n",
            "  Downloading python_toolbox-1.0.11-py2.py3-none-any.whl (529 kB)\n",
            "\u001b[?25l\r\u001b[K     |                               | 10 kB 33.5 MB/s eta 0:00:01\r\u001b[K     |                              | 20 kB 41.7 MB/s eta 0:00:01\r\u001b[K     |                              | 30 kB 43.5 MB/s eta 0:00:01\r\u001b[K     |                             | 40 kB 25.4 MB/s eta 0:00:01\r\u001b[K     |                             | 51 kB 17.8 MB/s eta 0:00:01\r\u001b[K     |                            | 61 kB 18.8 MB/s eta 0:00:01\r\u001b[K     |                           | 71 kB 15.3 MB/s eta 0:00:01\r\u001b[K     |                           | 81 kB 17.0 MB/s eta 0:00:01\r\u001b[K     |                          | 92 kB 14.2 MB/s eta 0:00:01\r\u001b[K     |                         | 102 kB 14.6 MB/s eta 0:00:01\r\u001b[K     |                         | 112 kB 14.6 MB/s eta 0:00:01\r\u001b[K     |                        | 122 kB 14.6 MB/s eta 0:00:01\r\u001b[K     |                        | 133 kB 14.6 MB/s eta 0:00:01\r\u001b[K     |                       | 143 kB 14.6 MB/s eta 0:00:01\r\u001b[K     |                      | 153 kB 14.6 MB/s eta 0:00:01\r\u001b[K     |                      | 163 kB 14.6 MB/s eta 0:00:01\r\u001b[K     |                     | 174 kB 14.6 MB/s eta 0:00:01\r\u001b[K     |                    | 184 kB 14.6 MB/s eta 0:00:01\r\u001b[K     |                    | 194 kB 14.6 MB/s eta 0:00:01\r\u001b[K     |                   | 204 kB 14.6 MB/s eta 0:00:01\r\u001b[K     |                   | 215 kB 14.6 MB/s eta 0:00:01\r\u001b[K     |                  | 225 kB 14.6 MB/s eta 0:00:01\r\u001b[K     |                 | 235 kB 14.6 MB/s eta 0:00:01\r\u001b[K     |                 | 245 kB 14.6 MB/s eta 0:00:01\r\u001b[K     |                | 256 kB 14.6 MB/s eta 0:00:01\r\u001b[K     |                | 266 kB 14.6 MB/s eta 0:00:01\r\u001b[K     |               | 276 kB 14.6 MB/s eta 0:00:01\r\u001b[K     |              | 286 kB 14.6 MB/s eta 0:00:01\r\u001b[K     |              | 296 kB 14.6 MB/s eta 0:00:01\r\u001b[K     |             | 307 kB 14.6 MB/s eta 0:00:01\r\u001b[K     |            | 317 kB 14.6 MB/s eta 0:00:01\r\u001b[K     |            | 327 kB 14.6 MB/s eta 0:00:01\r\u001b[K     |           | 337 kB 14.6 MB/s eta 0:00:01\r\u001b[K     |           | 348 kB 14.6 MB/s eta 0:00:01\r\u001b[K     |          | 358 kB 14.6 MB/s eta 0:00:01\r\u001b[K     |         | 368 kB 14.6 MB/s eta 0:00:01\r\u001b[K     |         | 378 kB 14.6 MB/s eta 0:00:01\r\u001b[K     |        | 389 kB 14.6 MB/s eta 0:00:01\r\u001b[K     |       | 399 kB 14.6 MB/s eta 0:00:01\r\u001b[K     |       | 409 kB 14.6 MB/s eta 0:00:01\r\u001b[K     |      | 419 kB 14.6 MB/s eta 0:00:01\r\u001b[K     |      | 430 kB 14.6 MB/s eta 0:00:01\r\u001b[K     |     | 440 kB 14.6 MB/s eta 0:00:01\r\u001b[K     |    | 450 kB 14.6 MB/s eta 0:00:01\r\u001b[K     |    | 460 kB 14.6 MB/s eta 0:00:01\r\u001b[K     |   | 471 kB 14.6 MB/s eta 0:00:01\r\u001b[K     |   | 481 kB 14.6 MB/s eta 0:00:01\r\u001b[K     |  | 491 kB 14.6 MB/s eta 0:00:01\r\u001b[K     | | 501 kB 14.6 MB/s eta 0:00:01\r\u001b[K     | | 512 kB 14.6 MB/s eta 0:00:01\r\u001b[K     || 522 kB 14.6 MB/s eta 0:00:01\r\u001b[K     || 529 kB 14.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from python_toolbox) (57.4.0)\n",
            "Installing collected packages: python-toolbox\n",
            "Successfully installed python-toolbox-1.0.11\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p8bMWLRph9Au",
        "outputId": "a5ce457d-69d4-4186-fcb5-3e01e11ab6d5"
      },
      "source": [
        "np.arange(0,2 ** 11-48, 1)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([   0,    1,    2, ..., 1997, 1998, 1999])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "7kKB5_x6QqXd",
        "outputId": "1a39c2a5-a091-4393-9d8b-4f6f19be9294"
      },
      "source": [
        "from python_toolbox import random_tools\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "\n",
        "def modular_fn(X):\n",
        "  ''' Takes input as integers and returns modular the input as: x % 500'''\n",
        "  return X % 500\n",
        "\n",
        "data_population = random_tools.shuffled(range(2 ** 11-48)) #np.arange(0,2 ** 11-48, 1)\n",
        "data = []\n",
        "for d in data_population:\n",
        "  arr = []\n",
        "  for i in range(20, -1, -1):\n",
        "      arr.append((d & 1<<i)>>i)\n",
        "  data.append(np.array(arr))\n",
        "input_data = np.array(data)\n",
        "label_data = np.array(list(map(modular_fn, data_population)))\n",
        "\n",
        "ohe = OneHotEncoder()\n",
        "label_data = ohe.fit_transform(label_data.reshape(-1,1)).todense()\n",
        "#Splitting dataset into train, validation and test set\n",
        "# Train data is 70% to the total dataset and test data is 30% \n",
        "# validation data is 20% of the train data\n",
        "\n",
        "train_inputs = input_data[:1120,:]\n",
        "train_labels = label_data[:1120]\n",
        "\n",
        "valid_inputs = input_data[1120:1400,:]\n",
        "valid_labels = label_data[1120:1400]\n",
        "\n",
        "test_inputs = input_data[1400:,:]\n",
        "test_labels = label_data[1400:]\n",
        "print(train_inputs.shape, train_labels.shape,\n",
        "      valid_inputs.shape, valid_labels.shape, \n",
        "      test_inputs.shape, test_labels.shape)\n",
        "\n",
        "\n",
        "from tensorflow.keras import initializers\n",
        "from tensorflow.keras import regularizers\n",
        "initializer = tf.keras.initializers.RandomNormal(mean=0., stddev=1.)\n",
        "\n",
        "epochs = 250\n",
        "model = keras.models.Sequential([\n",
        "        keras.layers.Dense(128, activation='relu', input_dim=train_inputs.shape[1],\n",
        "                          kernel_initializer=initializers.RandomNormal(stddev=0.01),\n",
        "                          bias_initializer=initializers.Zeros(),\n",
        "                          kernel_regularizer=regularizers.l1_l2(l1=1e-5, l2=1e-4),\n",
        "                          bias_regularizer=regularizers.l2(1e-4),\n",
        "                          activity_regularizer=regularizers.l2(1e-5) ),\n",
        "        keras.layers.Dropout(0.3),\n",
        "        keras.layers.Dense(128, activation='relu'),\n",
        "        keras.layers.Dense(500, activation='softmax')\n",
        "])\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "my_callbacks = [tf.keras.callbacks.EarlyStopping(patience=2)]\n",
        "history = model.fit(train_inputs,train_labels, \n",
        "            epochs=epochs, \n",
        "            batch_size=50, \n",
        "            verbose = 1,\n",
        "            validation_data=(valid_inputs, valid_labels))\n",
        "\n",
        "preds = model.predict(test_inputs)\n",
        "\n",
        "#plotting loss and accuracy\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs_range = range(epochs)\n",
        "plt.figure(figsize=(8,5))\n",
        "plt.subplot(1,2,1)\n",
        "plt.plot(epochs_range, acc, label='train accuracy')\n",
        "plt.plot(epochs_range, val_acc, label='validatoin accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "plt.plot(epochs_range, loss, label='train loss')\n",
        "plt.plot(epochs_range, val_loss, label='validatoin loss')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('training and Validation Loss')\n"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1120, 21) (1120, 500) (280, 21) (280, 500) (600, 21) (600, 500)\n",
            "Epoch 1/250\n",
            "23/23 [==============================] - 1s 13ms/step - loss: 6.2173 - accuracy: 0.0018 - val_loss: 6.2195 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/250\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 6.2035 - accuracy: 0.0036 - val_loss: 6.2393 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/250\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 6.1668 - accuracy: 0.0045 - val_loss: 6.3565 - val_accuracy: 0.0000e+00\n",
            "Epoch 4/250\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 6.0846 - accuracy: 0.0054 - val_loss: 6.5105 - val_accuracy: 0.0000e+00\n",
            "Epoch 5/250\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 5.9724 - accuracy: 0.0134 - val_loss: 6.5521 - val_accuracy: 0.0000e+00\n",
            "Epoch 6/250\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 5.7863 - accuracy: 0.0188 - val_loss: 6.5673 - val_accuracy: 0.0000e+00\n",
            "Epoch 7/250\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 5.5167 - accuracy: 0.0446 - val_loss: 6.6169 - val_accuracy: 0.0000e+00\n",
            "Epoch 8/250\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 5.1797 - accuracy: 0.0491 - val_loss: 6.5709 - val_accuracy: 0.0071\n",
            "Epoch 9/250\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 4.7938 - accuracy: 0.0607 - val_loss: 6.5718 - val_accuracy: 0.0071\n",
            "Epoch 10/250\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 4.4476 - accuracy: 0.0634 - val_loss: 6.4871 - val_accuracy: 0.0107\n",
            "Epoch 11/250\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 4.1328 - accuracy: 0.0732 - val_loss: 6.4185 - val_accuracy: 0.0179\n",
            "Epoch 12/250\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 3.9093 - accuracy: 0.0723 - val_loss: 6.4365 - val_accuracy: 0.0107\n",
            "Epoch 13/250\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 3.7642 - accuracy: 0.0643 - val_loss: 6.4279 - val_accuracy: 0.0214\n",
            "Epoch 14/250\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 3.6274 - accuracy: 0.0661 - val_loss: 6.5119 - val_accuracy: 0.0179\n",
            "Epoch 15/250\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 3.5687 - accuracy: 0.0652 - val_loss: 6.5980 - val_accuracy: 0.0179\n",
            "Epoch 16/250\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 3.5113 - accuracy: 0.0812 - val_loss: 6.6432 - val_accuracy: 0.0107\n",
            "Epoch 17/250\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 3.4669 - accuracy: 0.0643 - val_loss: 6.6898 - val_accuracy: 0.0143\n",
            "Epoch 18/250\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 3.3966 - accuracy: 0.0839 - val_loss: 6.7567 - val_accuracy: 0.0286\n",
            "Epoch 19/250\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 3.3315 - accuracy: 0.0839 - val_loss: 6.8946 - val_accuracy: 0.0071\n",
            "Epoch 20/250\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 3.3107 - accuracy: 0.0866 - val_loss: 6.8824 - val_accuracy: 0.0071\n",
            "Epoch 21/250\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 3.2712 - accuracy: 0.0955 - val_loss: 7.0204 - val_accuracy: 0.0250\n",
            "Epoch 22/250\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 3.2244 - accuracy: 0.1000 - val_loss: 7.1168 - val_accuracy: 0.0107\n",
            "Epoch 23/250\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 3.1959 - accuracy: 0.1187 - val_loss: 7.1842 - val_accuracy: 0.0143\n",
            "Epoch 24/250\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 3.1629 - accuracy: 0.1161 - val_loss: 7.2041 - val_accuracy: 0.0071\n",
            "Epoch 25/250\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 3.1510 - accuracy: 0.1107 - val_loss: 7.2232 - val_accuracy: 0.0179\n",
            "Epoch 26/250\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 3.1070 - accuracy: 0.1107 - val_loss: 7.3336 - val_accuracy: 0.0107\n",
            "Epoch 27/250\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 3.0659 - accuracy: 0.1223 - val_loss: 7.4150 - val_accuracy: 0.0214\n",
            "Epoch 28/250\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 3.0296 - accuracy: 0.1295 - val_loss: 7.4993 - val_accuracy: 0.0000e+00\n",
            "Epoch 29/250\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 2.9994 - accuracy: 0.1429 - val_loss: 7.5896 - val_accuracy: 0.0179\n",
            "Epoch 30/250\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 3.0046 - accuracy: 0.1321 - val_loss: 7.5943 - val_accuracy: 0.0107\n",
            "Epoch 31/250\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 2.9674 - accuracy: 0.1384 - val_loss: 7.6582 - val_accuracy: 0.0107\n",
            "Epoch 32/250\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 2.9182 - accuracy: 0.1545 - val_loss: 7.8191 - val_accuracy: 0.0036\n",
            "Epoch 33/250\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 2.8797 - accuracy: 0.1616 - val_loss: 7.9443 - val_accuracy: 0.0143\n",
            "Epoch 34/250\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 2.8878 - accuracy: 0.1402 - val_loss: 7.9585 - val_accuracy: 0.0143\n",
            "Epoch 35/250\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 2.8478 - accuracy: 0.1580 - val_loss: 8.0178 - val_accuracy: 0.0143\n",
            "Epoch 36/250\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 2.7956 - accuracy: 0.1679 - val_loss: 8.1379 - val_accuracy: 0.0071\n",
            "Epoch 37/250\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 2.7975 - accuracy: 0.1714 - val_loss: 8.1626 - val_accuracy: 0.0143\n",
            "Epoch 38/250\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 2.7447 - accuracy: 0.1866 - val_loss: 8.2570 - val_accuracy: 0.0143\n",
            "Epoch 39/250\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 2.7336 - accuracy: 0.1714 - val_loss: 8.3868 - val_accuracy: 0.0107\n",
            "Epoch 40/250\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 2.7029 - accuracy: 0.1902 - val_loss: 8.5125 - val_accuracy: 0.0179\n",
            "Epoch 41/250\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 2.6221 - accuracy: 0.1955 - val_loss: 8.6490 - val_accuracy: 0.0071\n",
            "Epoch 42/250\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 2.6079 - accuracy: 0.2089 - val_loss: 8.7401 - val_accuracy: 0.0179\n",
            "Epoch 43/250\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 2.6256 - accuracy: 0.1902 - val_loss: 8.8277 - val_accuracy: 0.0107\n",
            "Epoch 44/250\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 2.5911 - accuracy: 0.2125 - val_loss: 8.8430 - val_accuracy: 0.0107\n",
            "Epoch 45/250\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 2.5411 - accuracy: 0.1955 - val_loss: 8.9714 - val_accuracy: 0.0107\n",
            "Epoch 46/250\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 2.5135 - accuracy: 0.2223 - val_loss: 9.0993 - val_accuracy: 0.0143\n",
            "Epoch 47/250\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 2.5023 - accuracy: 0.2143 - val_loss: 9.1598 - val_accuracy: 0.0143\n",
            "Epoch 48/250\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 2.4434 - accuracy: 0.2188 - val_loss: 9.2647 - val_accuracy: 0.0036\n",
            "Epoch 49/250\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 2.4520 - accuracy: 0.2509 - val_loss: 9.3329 - val_accuracy: 0.0107\n",
            "Epoch 50/250\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 2.3974 - accuracy: 0.2411 - val_loss: 9.4523 - val_accuracy: 0.0179\n",
            "Epoch 51/250\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 2.3869 - accuracy: 0.2473 - val_loss: 9.5404 - val_accuracy: 0.0143\n",
            "Epoch 52/250\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 2.3228 - accuracy: 0.2429 - val_loss: 9.6663 - val_accuracy: 0.0107\n",
            "Epoch 53/250\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 2.2944 - accuracy: 0.2509 - val_loss: 9.7830 - val_accuracy: 0.0179\n",
            "Epoch 54/250\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 2.2904 - accuracy: 0.2464 - val_loss: 9.8883 - val_accuracy: 0.0071\n",
            "Epoch 55/250\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 2.2557 - accuracy: 0.2616 - val_loss: 9.9619 - val_accuracy: 0.0214\n",
            "Epoch 56/250\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 2.2222 - accuracy: 0.2580 - val_loss: 10.1083 - val_accuracy: 0.0107\n",
            "Epoch 57/250\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 2.1804 - accuracy: 0.2893 - val_loss: 10.2466 - val_accuracy: 0.0143\n",
            "Epoch 58/250\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 2.1767 - accuracy: 0.2830 - val_loss: 10.3030 - val_accuracy: 0.0143\n",
            "Epoch 59/250\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 2.1088 - accuracy: 0.3054 - val_loss: 10.5029 - val_accuracy: 0.0250\n",
            "Epoch 60/250\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 2.1014 - accuracy: 0.2920 - val_loss: 10.6103 - val_accuracy: 0.0143\n",
            "Epoch 61/250\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 2.0688 - accuracy: 0.3205 - val_loss: 10.6514 - val_accuracy: 0.0143\n",
            "Epoch 62/250\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 2.0487 - accuracy: 0.3071 - val_loss: 10.7718 - val_accuracy: 0.0179\n",
            "Epoch 63/250\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 2.0231 - accuracy: 0.3384 - val_loss: 10.8515 - val_accuracy: 0.0071\n",
            "Epoch 64/250\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.9881 - accuracy: 0.3375 - val_loss: 11.0028 - val_accuracy: 0.0071\n",
            "Epoch 65/250\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.9718 - accuracy: 0.3179 - val_loss: 11.0850 - val_accuracy: 0.0107\n",
            "Epoch 66/250\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.9501 - accuracy: 0.3420 - val_loss: 11.1762 - val_accuracy: 0.0107\n",
            "Epoch 67/250\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.8941 - accuracy: 0.3536 - val_loss: 11.3539 - val_accuracy: 0.0107\n",
            "Epoch 68/250\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.8843 - accuracy: 0.3562 - val_loss: 11.5446 - val_accuracy: 0.0107\n",
            "Epoch 69/250\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 1.8476 - accuracy: 0.3857 - val_loss: 11.6958 - val_accuracy: 0.0071\n",
            "Epoch 70/250\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.8424 - accuracy: 0.3804 - val_loss: 11.7625 - val_accuracy: 0.0107\n",
            "Epoch 71/250\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.8320 - accuracy: 0.3795 - val_loss: 11.8916 - val_accuracy: 0.0036\n",
            "Epoch 72/250\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.7791 - accuracy: 0.4036 - val_loss: 12.0253 - val_accuracy: 0.0179\n",
            "Epoch 73/250\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.7534 - accuracy: 0.4107 - val_loss: 12.0971 - val_accuracy: 0.0143\n",
            "Epoch 74/250\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 1.7241 - accuracy: 0.4116 - val_loss: 12.2973 - val_accuracy: 0.0143\n",
            "Epoch 75/250\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 1.7187 - accuracy: 0.4089 - val_loss: 12.3763 - val_accuracy: 0.0143\n",
            "Epoch 76/250\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 1.6864 - accuracy: 0.4259 - val_loss: 12.5037 - val_accuracy: 0.0179\n",
            "Epoch 77/250\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.6657 - accuracy: 0.4313 - val_loss: 12.5543 - val_accuracy: 0.0143\n",
            "Epoch 78/250\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 1.6115 - accuracy: 0.4696 - val_loss: 12.7585 - val_accuracy: 0.0214\n",
            "Epoch 79/250\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.6310 - accuracy: 0.4286 - val_loss: 12.8395 - val_accuracy: 0.0143\n",
            "Epoch 80/250\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.5729 - accuracy: 0.4714 - val_loss: 12.9681 - val_accuracy: 0.0143\n",
            "Epoch 81/250\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.5709 - accuracy: 0.4741 - val_loss: 13.0889 - val_accuracy: 0.0071\n",
            "Epoch 82/250\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.5261 - accuracy: 0.4866 - val_loss: 13.1950 - val_accuracy: 0.0143\n",
            "Epoch 83/250\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 1.5207 - accuracy: 0.4866 - val_loss: 13.3233 - val_accuracy: 0.0071\n",
            "Epoch 84/250\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 1.5189 - accuracy: 0.4812 - val_loss: 13.4916 - val_accuracy: 0.0036\n",
            "Epoch 85/250\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 1.4761 - accuracy: 0.4991 - val_loss: 13.5672 - val_accuracy: 0.0107\n",
            "Epoch 86/250\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.4468 - accuracy: 0.5125 - val_loss: 13.6907 - val_accuracy: 0.0107\n",
            "Epoch 87/250\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 1.4023 - accuracy: 0.5259 - val_loss: 13.8640 - val_accuracy: 0.0071\n",
            "Epoch 88/250\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.4169 - accuracy: 0.5134 - val_loss: 13.9705 - val_accuracy: 0.0107\n",
            "Epoch 89/250\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.3891 - accuracy: 0.5188 - val_loss: 14.0046 - val_accuracy: 0.0143\n",
            "Epoch 90/250\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.3640 - accuracy: 0.5366 - val_loss: 14.1025 - val_accuracy: 0.0071\n",
            "Epoch 91/250\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 1.3277 - accuracy: 0.5813 - val_loss: 14.3113 - val_accuracy: 0.0107\n",
            "Epoch 92/250\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.3140 - accuracy: 0.5509 - val_loss: 14.4211 - val_accuracy: 0.0036\n",
            "Epoch 93/250\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.3144 - accuracy: 0.5750 - val_loss: 14.6106 - val_accuracy: 0.0071\n",
            "Epoch 94/250\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.2518 - accuracy: 0.5705 - val_loss: 14.6620 - val_accuracy: 0.0071\n",
            "Epoch 95/250\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.2354 - accuracy: 0.5768 - val_loss: 14.8669 - val_accuracy: 0.0107\n",
            "Epoch 96/250\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 1.2210 - accuracy: 0.5768 - val_loss: 14.9666 - val_accuracy: 0.0071\n",
            "Epoch 97/250\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 1.2128 - accuracy: 0.5929 - val_loss: 14.9955 - val_accuracy: 0.0071\n",
            "Epoch 98/250\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.1725 - accuracy: 0.6214 - val_loss: 15.2385 - val_accuracy: 0.0071\n",
            "Epoch 99/250\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.1410 - accuracy: 0.6205 - val_loss: 15.4243 - val_accuracy: 0.0036\n",
            "Epoch 100/250\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 1.1405 - accuracy: 0.6304 - val_loss: 15.5572 - val_accuracy: 0.0071\n",
            "Epoch 101/250\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.1556 - accuracy: 0.6348 - val_loss: 15.6982 - val_accuracy: 0.0143\n",
            "Epoch 102/250\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.1062 - accuracy: 0.6518 - val_loss: 15.7696 - val_accuracy: 0.0036\n",
            "Epoch 103/250\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.0844 - accuracy: 0.6509 - val_loss: 15.9112 - val_accuracy: 0.0107\n",
            "Epoch 104/250\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.0411 - accuracy: 0.6482 - val_loss: 16.0381 - val_accuracy: 0.0071\n",
            "Epoch 105/250\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.0603 - accuracy: 0.6670 - val_loss: 16.1923 - val_accuracy: 0.0143\n",
            "Epoch 106/250\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 1.0207 - accuracy: 0.6812 - val_loss: 16.2840 - val_accuracy: 0.0143\n",
            "Epoch 107/250\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.9864 - accuracy: 0.6929 - val_loss: 16.4279 - val_accuracy: 0.0179\n",
            "Epoch 108/250\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.0195 - accuracy: 0.6732 - val_loss: 16.4590 - val_accuracy: 0.0071\n",
            "Epoch 109/250\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.9793 - accuracy: 0.6848 - val_loss: 16.6454 - val_accuracy: 0.0179\n",
            "Epoch 110/250\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.9518 - accuracy: 0.6902 - val_loss: 16.8087 - val_accuracy: 0.0107\n",
            "Epoch 111/250\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.9392 - accuracy: 0.6920 - val_loss: 16.8679 - val_accuracy: 0.0107\n",
            "Epoch 112/250\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.9420 - accuracy: 0.7063 - val_loss: 17.0061 - val_accuracy: 0.0107\n",
            "Epoch 113/250\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.8978 - accuracy: 0.7188 - val_loss: 16.9970 - val_accuracy: 0.0179\n",
            "Epoch 114/250\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.8888 - accuracy: 0.7188 - val_loss: 17.2320 - val_accuracy: 0.0107\n",
            "Epoch 115/250\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 0.8571 - accuracy: 0.7464 - val_loss: 17.3351 - val_accuracy: 0.0107\n",
            "Epoch 116/250\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.8212 - accuracy: 0.7500 - val_loss: 17.5072 - val_accuracy: 0.0107\n",
            "Epoch 117/250\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7963 - accuracy: 0.7777 - val_loss: 17.5727 - val_accuracy: 0.0107\n",
            "Epoch 118/250\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.7743 - accuracy: 0.7714 - val_loss: 17.7620 - val_accuracy: 0.0107\n",
            "Epoch 119/250\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.7580 - accuracy: 0.7812 - val_loss: 17.9444 - val_accuracy: 0.0179\n",
            "Epoch 120/250\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.7422 - accuracy: 0.7893 - val_loss: 18.0798 - val_accuracy: 0.0179\n",
            "Epoch 121/250\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.7426 - accuracy: 0.7955 - val_loss: 18.1410 - val_accuracy: 0.0143\n",
            "Epoch 122/250\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.7548 - accuracy: 0.7643 - val_loss: 18.2376 - val_accuracy: 0.0107\n",
            "Epoch 123/250\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7291 - accuracy: 0.7973 - val_loss: 18.3467 - val_accuracy: 0.0214\n",
            "Epoch 124/250\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.7037 - accuracy: 0.7884 - val_loss: 18.4954 - val_accuracy: 0.0107\n",
            "Epoch 125/250\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.7294 - accuracy: 0.7884 - val_loss: 18.6705 - val_accuracy: 0.0071\n",
            "Epoch 126/250\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.6592 - accuracy: 0.8179 - val_loss: 18.8001 - val_accuracy: 0.0107\n",
            "Epoch 127/250\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.6869 - accuracy: 0.7937 - val_loss: 18.7548 - val_accuracy: 0.0179\n",
            "Epoch 128/250\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.6546 - accuracy: 0.8071 - val_loss: 18.8277 - val_accuracy: 0.0179\n",
            "Epoch 129/250\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.6249 - accuracy: 0.8250 - val_loss: 19.0903 - val_accuracy: 0.0143\n",
            "Epoch 130/250\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.6344 - accuracy: 0.8161 - val_loss: 19.2408 - val_accuracy: 0.0107\n",
            "Epoch 131/250\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.6004 - accuracy: 0.8268 - val_loss: 19.3222 - val_accuracy: 0.0179\n",
            "Epoch 132/250\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.6161 - accuracy: 0.8277 - val_loss: 19.4921 - val_accuracy: 0.0143\n",
            "Epoch 133/250\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.5788 - accuracy: 0.8571 - val_loss: 19.6055 - val_accuracy: 0.0214\n",
            "Epoch 134/250\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.5778 - accuracy: 0.8455 - val_loss: 19.7305 - val_accuracy: 0.0179\n",
            "Epoch 135/250\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.5707 - accuracy: 0.8527 - val_loss: 19.7509 - val_accuracy: 0.0179\n",
            "Epoch 136/250\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.5708 - accuracy: 0.8536 - val_loss: 19.8195 - val_accuracy: 0.0179\n",
            "Epoch 137/250\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.5813 - accuracy: 0.8357 - val_loss: 19.9343 - val_accuracy: 0.0107\n",
            "Epoch 138/250\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.5310 - accuracy: 0.8714 - val_loss: 19.9629 - val_accuracy: 0.0179\n",
            "Epoch 139/250\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.5585 - accuracy: 0.8527 - val_loss: 20.0506 - val_accuracy: 0.0179\n",
            "Epoch 140/250\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.5313 - accuracy: 0.8527 - val_loss: 20.2071 - val_accuracy: 0.0250\n",
            "Epoch 141/250\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.4924 - accuracy: 0.8607 - val_loss: 20.3599 - val_accuracy: 0.0179\n",
            "Epoch 142/250\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.5162 - accuracy: 0.8616 - val_loss: 20.4559 - val_accuracy: 0.0107\n",
            "Epoch 143/250\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.4942 - accuracy: 0.8839 - val_loss: 20.5162 - val_accuracy: 0.0179\n",
            "Epoch 144/250\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.4790 - accuracy: 0.8705 - val_loss: 20.6764 - val_accuracy: 0.0179\n",
            "Epoch 145/250\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.4730 - accuracy: 0.8795 - val_loss: 20.7355 - val_accuracy: 0.0143\n",
            "Epoch 146/250\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.4671 - accuracy: 0.8768 - val_loss: 20.8945 - val_accuracy: 0.0214\n",
            "Epoch 147/250\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.4515 - accuracy: 0.8920 - val_loss: 21.0264 - val_accuracy: 0.0179\n",
            "Epoch 148/250\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.4578 - accuracy: 0.8911 - val_loss: 21.0169 - val_accuracy: 0.0143\n",
            "Epoch 149/250\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.4488 - accuracy: 0.8902 - val_loss: 21.0650 - val_accuracy: 0.0250\n",
            "Epoch 150/250\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.4445 - accuracy: 0.8884 - val_loss: 21.1034 - val_accuracy: 0.0107\n",
            "Epoch 151/250\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.4253 - accuracy: 0.8955 - val_loss: 21.1630 - val_accuracy: 0.0250\n",
            "Epoch 152/250\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.4279 - accuracy: 0.8929 - val_loss: 21.3814 - val_accuracy: 0.0250\n",
            "Epoch 153/250\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 0.4272 - accuracy: 0.8920 - val_loss: 21.4362 - val_accuracy: 0.0143\n",
            "Epoch 154/250\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.4092 - accuracy: 0.8938 - val_loss: 21.5201 - val_accuracy: 0.0214\n",
            "Epoch 155/250\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.4130 - accuracy: 0.8973 - val_loss: 21.6726 - val_accuracy: 0.0286\n",
            "Epoch 156/250\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.4048 - accuracy: 0.8938 - val_loss: 21.7169 - val_accuracy: 0.0214\n",
            "Epoch 157/250\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.4030 - accuracy: 0.9045 - val_loss: 21.6951 - val_accuracy: 0.0286\n",
            "Epoch 158/250\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.3910 - accuracy: 0.9018 - val_loss: 21.7385 - val_accuracy: 0.0250\n",
            "Epoch 159/250\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.3753 - accuracy: 0.9071 - val_loss: 21.8289 - val_accuracy: 0.0321\n",
            "Epoch 160/250\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.3753 - accuracy: 0.9161 - val_loss: 21.9008 - val_accuracy: 0.0321\n",
            "Epoch 161/250\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.4066 - accuracy: 0.8911 - val_loss: 21.9148 - val_accuracy: 0.0250\n",
            "Epoch 162/250\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.3644 - accuracy: 0.9170 - val_loss: 22.0831 - val_accuracy: 0.0214\n",
            "Epoch 163/250\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.3529 - accuracy: 0.9116 - val_loss: 22.0635 - val_accuracy: 0.0286\n",
            "Epoch 164/250\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.3649 - accuracy: 0.9116 - val_loss: 22.2056 - val_accuracy: 0.0214\n",
            "Epoch 165/250\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 0.3478 - accuracy: 0.9170 - val_loss: 22.2895 - val_accuracy: 0.0214\n",
            "Epoch 166/250\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.3478 - accuracy: 0.9250 - val_loss: 22.4710 - val_accuracy: 0.0321\n",
            "Epoch 167/250\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.3414 - accuracy: 0.9232 - val_loss: 22.4957 - val_accuracy: 0.0250\n",
            "Epoch 168/250\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.3532 - accuracy: 0.9089 - val_loss: 22.5096 - val_accuracy: 0.0250\n",
            "Epoch 169/250\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.3148 - accuracy: 0.9286 - val_loss: 22.5838 - val_accuracy: 0.0321\n",
            "Epoch 170/250\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.3220 - accuracy: 0.9259 - val_loss: 22.6213 - val_accuracy: 0.0393\n",
            "Epoch 171/250\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.3279 - accuracy: 0.9205 - val_loss: 22.7680 - val_accuracy: 0.0250\n",
            "Epoch 172/250\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.3364 - accuracy: 0.9161 - val_loss: 22.7394 - val_accuracy: 0.0214\n",
            "Epoch 173/250\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.3273 - accuracy: 0.9232 - val_loss: 22.8063 - val_accuracy: 0.0286\n",
            "Epoch 174/250\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.2875 - accuracy: 0.9321 - val_loss: 22.8067 - val_accuracy: 0.0286\n",
            "Epoch 175/250\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.3172 - accuracy: 0.9232 - val_loss: 22.8510 - val_accuracy: 0.0286\n",
            "Epoch 176/250\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.2789 - accuracy: 0.9420 - val_loss: 23.0279 - val_accuracy: 0.0250\n",
            "Epoch 177/250\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.2951 - accuracy: 0.9330 - val_loss: 23.0576 - val_accuracy: 0.0321\n",
            "Epoch 178/250\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.2981 - accuracy: 0.9277 - val_loss: 23.2370 - val_accuracy: 0.0286\n",
            "Epoch 179/250\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.2794 - accuracy: 0.9339 - val_loss: 23.3094 - val_accuracy: 0.0250\n",
            "Epoch 180/250\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.2755 - accuracy: 0.9411 - val_loss: 23.3417 - val_accuracy: 0.0321\n",
            "Epoch 181/250\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2961 - accuracy: 0.9286 - val_loss: 23.4237 - val_accuracy: 0.0250\n",
            "Epoch 182/250\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2607 - accuracy: 0.9411 - val_loss: 23.4131 - val_accuracy: 0.0286\n",
            "Epoch 183/250\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.2857 - accuracy: 0.9375 - val_loss: 23.4340 - val_accuracy: 0.0321\n",
            "Epoch 184/250\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.2778 - accuracy: 0.9348 - val_loss: 23.5801 - val_accuracy: 0.0321\n",
            "Epoch 185/250\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.3114 - accuracy: 0.9196 - val_loss: 23.5291 - val_accuracy: 0.0429\n",
            "Epoch 186/250\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.2612 - accuracy: 0.9339 - val_loss: 23.5846 - val_accuracy: 0.0286\n",
            "Epoch 187/250\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2746 - accuracy: 0.9321 - val_loss: 23.6200 - val_accuracy: 0.0357\n",
            "Epoch 188/250\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2785 - accuracy: 0.9357 - val_loss: 23.6086 - val_accuracy: 0.0357\n",
            "Epoch 189/250\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.2528 - accuracy: 0.9375 - val_loss: 23.6829 - val_accuracy: 0.0357\n",
            "Epoch 190/250\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.2610 - accuracy: 0.9375 - val_loss: 23.6993 - val_accuracy: 0.0357\n",
            "Epoch 191/250\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.2574 - accuracy: 0.9393 - val_loss: 23.8306 - val_accuracy: 0.0321\n",
            "Epoch 192/250\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.2559 - accuracy: 0.9464 - val_loss: 24.0291 - val_accuracy: 0.0357\n",
            "Epoch 193/250\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.2634 - accuracy: 0.9312 - val_loss: 24.1197 - val_accuracy: 0.0464\n",
            "Epoch 194/250\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.2375 - accuracy: 0.9464 - val_loss: 24.2738 - val_accuracy: 0.0250\n",
            "Epoch 195/250\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.2394 - accuracy: 0.9446 - val_loss: 24.1967 - val_accuracy: 0.0321\n",
            "Epoch 196/250\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2616 - accuracy: 0.9295 - val_loss: 24.2256 - val_accuracy: 0.0321\n",
            "Epoch 197/250\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.2321 - accuracy: 0.9438 - val_loss: 24.2404 - val_accuracy: 0.0214\n",
            "Epoch 198/250\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.2238 - accuracy: 0.9482 - val_loss: 24.2840 - val_accuracy: 0.0250\n",
            "Epoch 199/250\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.2323 - accuracy: 0.9411 - val_loss: 24.3653 - val_accuracy: 0.0321\n",
            "Epoch 200/250\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2210 - accuracy: 0.9518 - val_loss: 24.4047 - val_accuracy: 0.0429\n",
            "Epoch 201/250\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.2219 - accuracy: 0.9518 - val_loss: 24.4853 - val_accuracy: 0.0357\n",
            "Epoch 202/250\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.2472 - accuracy: 0.9473 - val_loss: 24.6618 - val_accuracy: 0.0429\n",
            "Epoch 203/250\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2143 - accuracy: 0.9464 - val_loss: 24.5734 - val_accuracy: 0.0429\n",
            "Epoch 204/250\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2405 - accuracy: 0.9357 - val_loss: 24.5431 - val_accuracy: 0.0429\n",
            "Epoch 205/250\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 0.2359 - accuracy: 0.9473 - val_loss: 24.5006 - val_accuracy: 0.0321\n",
            "Epoch 206/250\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2135 - accuracy: 0.9545 - val_loss: 24.8066 - val_accuracy: 0.0429\n",
            "Epoch 207/250\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.2285 - accuracy: 0.9455 - val_loss: 24.7122 - val_accuracy: 0.0357\n",
            "Epoch 208/250\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2219 - accuracy: 0.9366 - val_loss: 24.7056 - val_accuracy: 0.0357\n",
            "Epoch 209/250\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2053 - accuracy: 0.9571 - val_loss: 24.8629 - val_accuracy: 0.0393\n",
            "Epoch 210/250\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.2216 - accuracy: 0.9554 - val_loss: 24.8421 - val_accuracy: 0.0321\n",
            "Epoch 211/250\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2008 - accuracy: 0.9500 - val_loss: 24.8935 - val_accuracy: 0.0250\n",
            "Epoch 212/250\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 0.2167 - accuracy: 0.9500 - val_loss: 24.9165 - val_accuracy: 0.0321\n",
            "Epoch 213/250\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.2141 - accuracy: 0.9473 - val_loss: 24.9737 - val_accuracy: 0.0286\n",
            "Epoch 214/250\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.1920 - accuracy: 0.9580 - val_loss: 24.9785 - val_accuracy: 0.0286\n",
            "Epoch 215/250\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2129 - accuracy: 0.9536 - val_loss: 25.1781 - val_accuracy: 0.0321\n",
            "Epoch 216/250\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2274 - accuracy: 0.9473 - val_loss: 25.2507 - val_accuracy: 0.0250\n",
            "Epoch 217/250\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.2117 - accuracy: 0.9384 - val_loss: 25.2527 - val_accuracy: 0.0214\n",
            "Epoch 218/250\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.2133 - accuracy: 0.9464 - val_loss: 25.0876 - val_accuracy: 0.0286\n",
            "Epoch 219/250\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.1874 - accuracy: 0.9625 - val_loss: 25.1687 - val_accuracy: 0.0250\n",
            "Epoch 220/250\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.1769 - accuracy: 0.9625 - val_loss: 25.2341 - val_accuracy: 0.0357\n",
            "Epoch 221/250\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.1749 - accuracy: 0.9661 - val_loss: 25.3596 - val_accuracy: 0.0321\n",
            "Epoch 222/250\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.1798 - accuracy: 0.9589 - val_loss: 25.3758 - val_accuracy: 0.0286\n",
            "Epoch 223/250\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.1783 - accuracy: 0.9580 - val_loss: 25.4137 - val_accuracy: 0.0357\n",
            "Epoch 224/250\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 0.1815 - accuracy: 0.9589 - val_loss: 25.5833 - val_accuracy: 0.0464\n",
            "Epoch 225/250\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.1813 - accuracy: 0.9598 - val_loss: 25.6725 - val_accuracy: 0.0321\n",
            "Epoch 226/250\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.1784 - accuracy: 0.9616 - val_loss: 25.7239 - val_accuracy: 0.0464\n",
            "Epoch 227/250\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.1873 - accuracy: 0.9571 - val_loss: 25.7049 - val_accuracy: 0.0393\n",
            "Epoch 228/250\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.1862 - accuracy: 0.9580 - val_loss: 25.6958 - val_accuracy: 0.0321\n",
            "Epoch 229/250\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.1931 - accuracy: 0.9545 - val_loss: 25.7470 - val_accuracy: 0.0321\n",
            "Epoch 230/250\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.1873 - accuracy: 0.9554 - val_loss: 25.8075 - val_accuracy: 0.0357\n",
            "Epoch 231/250\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.1729 - accuracy: 0.9652 - val_loss: 25.9366 - val_accuracy: 0.0321\n",
            "Epoch 232/250\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.1675 - accuracy: 0.9723 - val_loss: 25.8768 - val_accuracy: 0.0357\n",
            "Epoch 233/250\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.1968 - accuracy: 0.9545 - val_loss: 25.8684 - val_accuracy: 0.0286\n",
            "Epoch 234/250\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.1658 - accuracy: 0.9661 - val_loss: 25.9243 - val_accuracy: 0.0429\n",
            "Epoch 235/250\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.1840 - accuracy: 0.9554 - val_loss: 25.9779 - val_accuracy: 0.0393\n",
            "Epoch 236/250\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.1644 - accuracy: 0.9643 - val_loss: 26.0319 - val_accuracy: 0.0357\n",
            "Epoch 237/250\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.1694 - accuracy: 0.9589 - val_loss: 26.0950 - val_accuracy: 0.0393\n",
            "Epoch 238/250\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.1661 - accuracy: 0.9580 - val_loss: 26.2106 - val_accuracy: 0.0357\n",
            "Epoch 239/250\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.1616 - accuracy: 0.9643 - val_loss: 26.1641 - val_accuracy: 0.0429\n",
            "Epoch 240/250\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.1886 - accuracy: 0.9571 - val_loss: 26.1867 - val_accuracy: 0.0393\n",
            "Epoch 241/250\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.1588 - accuracy: 0.9643 - val_loss: 26.2592 - val_accuracy: 0.0429\n",
            "Epoch 242/250\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.1580 - accuracy: 0.9670 - val_loss: 26.1882 - val_accuracy: 0.0393\n",
            "Epoch 243/250\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.1659 - accuracy: 0.9598 - val_loss: 26.2849 - val_accuracy: 0.0357\n",
            "Epoch 244/250\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.1777 - accuracy: 0.9589 - val_loss: 26.3153 - val_accuracy: 0.0393\n",
            "Epoch 245/250\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.1691 - accuracy: 0.9598 - val_loss: 26.3449 - val_accuracy: 0.0357\n",
            "Epoch 246/250\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.1736 - accuracy: 0.9580 - val_loss: 26.2954 - val_accuracy: 0.0321\n",
            "Epoch 247/250\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.1741 - accuracy: 0.9652 - val_loss: 26.2973 - val_accuracy: 0.0429\n",
            "Epoch 248/250\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.1727 - accuracy: 0.9598 - val_loss: 26.4334 - val_accuracy: 0.0357\n",
            "Epoch 249/250\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.1592 - accuracy: 0.9661 - val_loss: 26.2338 - val_accuracy: 0.0429\n",
            "Epoch 250/250\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.1744 - accuracy: 0.9554 - val_loss: 26.4334 - val_accuracy: 0.0429\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'training and Validation Loss')"
            ]
          },
          "metadata": {},
          "execution_count": 66
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x360 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2DH1qPePozkZ",
        "outputId": "c4238d08-a314-499a-e27e-b7f33bf555c8"
      },
      "source": [
        "valid_preds = model.predict(valid_inputs)\n",
        "[np.argmax(preds[i]) for i in range(valid_preds.shape[0])][:10], [np.argmax(valid_labels[i]) for i in range(valid_labels.shape[0])][:10]"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([77, 336, 107, 40, 182, 155, 403, 9, 188, 462],\n",
              " [271, 168, 199, 193, 338, 453, 292, 213, 173, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jb6AGobhoozW",
        "outputId": "effd39d1-d90b-45ff-d8fa-9ab8c660fcf5"
      },
      "source": [
        "preds = model.predict(test_inputs)\n",
        "[np.argmax(preds[i]) for i in range(preds.shape[0])][:10], [np.argmax(test_labels[i]) for i in range(test_labels.shape[0])][:10]"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([77, 336, 107, 40, 182, 155, 403, 9, 188, 462],\n",
              " [81, 320, 99, 40, 190, 167, 399, 497, 204, 450])"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GclNsMO0oe5U"
      },
      "source": [
        "As we see the model is preforming well in train data but fails to perform in validation or test data. This is overfitting, where model momorize train data and fails to preform on test or validation data. \n",
        "I used regualazitation technique and dropout but the model still seems to perform poorly. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JUWIOVpxsSRk"
      },
      "source": [
        "### Model 3: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "hP8PXj0gniEQ",
        "outputId": "6d5804b2-f82d-4b97-953c-ca22df6ea671"
      },
      "source": [
        "import keras.models\n",
        "import numpy as np\n",
        "from python_toolbox import random_tools\n",
        "\n",
        "RADIX = 500\n",
        "FEATURE_BITS = 11\n",
        "\n",
        "def _get_number(vector):\n",
        "    return sum(x * 2 ** i for i, x in enumerate(vector))\n",
        "\n",
        "def _get_mod_result(vector):\n",
        "    return _get_number(vector) % RADIX\n",
        "\n",
        "def _number_to_vector(number):\n",
        "    binary_string = bin(number)[2:]\n",
        "    if len(binary_string) > FEATURE_BITS:\n",
        "        raise NotImplementedError\n",
        "    bits = (((0,) * (FEATURE_BITS - len(binary_string))) +\n",
        "            tuple(map(int, binary_string)))[::-1]\n",
        "    assert len(bits) == FEATURE_BITS\n",
        "    return np.c_[bits]\n",
        "\n",
        "def get_mod_result_vector(vector):\n",
        "    v = np.repeat(0, 500)\n",
        "    v[_get_mod_result(vector)] = 1\n",
        "    return v\n",
        "\n",
        "epochs = 2000\n",
        "\n",
        "def main():\n",
        "    train_inputs = np.random.randint(2, size=(1120, FEATURE_BITS))\n",
        "    train_labels = np.vstack(map(get_mod_result_vector, train_inputs))\n",
        "\n",
        "    valid_inputs = np.random.randint(2, size=(280, FEATURE_BITS))\n",
        "    valid_labels = np.vstack(map(get_mod_result_vector, valid_inputs))\n",
        "\n",
        "    test_input = random_tools.shuffled(range(2 ** FEATURE_BITS - 49))[:600]\n",
        "\n",
        "    model = keras.models.Sequential([\n",
        "            keras.layers.Dense(20, activation='relu', input_dim=FEATURE_BITS),\n",
        "            keras.layers.Dense(20, activation='relu'),\n",
        "            keras.layers.Dense(500, activation='softmax')\n",
        "    ])\n",
        "    model.compile(optimizer='sgd',\n",
        "                  loss='categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    history = model.fit(train_inputs,train_labels, \n",
        "                        epochs=epochs, \n",
        "                        batch_size=50, \n",
        "                        verbose = 1,\n",
        "                        validation_data=(valid_inputs, valid_labels))\n",
        "    def predict(number):\n",
        "        preds = model.predict(_number_to_vector(number))\n",
        "        return np.argmax(preds)\n",
        "        \n",
        "    def is_correct_for_number(x):\n",
        "        return bool(predict(x) == x % RADIX)\n",
        "    print('Total accuracy:')\n",
        "    print(sum(map(is_correct_for_number, test_input)) / len(test_input))\n",
        "\n",
        "    #plotting loss and accuracy\n",
        "    acc = history.history['accuracy']\n",
        "    val_acc = history.history['val_accuracy']\n",
        "\n",
        "    loss = history.history['loss']\n",
        "    val_loss = history.history['val_loss']\n",
        "\n",
        "    epochs_range = range(epochs)\n",
        "    plt.figure(figsize=(8,5))\n",
        "    plt.subplot(1,2,1)\n",
        "    plt.plot(epochs_range, acc, label='train accuracy')\n",
        "    plt.plot(epochs_range, val_acc, label='validatoin accuracy')\n",
        "    plt.legend(loc='lower right')\n",
        "    plt.title('training and Validation Accuracy')\n",
        "\n",
        "    plt.subplot(1,2,2)\n",
        "    plt.plot(epochs_range, loss, label='train loss')\n",
        "    plt.plot(epochs_range, val_loss, label='validatoin loss')\n",
        "    plt.legend(loc='lower right')\n",
        "    plt.title('training and Validation Loss')\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:32: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:35: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2000\n",
            "23/23 [==============================] - 1s 11ms/step - loss: 6.2204 - accuracy: 0.0027 - val_loss: 6.2198 - val_accuracy: 0.0036\n",
            "Epoch 2/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 6.2197 - accuracy: 0.0027 - val_loss: 6.2198 - val_accuracy: 0.0036\n",
            "Epoch 3/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 6.2189 - accuracy: 0.0027 - val_loss: 6.2197 - val_accuracy: 0.0036\n",
            "Epoch 4/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 6.2181 - accuracy: 0.0027 - val_loss: 6.2197 - val_accuracy: 0.0036\n",
            "Epoch 5/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 6.2174 - accuracy: 0.0027 - val_loss: 6.2196 - val_accuracy: 0.0036\n",
            "Epoch 6/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 6.2167 - accuracy: 0.0027 - val_loss: 6.2196 - val_accuracy: 0.0036\n",
            "Epoch 7/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 6.2159 - accuracy: 0.0027 - val_loss: 6.2195 - val_accuracy: 0.0036\n",
            "Epoch 8/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 6.2152 - accuracy: 0.0027 - val_loss: 6.2195 - val_accuracy: 0.0036\n",
            "Epoch 9/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 6.2145 - accuracy: 0.0027 - val_loss: 6.2194 - val_accuracy: 0.0036\n",
            "Epoch 10/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 6.2138 - accuracy: 0.0027 - val_loss: 6.2194 - val_accuracy: 0.0036\n",
            "Epoch 11/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 6.2131 - accuracy: 0.0027 - val_loss: 6.2194 - val_accuracy: 0.0036\n",
            "Epoch 12/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 6.2124 - accuracy: 0.0027 - val_loss: 6.2193 - val_accuracy: 0.0036\n",
            "Epoch 13/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 6.2117 - accuracy: 0.0027 - val_loss: 6.2193 - val_accuracy: 0.0036\n",
            "Epoch 14/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 6.2110 - accuracy: 0.0027 - val_loss: 6.2193 - val_accuracy: 0.0036\n",
            "Epoch 15/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 6.2103 - accuracy: 0.0027 - val_loss: 6.2192 - val_accuracy: 0.0036\n",
            "Epoch 16/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 6.2096 - accuracy: 0.0027 - val_loss: 6.2192 - val_accuracy: 0.0036\n",
            "Epoch 17/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 6.2089 - accuracy: 0.0027 - val_loss: 6.2192 - val_accuracy: 0.0036\n",
            "Epoch 18/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 6.2082 - accuracy: 0.0027 - val_loss: 6.2192 - val_accuracy: 0.0036\n",
            "Epoch 19/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 6.2075 - accuracy: 0.0027 - val_loss: 6.2192 - val_accuracy: 0.0036\n",
            "Epoch 20/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 6.2069 - accuracy: 0.0027 - val_loss: 6.2191 - val_accuracy: 0.0036\n",
            "Epoch 21/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 6.2062 - accuracy: 0.0027 - val_loss: 6.2191 - val_accuracy: 0.0036\n",
            "Epoch 22/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 6.2055 - accuracy: 0.0027 - val_loss: 6.2191 - val_accuracy: 0.0036\n",
            "Epoch 23/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 6.2048 - accuracy: 0.0027 - val_loss: 6.2191 - val_accuracy: 0.0036\n",
            "Epoch 24/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 6.2042 - accuracy: 0.0027 - val_loss: 6.2191 - val_accuracy: 0.0036\n",
            "Epoch 25/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 6.2035 - accuracy: 0.0027 - val_loss: 6.2191 - val_accuracy: 0.0036\n",
            "Epoch 26/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 6.2028 - accuracy: 0.0027 - val_loss: 6.2191 - val_accuracy: 0.0036\n",
            "Epoch 27/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 6.2021 - accuracy: 0.0027 - val_loss: 6.2191 - val_accuracy: 0.0036\n",
            "Epoch 28/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 6.2014 - accuracy: 0.0027 - val_loss: 6.2191 - val_accuracy: 0.0036\n",
            "Epoch 29/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 6.2008 - accuracy: 0.0027 - val_loss: 6.2191 - val_accuracy: 0.0036\n",
            "Epoch 30/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 6.2001 - accuracy: 0.0045 - val_loss: 6.2191 - val_accuracy: 0.0036\n",
            "Epoch 31/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 6.1994 - accuracy: 0.0080 - val_loss: 6.2191 - val_accuracy: 0.0036\n",
            "Epoch 32/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 6.1987 - accuracy: 0.0071 - val_loss: 6.2191 - val_accuracy: 0.0000e+00\n",
            "Epoch 33/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 6.1980 - accuracy: 0.0071 - val_loss: 6.2191 - val_accuracy: 0.0000e+00\n",
            "Epoch 34/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 6.1973 - accuracy: 0.0089 - val_loss: 6.2192 - val_accuracy: 0.0000e+00\n",
            "Epoch 35/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 6.1966 - accuracy: 0.0098 - val_loss: 6.2192 - val_accuracy: 0.0000e+00\n",
            "Epoch 36/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 6.1959 - accuracy: 0.0116 - val_loss: 6.2192 - val_accuracy: 0.0000e+00\n",
            "Epoch 37/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 6.1952 - accuracy: 0.0116 - val_loss: 6.2192 - val_accuracy: 0.0000e+00\n",
            "Epoch 38/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 6.1944 - accuracy: 0.0116 - val_loss: 6.2192 - val_accuracy: 0.0000e+00\n",
            "Epoch 39/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 6.1937 - accuracy: 0.0116 - val_loss: 6.2193 - val_accuracy: 0.0000e+00\n",
            "Epoch 40/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 6.1930 - accuracy: 0.0116 - val_loss: 6.2193 - val_accuracy: 0.0000e+00\n",
            "Epoch 41/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 6.1923 - accuracy: 0.0134 - val_loss: 6.2193 - val_accuracy: 0.0000e+00\n",
            "Epoch 42/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 6.1915 - accuracy: 0.0134 - val_loss: 6.2193 - val_accuracy: 0.0000e+00\n",
            "Epoch 43/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 6.1908 - accuracy: 0.0134 - val_loss: 6.2193 - val_accuracy: 0.0000e+00\n",
            "Epoch 44/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 6.1900 - accuracy: 0.0134 - val_loss: 6.2194 - val_accuracy: 0.0000e+00\n",
            "Epoch 45/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 6.1893 - accuracy: 0.0134 - val_loss: 6.2194 - val_accuracy: 0.0000e+00\n",
            "Epoch 46/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 6.1885 - accuracy: 0.0143 - val_loss: 6.2194 - val_accuracy: 0.0000e+00\n",
            "Epoch 47/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 6.1877 - accuracy: 0.0143 - val_loss: 6.2195 - val_accuracy: 0.0000e+00\n",
            "Epoch 48/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 6.1870 - accuracy: 0.0152 - val_loss: 6.2195 - val_accuracy: 0.0000e+00\n",
            "Epoch 49/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 6.1862 - accuracy: 0.0152 - val_loss: 6.2196 - val_accuracy: 0.0000e+00\n",
            "Epoch 50/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 6.1854 - accuracy: 0.0152 - val_loss: 6.2196 - val_accuracy: 0.0000e+00\n",
            "Epoch 51/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 6.1846 - accuracy: 0.0152 - val_loss: 6.2197 - val_accuracy: 0.0000e+00\n",
            "Epoch 52/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 6.1837 - accuracy: 0.0152 - val_loss: 6.2197 - val_accuracy: 0.0000e+00\n",
            "Epoch 53/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 6.1829 - accuracy: 0.0152 - val_loss: 6.2198 - val_accuracy: 0.0000e+00\n",
            "Epoch 54/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 6.1820 - accuracy: 0.0152 - val_loss: 6.2199 - val_accuracy: 0.0000e+00\n",
            "Epoch 55/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 6.1811 - accuracy: 0.0152 - val_loss: 6.2200 - val_accuracy: 0.0000e+00\n",
            "Epoch 56/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 6.1803 - accuracy: 0.0152 - val_loss: 6.2200 - val_accuracy: 0.0000e+00\n",
            "Epoch 57/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 6.1794 - accuracy: 0.0152 - val_loss: 6.2201 - val_accuracy: 0.0000e+00\n",
            "Epoch 58/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 6.1785 - accuracy: 0.0143 - val_loss: 6.2202 - val_accuracy: 0.0000e+00\n",
            "Epoch 59/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 6.1776 - accuracy: 0.0143 - val_loss: 6.2203 - val_accuracy: 0.0000e+00\n",
            "Epoch 60/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 6.1766 - accuracy: 0.0143 - val_loss: 6.2204 - val_accuracy: 0.0000e+00\n",
            "Epoch 61/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 6.1757 - accuracy: 0.0143 - val_loss: 6.2204 - val_accuracy: 0.0000e+00\n",
            "Epoch 62/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 6.1747 - accuracy: 0.0143 - val_loss: 6.2206 - val_accuracy: 0.0000e+00\n",
            "Epoch 63/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 6.1738 - accuracy: 0.0143 - val_loss: 6.2207 - val_accuracy: 0.0000e+00\n",
            "Epoch 64/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 6.1728 - accuracy: 0.0143 - val_loss: 6.2208 - val_accuracy: 0.0000e+00\n",
            "Epoch 65/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 6.1718 - accuracy: 0.0143 - val_loss: 6.2209 - val_accuracy: 0.0000e+00\n",
            "Epoch 66/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 6.1707 - accuracy: 0.0143 - val_loss: 6.2210 - val_accuracy: 0.0000e+00\n",
            "Epoch 67/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 6.1697 - accuracy: 0.0143 - val_loss: 6.2212 - val_accuracy: 0.0000e+00\n",
            "Epoch 68/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 6.1686 - accuracy: 0.0143 - val_loss: 6.2213 - val_accuracy: 0.0000e+00\n",
            "Epoch 69/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 6.1675 - accuracy: 0.0143 - val_loss: 6.2214 - val_accuracy: 0.0000e+00\n",
            "Epoch 70/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 6.1664 - accuracy: 0.0134 - val_loss: 6.2216 - val_accuracy: 0.0000e+00\n",
            "Epoch 71/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 6.1653 - accuracy: 0.0143 - val_loss: 6.2218 - val_accuracy: 0.0000e+00\n",
            "Epoch 72/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 6.1641 - accuracy: 0.0143 - val_loss: 6.2219 - val_accuracy: 0.0000e+00\n",
            "Epoch 73/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 6.1629 - accuracy: 0.0143 - val_loss: 6.2221 - val_accuracy: 0.0000e+00\n",
            "Epoch 74/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 6.1618 - accuracy: 0.0143 - val_loss: 6.2222 - val_accuracy: 0.0000e+00\n",
            "Epoch 75/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 6.1606 - accuracy: 0.0143 - val_loss: 6.2224 - val_accuracy: 0.0000e+00\n",
            "Epoch 76/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 6.1593 - accuracy: 0.0143 - val_loss: 6.2226 - val_accuracy: 0.0000e+00\n",
            "Epoch 77/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 6.1580 - accuracy: 0.0143 - val_loss: 6.2228 - val_accuracy: 0.0000e+00\n",
            "Epoch 78/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 6.1568 - accuracy: 0.0143 - val_loss: 6.2229 - val_accuracy: 0.0000e+00\n",
            "Epoch 79/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 6.1554 - accuracy: 0.0143 - val_loss: 6.2232 - val_accuracy: 0.0000e+00\n",
            "Epoch 80/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 6.1541 - accuracy: 0.0125 - val_loss: 6.2234 - val_accuracy: 0.0000e+00\n",
            "Epoch 81/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 6.1527 - accuracy: 0.0143 - val_loss: 6.2236 - val_accuracy: 0.0000e+00\n",
            "Epoch 82/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 6.1513 - accuracy: 0.0143 - val_loss: 6.2238 - val_accuracy: 0.0000e+00\n",
            "Epoch 83/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 6.1498 - accuracy: 0.0143 - val_loss: 6.2241 - val_accuracy: 0.0000e+00\n",
            "Epoch 84/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 6.1484 - accuracy: 0.0143 - val_loss: 6.2244 - val_accuracy: 0.0000e+00\n",
            "Epoch 85/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 6.1469 - accuracy: 0.0143 - val_loss: 6.2247 - val_accuracy: 0.0000e+00\n",
            "Epoch 86/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 6.1453 - accuracy: 0.0143 - val_loss: 6.2250 - val_accuracy: 0.0000e+00\n",
            "Epoch 87/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 6.1437 - accuracy: 0.0143 - val_loss: 6.2253 - val_accuracy: 0.0000e+00\n",
            "Epoch 88/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 6.1421 - accuracy: 0.0143 - val_loss: 6.2256 - val_accuracy: 0.0000e+00\n",
            "Epoch 89/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 6.1404 - accuracy: 0.0134 - val_loss: 6.2260 - val_accuracy: 0.0000e+00\n",
            "Epoch 90/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 6.1387 - accuracy: 0.0134 - val_loss: 6.2264 - val_accuracy: 0.0000e+00\n",
            "Epoch 91/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 6.1370 - accuracy: 0.0143 - val_loss: 6.2267 - val_accuracy: 0.0000e+00\n",
            "Epoch 92/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 6.1353 - accuracy: 0.0143 - val_loss: 6.2272 - val_accuracy: 0.0000e+00\n",
            "Epoch 93/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 6.1335 - accuracy: 0.0143 - val_loss: 6.2276 - val_accuracy: 0.0000e+00\n",
            "Epoch 94/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 6.1317 - accuracy: 0.0143 - val_loss: 6.2281 - val_accuracy: 0.0000e+00\n",
            "Epoch 95/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 6.1298 - accuracy: 0.0143 - val_loss: 6.2286 - val_accuracy: 0.0000e+00\n",
            "Epoch 96/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 6.1279 - accuracy: 0.0143 - val_loss: 6.2291 - val_accuracy: 0.0000e+00\n",
            "Epoch 97/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 6.1259 - accuracy: 0.0143 - val_loss: 6.2297 - val_accuracy: 0.0000e+00\n",
            "Epoch 98/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 6.1239 - accuracy: 0.0143 - val_loss: 6.2303 - val_accuracy: 0.0000e+00\n",
            "Epoch 99/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 6.1218 - accuracy: 0.0143 - val_loss: 6.2309 - val_accuracy: 0.0000e+00\n",
            "Epoch 100/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 6.1198 - accuracy: 0.0143 - val_loss: 6.2315 - val_accuracy: 0.0000e+00\n",
            "Epoch 101/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 6.1177 - accuracy: 0.0143 - val_loss: 6.2322 - val_accuracy: 0.0000e+00\n",
            "Epoch 102/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 6.1155 - accuracy: 0.0143 - val_loss: 6.2329 - val_accuracy: 0.0000e+00\n",
            "Epoch 103/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 6.1134 - accuracy: 0.0143 - val_loss: 6.2337 - val_accuracy: 0.0000e+00\n",
            "Epoch 104/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 6.1111 - accuracy: 0.0143 - val_loss: 6.2344 - val_accuracy: 0.0000e+00\n",
            "Epoch 105/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 6.1089 - accuracy: 0.0143 - val_loss: 6.2352 - val_accuracy: 0.0000e+00\n",
            "Epoch 106/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 6.1066 - accuracy: 0.0143 - val_loss: 6.2360 - val_accuracy: 0.0000e+00\n",
            "Epoch 107/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 6.1043 - accuracy: 0.0143 - val_loss: 6.2370 - val_accuracy: 0.0000e+00\n",
            "Epoch 108/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 6.1018 - accuracy: 0.0143 - val_loss: 6.2379 - val_accuracy: 0.0000e+00\n",
            "Epoch 109/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 6.0994 - accuracy: 0.0143 - val_loss: 6.2389 - val_accuracy: 0.0000e+00\n",
            "Epoch 110/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 6.0970 - accuracy: 0.0143 - val_loss: 6.2398 - val_accuracy: 0.0000e+00\n",
            "Epoch 111/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 6.0946 - accuracy: 0.0143 - val_loss: 6.2408 - val_accuracy: 0.0000e+00\n",
            "Epoch 112/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 6.0921 - accuracy: 0.0143 - val_loss: 6.2418 - val_accuracy: 0.0000e+00\n",
            "Epoch 113/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 6.0896 - accuracy: 0.0134 - val_loss: 6.2429 - val_accuracy: 0.0000e+00\n",
            "Epoch 114/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 6.0869 - accuracy: 0.0143 - val_loss: 6.2441 - val_accuracy: 0.0000e+00\n",
            "Epoch 115/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 6.0843 - accuracy: 0.0143 - val_loss: 6.2453 - val_accuracy: 0.0000e+00\n",
            "Epoch 116/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 6.0817 - accuracy: 0.0143 - val_loss: 6.2465 - val_accuracy: 0.0000e+00\n",
            "Epoch 117/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 6.0790 - accuracy: 0.0125 - val_loss: 6.2477 - val_accuracy: 0.0000e+00\n",
            "Epoch 118/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 6.0764 - accuracy: 0.0143 - val_loss: 6.2490 - val_accuracy: 0.0000e+00\n",
            "Epoch 119/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 6.0737 - accuracy: 0.0134 - val_loss: 6.2504 - val_accuracy: 0.0000e+00\n",
            "Epoch 120/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 6.0710 - accuracy: 0.0143 - val_loss: 6.2518 - val_accuracy: 0.0000e+00\n",
            "Epoch 121/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 6.0682 - accuracy: 0.0143 - val_loss: 6.2532 - val_accuracy: 0.0000e+00\n",
            "Epoch 122/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 6.0654 - accuracy: 0.0143 - val_loss: 6.2548 - val_accuracy: 0.0000e+00\n",
            "Epoch 123/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 6.0626 - accuracy: 0.0125 - val_loss: 6.2563 - val_accuracy: 0.0000e+00\n",
            "Epoch 124/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 6.0599 - accuracy: 0.0134 - val_loss: 6.2580 - val_accuracy: 0.0000e+00\n",
            "Epoch 125/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 6.0571 - accuracy: 0.0125 - val_loss: 6.2597 - val_accuracy: 0.0000e+00\n",
            "Epoch 126/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 6.0543 - accuracy: 0.0143 - val_loss: 6.2614 - val_accuracy: 0.0000e+00\n",
            "Epoch 127/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 6.0515 - accuracy: 0.0134 - val_loss: 6.2632 - val_accuracy: 0.0000e+00\n",
            "Epoch 128/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 6.0487 - accuracy: 0.0134 - val_loss: 6.2650 - val_accuracy: 0.0000e+00\n",
            "Epoch 129/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 6.0459 - accuracy: 0.0125 - val_loss: 6.2670 - val_accuracy: 0.0000e+00\n",
            "Epoch 130/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 6.0431 - accuracy: 0.0125 - val_loss: 6.2688 - val_accuracy: 0.0000e+00\n",
            "Epoch 131/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 6.0404 - accuracy: 0.0125 - val_loss: 6.2706 - val_accuracy: 0.0000e+00\n",
            "Epoch 132/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 6.0375 - accuracy: 0.0125 - val_loss: 6.2727 - val_accuracy: 0.0000e+00\n",
            "Epoch 133/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 6.0347 - accuracy: 0.0125 - val_loss: 6.2746 - val_accuracy: 0.0000e+00\n",
            "Epoch 134/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 6.0320 - accuracy: 0.0125 - val_loss: 6.2769 - val_accuracy: 0.0000e+00\n",
            "Epoch 135/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 6.0291 - accuracy: 0.0125 - val_loss: 6.2789 - val_accuracy: 0.0000e+00\n",
            "Epoch 136/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 6.0264 - accuracy: 0.0125 - val_loss: 6.2809 - val_accuracy: 0.0000e+00\n",
            "Epoch 137/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 6.0236 - accuracy: 0.0125 - val_loss: 6.2829 - val_accuracy: 0.0000e+00\n",
            "Epoch 138/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 6.0210 - accuracy: 0.0125 - val_loss: 6.2851 - val_accuracy: 0.0000e+00\n",
            "Epoch 139/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 6.0181 - accuracy: 0.0125 - val_loss: 6.2874 - val_accuracy: 0.0000e+00\n",
            "Epoch 140/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 6.0154 - accuracy: 0.0125 - val_loss: 6.2896 - val_accuracy: 0.0000e+00\n",
            "Epoch 141/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 6.0127 - accuracy: 0.0125 - val_loss: 6.2916 - val_accuracy: 0.0000e+00\n",
            "Epoch 142/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 6.0101 - accuracy: 0.0125 - val_loss: 6.2937 - val_accuracy: 0.0000e+00\n",
            "Epoch 143/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 6.0074 - accuracy: 0.0125 - val_loss: 6.2960 - val_accuracy: 0.0000e+00\n",
            "Epoch 144/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 6.0048 - accuracy: 0.0125 - val_loss: 6.2978 - val_accuracy: 0.0000e+00\n",
            "Epoch 145/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 6.0023 - accuracy: 0.0125 - val_loss: 6.3001 - val_accuracy: 0.0000e+00\n",
            "Epoch 146/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 5.9997 - accuracy: 0.0125 - val_loss: 6.3021 - val_accuracy: 0.0000e+00\n",
            "Epoch 147/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 5.9972 - accuracy: 0.0125 - val_loss: 6.3039 - val_accuracy: 0.0000e+00\n",
            "Epoch 148/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 5.9946 - accuracy: 0.0125 - val_loss: 6.3059 - val_accuracy: 0.0000e+00\n",
            "Epoch 149/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 5.9922 - accuracy: 0.0125 - val_loss: 6.3081 - val_accuracy: 0.0000e+00\n",
            "Epoch 150/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 5.9896 - accuracy: 0.0125 - val_loss: 6.3099 - val_accuracy: 0.0000e+00\n",
            "Epoch 151/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 5.9872 - accuracy: 0.0125 - val_loss: 6.3122 - val_accuracy: 0.0000e+00\n",
            "Epoch 152/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 5.9846 - accuracy: 0.0125 - val_loss: 6.3141 - val_accuracy: 0.0000e+00\n",
            "Epoch 153/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 5.9821 - accuracy: 0.0125 - val_loss: 6.3158 - val_accuracy: 0.0000e+00\n",
            "Epoch 154/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 5.9796 - accuracy: 0.0125 - val_loss: 6.3176 - val_accuracy: 0.0000e+00\n",
            "Epoch 155/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 5.9772 - accuracy: 0.0125 - val_loss: 6.3196 - val_accuracy: 0.0000e+00\n",
            "Epoch 156/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 5.9747 - accuracy: 0.0125 - val_loss: 6.3216 - val_accuracy: 0.0000e+00\n",
            "Epoch 157/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 5.9723 - accuracy: 0.0125 - val_loss: 6.3236 - val_accuracy: 0.0000e+00\n",
            "Epoch 158/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 5.9699 - accuracy: 0.0125 - val_loss: 6.3251 - val_accuracy: 0.0000e+00\n",
            "Epoch 159/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 5.9676 - accuracy: 0.0125 - val_loss: 6.3266 - val_accuracy: 0.0000e+00\n",
            "Epoch 160/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 5.9651 - accuracy: 0.0134 - val_loss: 6.3283 - val_accuracy: 0.0000e+00\n",
            "Epoch 161/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 5.9628 - accuracy: 0.0125 - val_loss: 6.3299 - val_accuracy: 0.0000e+00\n",
            "Epoch 162/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 5.9604 - accuracy: 0.0125 - val_loss: 6.3313 - val_accuracy: 0.0000e+00\n",
            "Epoch 163/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 5.9580 - accuracy: 0.0125 - val_loss: 6.3329 - val_accuracy: 0.0000e+00\n",
            "Epoch 164/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 5.9557 - accuracy: 0.0134 - val_loss: 6.3345 - val_accuracy: 0.0000e+00\n",
            "Epoch 165/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 5.9533 - accuracy: 0.0134 - val_loss: 6.3360 - val_accuracy: 0.0000e+00\n",
            "Epoch 166/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 5.9508 - accuracy: 0.0134 - val_loss: 6.3375 - val_accuracy: 0.0000e+00\n",
            "Epoch 167/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 5.9485 - accuracy: 0.0125 - val_loss: 6.3393 - val_accuracy: 0.0000e+00\n",
            "Epoch 168/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 5.9462 - accuracy: 0.0125 - val_loss: 6.3410 - val_accuracy: 0.0000e+00\n",
            "Epoch 169/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 5.9440 - accuracy: 0.0143 - val_loss: 6.3425 - val_accuracy: 0.0000e+00\n",
            "Epoch 170/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 5.9416 - accuracy: 0.0134 - val_loss: 6.3443 - val_accuracy: 0.0000e+00\n",
            "Epoch 171/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 5.9393 - accuracy: 0.0125 - val_loss: 6.3460 - val_accuracy: 0.0000e+00\n",
            "Epoch 172/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 5.9371 - accuracy: 0.0134 - val_loss: 6.3476 - val_accuracy: 0.0000e+00\n",
            "Epoch 173/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 5.9348 - accuracy: 0.0134 - val_loss: 6.3491 - val_accuracy: 0.0000e+00\n",
            "Epoch 174/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 5.9324 - accuracy: 0.0143 - val_loss: 6.3504 - val_accuracy: 0.0000e+00\n",
            "Epoch 175/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 5.9302 - accuracy: 0.0125 - val_loss: 6.3515 - val_accuracy: 0.0000e+00\n",
            "Epoch 176/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 5.9279 - accuracy: 0.0134 - val_loss: 6.3531 - val_accuracy: 0.0000e+00\n",
            "Epoch 177/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 5.9257 - accuracy: 0.0143 - val_loss: 6.3550 - val_accuracy: 0.0000e+00\n",
            "Epoch 178/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 5.9235 - accuracy: 0.0143 - val_loss: 6.3565 - val_accuracy: 0.0000e+00\n",
            "Epoch 179/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 5.9210 - accuracy: 0.0143 - val_loss: 6.3575 - val_accuracy: 0.0000e+00\n",
            "Epoch 180/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 5.9187 - accuracy: 0.0143 - val_loss: 6.3589 - val_accuracy: 0.0000e+00\n",
            "Epoch 181/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 5.9164 - accuracy: 0.0143 - val_loss: 6.3603 - val_accuracy: 0.0000e+00\n",
            "Epoch 182/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 5.9142 - accuracy: 0.0143 - val_loss: 6.3616 - val_accuracy: 0.0000e+00\n",
            "Epoch 183/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 5.9118 - accuracy: 0.0143 - val_loss: 6.3630 - val_accuracy: 0.0000e+00\n",
            "Epoch 184/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 5.9097 - accuracy: 0.0143 - val_loss: 6.3644 - val_accuracy: 0.0000e+00\n",
            "Epoch 185/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 5.9073 - accuracy: 0.0134 - val_loss: 6.3657 - val_accuracy: 0.0000e+00\n",
            "Epoch 186/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 5.9051 - accuracy: 0.0143 - val_loss: 6.3666 - val_accuracy: 0.0000e+00\n",
            "Epoch 187/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 5.9028 - accuracy: 0.0125 - val_loss: 6.3681 - val_accuracy: 0.0000e+00\n",
            "Epoch 188/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 5.9006 - accuracy: 0.0143 - val_loss: 6.3689 - val_accuracy: 0.0000e+00\n",
            "Epoch 189/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 5.8983 - accuracy: 0.0125 - val_loss: 6.3699 - val_accuracy: 0.0000e+00\n",
            "Epoch 190/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 5.8959 - accuracy: 0.0134 - val_loss: 6.3707 - val_accuracy: 0.0000e+00\n",
            "Epoch 191/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 5.8936 - accuracy: 0.0143 - val_loss: 6.3727 - val_accuracy: 0.0000e+00\n",
            "Epoch 192/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 5.8914 - accuracy: 0.0134 - val_loss: 6.3737 - val_accuracy: 0.0000e+00\n",
            "Epoch 193/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 5.8891 - accuracy: 0.0125 - val_loss: 6.3743 - val_accuracy: 0.0000e+00\n",
            "Epoch 194/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 5.8868 - accuracy: 0.0134 - val_loss: 6.3752 - val_accuracy: 0.0000e+00\n",
            "Epoch 195/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 5.8846 - accuracy: 0.0125 - val_loss: 6.3761 - val_accuracy: 0.0000e+00\n",
            "Epoch 196/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 5.8822 - accuracy: 0.0125 - val_loss: 6.3777 - val_accuracy: 0.0000e+00\n",
            "Epoch 197/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 5.8800 - accuracy: 0.0125 - val_loss: 6.3785 - val_accuracy: 0.0000e+00\n",
            "Epoch 198/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 5.8776 - accuracy: 0.0143 - val_loss: 6.3794 - val_accuracy: 0.0000e+00\n",
            "Epoch 199/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 5.8753 - accuracy: 0.0125 - val_loss: 6.3799 - val_accuracy: 0.0000e+00\n",
            "Epoch 200/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 5.8730 - accuracy: 0.0134 - val_loss: 6.3807 - val_accuracy: 0.0000e+00\n",
            "Epoch 201/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 5.8707 - accuracy: 0.0125 - val_loss: 6.3818 - val_accuracy: 0.0000e+00\n",
            "Epoch 202/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 5.8684 - accuracy: 0.0125 - val_loss: 6.3831 - val_accuracy: 0.0000e+00\n",
            "Epoch 203/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 5.8659 - accuracy: 0.0125 - val_loss: 6.3842 - val_accuracy: 0.0000e+00\n",
            "Epoch 204/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 5.8635 - accuracy: 0.0125 - val_loss: 6.3848 - val_accuracy: 0.0000e+00\n",
            "Epoch 205/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 5.8612 - accuracy: 0.0125 - val_loss: 6.3854 - val_accuracy: 0.0000e+00\n",
            "Epoch 206/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 5.8589 - accuracy: 0.0125 - val_loss: 6.3864 - val_accuracy: 0.0000e+00\n",
            "Epoch 207/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 5.8564 - accuracy: 0.0152 - val_loss: 6.3869 - val_accuracy: 0.0000e+00\n",
            "Epoch 208/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 5.8539 - accuracy: 0.0152 - val_loss: 6.3876 - val_accuracy: 0.0000e+00\n",
            "Epoch 209/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 5.8514 - accuracy: 0.0161 - val_loss: 6.3885 - val_accuracy: 0.0000e+00\n",
            "Epoch 210/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 5.8489 - accuracy: 0.0152 - val_loss: 6.3886 - val_accuracy: 0.0000e+00\n",
            "Epoch 211/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 5.8466 - accuracy: 0.0152 - val_loss: 6.3890 - val_accuracy: 0.0000e+00\n",
            "Epoch 212/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 5.8442 - accuracy: 0.0152 - val_loss: 6.3898 - val_accuracy: 0.0000e+00\n",
            "Epoch 213/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 5.8417 - accuracy: 0.0161 - val_loss: 6.3906 - val_accuracy: 0.0000e+00\n",
            "Epoch 214/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 5.8391 - accuracy: 0.0152 - val_loss: 6.3911 - val_accuracy: 0.0000e+00\n",
            "Epoch 215/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 5.8365 - accuracy: 0.0152 - val_loss: 6.3918 - val_accuracy: 0.0000e+00\n",
            "Epoch 216/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 5.8340 - accuracy: 0.0161 - val_loss: 6.3920 - val_accuracy: 0.0000e+00\n",
            "Epoch 217/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 5.8314 - accuracy: 0.0161 - val_loss: 6.3927 - val_accuracy: 0.0000e+00\n",
            "Epoch 218/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 5.8288 - accuracy: 0.0161 - val_loss: 6.3932 - val_accuracy: 0.0000e+00\n",
            "Epoch 219/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 5.8262 - accuracy: 0.0152 - val_loss: 6.3940 - val_accuracy: 0.0000e+00\n",
            "Epoch 220/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 5.8235 - accuracy: 0.0161 - val_loss: 6.3948 - val_accuracy: 0.0000e+00\n",
            "Epoch 221/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 5.8209 - accuracy: 0.0161 - val_loss: 6.3955 - val_accuracy: 0.0000e+00\n",
            "Epoch 222/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 5.8182 - accuracy: 0.0161 - val_loss: 6.3961 - val_accuracy: 0.0000e+00\n",
            "Epoch 223/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 5.8153 - accuracy: 0.0161 - val_loss: 6.3964 - val_accuracy: 0.0000e+00\n",
            "Epoch 224/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 5.8127 - accuracy: 0.0161 - val_loss: 6.3964 - val_accuracy: 0.0000e+00\n",
            "Epoch 225/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 5.8100 - accuracy: 0.0161 - val_loss: 6.3964 - val_accuracy: 0.0000e+00\n",
            "Epoch 226/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 5.8071 - accuracy: 0.0161 - val_loss: 6.3965 - val_accuracy: 0.0000e+00\n",
            "Epoch 227/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 5.8042 - accuracy: 0.0161 - val_loss: 6.3972 - val_accuracy: 0.0000e+00\n",
            "Epoch 228/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 5.8014 - accuracy: 0.0161 - val_loss: 6.3976 - val_accuracy: 0.0000e+00\n",
            "Epoch 229/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 5.7985 - accuracy: 0.0161 - val_loss: 6.3981 - val_accuracy: 0.0000e+00\n",
            "Epoch 230/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 5.7957 - accuracy: 0.0161 - val_loss: 6.3984 - val_accuracy: 0.0000e+00\n",
            "Epoch 231/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 5.7926 - accuracy: 0.0161 - val_loss: 6.3982 - val_accuracy: 0.0000e+00\n",
            "Epoch 232/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 5.7896 - accuracy: 0.0161 - val_loss: 6.3983 - val_accuracy: 0.0000e+00\n",
            "Epoch 233/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 5.7867 - accuracy: 0.0161 - val_loss: 6.3985 - val_accuracy: 0.0000e+00\n",
            "Epoch 234/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 5.7834 - accuracy: 0.0179 - val_loss: 6.3978 - val_accuracy: 0.0000e+00\n",
            "Epoch 235/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 5.7803 - accuracy: 0.0179 - val_loss: 6.3975 - val_accuracy: 0.0000e+00\n",
            "Epoch 236/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 5.7773 - accuracy: 0.0170 - val_loss: 6.3975 - val_accuracy: 0.0000e+00\n",
            "Epoch 237/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 5.7741 - accuracy: 0.0188 - val_loss: 6.3976 - val_accuracy: 0.0000e+00\n",
            "Epoch 238/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 5.7709 - accuracy: 0.0196 - val_loss: 6.3969 - val_accuracy: 0.0000e+00\n",
            "Epoch 239/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 5.7676 - accuracy: 0.0196 - val_loss: 6.3963 - val_accuracy: 0.0000e+00\n",
            "Epoch 240/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 5.7644 - accuracy: 0.0196 - val_loss: 6.3960 - val_accuracy: 0.0000e+00\n",
            "Epoch 241/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 5.7608 - accuracy: 0.0205 - val_loss: 6.3959 - val_accuracy: 0.0000e+00\n",
            "Epoch 242/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 5.7577 - accuracy: 0.0196 - val_loss: 6.3955 - val_accuracy: 0.0000e+00\n",
            "Epoch 243/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 5.7542 - accuracy: 0.0196 - val_loss: 6.3954 - val_accuracy: 0.0000e+00\n",
            "Epoch 244/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 5.7506 - accuracy: 0.0205 - val_loss: 6.3958 - val_accuracy: 0.0000e+00\n",
            "Epoch 245/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 5.7471 - accuracy: 0.0196 - val_loss: 6.3947 - val_accuracy: 0.0000e+00\n",
            "Epoch 246/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 5.7436 - accuracy: 0.0205 - val_loss: 6.3940 - val_accuracy: 0.0000e+00\n",
            "Epoch 247/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 5.7400 - accuracy: 0.0196 - val_loss: 6.3937 - val_accuracy: 0.0000e+00\n",
            "Epoch 248/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 5.7363 - accuracy: 0.0196 - val_loss: 6.3931 - val_accuracy: 0.0000e+00\n",
            "Epoch 249/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 5.7327 - accuracy: 0.0196 - val_loss: 6.3913 - val_accuracy: 0.0000e+00\n",
            "Epoch 250/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 5.7289 - accuracy: 0.0196 - val_loss: 6.3903 - val_accuracy: 0.0000e+00\n",
            "Epoch 251/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 5.7251 - accuracy: 0.0196 - val_loss: 6.3897 - val_accuracy: 0.0000e+00\n",
            "Epoch 252/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 5.7213 - accuracy: 0.0179 - val_loss: 6.3889 - val_accuracy: 0.0000e+00\n",
            "Epoch 253/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 5.7172 - accuracy: 0.0223 - val_loss: 6.3881 - val_accuracy: 0.0000e+00\n",
            "Epoch 254/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 5.7135 - accuracy: 0.0205 - val_loss: 6.3881 - val_accuracy: 0.0000e+00\n",
            "Epoch 255/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 5.7094 - accuracy: 0.0196 - val_loss: 6.3870 - val_accuracy: 0.0000e+00\n",
            "Epoch 256/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 5.7052 - accuracy: 0.0214 - val_loss: 6.3854 - val_accuracy: 0.0000e+00\n",
            "Epoch 257/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 5.7012 - accuracy: 0.0205 - val_loss: 6.3845 - val_accuracy: 0.0000e+00\n",
            "Epoch 258/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 5.6969 - accuracy: 0.0214 - val_loss: 6.3842 - val_accuracy: 0.0000e+00\n",
            "Epoch 259/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 5.6926 - accuracy: 0.0214 - val_loss: 6.3840 - val_accuracy: 0.0000e+00\n",
            "Epoch 260/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 5.6883 - accuracy: 0.0196 - val_loss: 6.3836 - val_accuracy: 0.0000e+00\n",
            "Epoch 261/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 5.6842 - accuracy: 0.0205 - val_loss: 6.3836 - val_accuracy: 0.0000e+00\n",
            "Epoch 262/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 5.6794 - accuracy: 0.0214 - val_loss: 6.3820 - val_accuracy: 0.0000e+00\n",
            "Epoch 263/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 5.6752 - accuracy: 0.0223 - val_loss: 6.3814 - val_accuracy: 0.0000e+00\n",
            "Epoch 264/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 5.6706 - accuracy: 0.0214 - val_loss: 6.3799 - val_accuracy: 0.0000e+00\n",
            "Epoch 265/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 5.6660 - accuracy: 0.0205 - val_loss: 6.3788 - val_accuracy: 0.0000e+00\n",
            "Epoch 266/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 5.6615 - accuracy: 0.0232 - val_loss: 6.3769 - val_accuracy: 0.0000e+00\n",
            "Epoch 267/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 5.6566 - accuracy: 0.0232 - val_loss: 6.3762 - val_accuracy: 0.0000e+00\n",
            "Epoch 268/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 5.6517 - accuracy: 0.0259 - val_loss: 6.3752 - val_accuracy: 0.0000e+00\n",
            "Epoch 269/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 5.6471 - accuracy: 0.0268 - val_loss: 6.3744 - val_accuracy: 0.0000e+00\n",
            "Epoch 270/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 5.6420 - accuracy: 0.0286 - val_loss: 6.3732 - val_accuracy: 0.0000e+00\n",
            "Epoch 271/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 5.6366 - accuracy: 0.0268 - val_loss: 6.3728 - val_accuracy: 0.0000e+00\n",
            "Epoch 272/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 5.6317 - accuracy: 0.0295 - val_loss: 6.3713 - val_accuracy: 0.0000e+00\n",
            "Epoch 273/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 5.6266 - accuracy: 0.0277 - val_loss: 6.3714 - val_accuracy: 0.0000e+00\n",
            "Epoch 274/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 5.6214 - accuracy: 0.0277 - val_loss: 6.3705 - val_accuracy: 0.0000e+00\n",
            "Epoch 275/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 5.6160 - accuracy: 0.0304 - val_loss: 6.3692 - val_accuracy: 0.0000e+00\n",
            "Epoch 276/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 5.6106 - accuracy: 0.0312 - val_loss: 6.3685 - val_accuracy: 0.0000e+00\n",
            "Epoch 277/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 5.6055 - accuracy: 0.0286 - val_loss: 6.3659 - val_accuracy: 0.0000e+00\n",
            "Epoch 278/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 5.5997 - accuracy: 0.0295 - val_loss: 6.3643 - val_accuracy: 0.0000e+00\n",
            "Epoch 279/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 5.5946 - accuracy: 0.0277 - val_loss: 6.3627 - val_accuracy: 0.0000e+00\n",
            "Epoch 280/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 5.5889 - accuracy: 0.0312 - val_loss: 6.3615 - val_accuracy: 0.0000e+00\n",
            "Epoch 281/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 5.5832 - accuracy: 0.0295 - val_loss: 6.3597 - val_accuracy: 0.0000e+00\n",
            "Epoch 282/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 5.5776 - accuracy: 0.0304 - val_loss: 6.3576 - val_accuracy: 0.0000e+00\n",
            "Epoch 283/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 5.5716 - accuracy: 0.0321 - val_loss: 6.3562 - val_accuracy: 0.0000e+00\n",
            "Epoch 284/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 5.5658 - accuracy: 0.0304 - val_loss: 6.3541 - val_accuracy: 0.0000e+00\n",
            "Epoch 285/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 5.5596 - accuracy: 0.0295 - val_loss: 6.3518 - val_accuracy: 0.0000e+00\n",
            "Epoch 286/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 5.5538 - accuracy: 0.0321 - val_loss: 6.3508 - val_accuracy: 0.0000e+00\n",
            "Epoch 287/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 5.5477 - accuracy: 0.0286 - val_loss: 6.3498 - val_accuracy: 0.0000e+00\n",
            "Epoch 288/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 5.5415 - accuracy: 0.0304 - val_loss: 6.3489 - val_accuracy: 0.0000e+00\n",
            "Epoch 289/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 5.5349 - accuracy: 0.0304 - val_loss: 6.3460 - val_accuracy: 0.0000e+00\n",
            "Epoch 290/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 5.5290 - accuracy: 0.0295 - val_loss: 6.3436 - val_accuracy: 0.0000e+00\n",
            "Epoch 291/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 5.5223 - accuracy: 0.0321 - val_loss: 6.3425 - val_accuracy: 0.0000e+00\n",
            "Epoch 292/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 5.5157 - accuracy: 0.0330 - val_loss: 6.3406 - val_accuracy: 0.0000e+00\n",
            "Epoch 293/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 5.5094 - accuracy: 0.0295 - val_loss: 6.3385 - val_accuracy: 0.0000e+00\n",
            "Epoch 294/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 5.5027 - accuracy: 0.0312 - val_loss: 6.3372 - val_accuracy: 0.0000e+00\n",
            "Epoch 295/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 5.4958 - accuracy: 0.0304 - val_loss: 6.3357 - val_accuracy: 0.0000e+00\n",
            "Epoch 296/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 5.4893 - accuracy: 0.0321 - val_loss: 6.3332 - val_accuracy: 0.0000e+00\n",
            "Epoch 297/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 5.4823 - accuracy: 0.0339 - val_loss: 6.3324 - val_accuracy: 0.0000e+00\n",
            "Epoch 298/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 5.4754 - accuracy: 0.0348 - val_loss: 6.3301 - val_accuracy: 0.0000e+00\n",
            "Epoch 299/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 5.4686 - accuracy: 0.0330 - val_loss: 6.3278 - val_accuracy: 0.0000e+00\n",
            "Epoch 300/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 5.4614 - accuracy: 0.0321 - val_loss: 6.3242 - val_accuracy: 0.0000e+00\n",
            "Epoch 301/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 5.4541 - accuracy: 0.0348 - val_loss: 6.3220 - val_accuracy: 0.0036\n",
            "Epoch 302/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 5.4471 - accuracy: 0.0348 - val_loss: 6.3193 - val_accuracy: 0.0036\n",
            "Epoch 303/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 5.4397 - accuracy: 0.0366 - val_loss: 6.3180 - val_accuracy: 0.0036\n",
            "Epoch 304/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 5.4325 - accuracy: 0.0384 - val_loss: 6.3172 - val_accuracy: 0.0036\n",
            "Epoch 305/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 5.4249 - accuracy: 0.0375 - val_loss: 6.3144 - val_accuracy: 0.0036\n",
            "Epoch 306/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 5.4180 - accuracy: 0.0393 - val_loss: 6.3128 - val_accuracy: 0.0036\n",
            "Epoch 307/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 5.4100 - accuracy: 0.0402 - val_loss: 6.3104 - val_accuracy: 0.0036\n",
            "Epoch 308/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 5.4022 - accuracy: 0.0420 - val_loss: 6.3078 - val_accuracy: 0.0036\n",
            "Epoch 309/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 5.3948 - accuracy: 0.0420 - val_loss: 6.3048 - val_accuracy: 0.0036\n",
            "Epoch 310/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 5.3870 - accuracy: 0.0429 - val_loss: 6.3025 - val_accuracy: 0.0036\n",
            "Epoch 311/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 5.3790 - accuracy: 0.0402 - val_loss: 6.3015 - val_accuracy: 0.0036\n",
            "Epoch 312/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 5.3712 - accuracy: 0.0402 - val_loss: 6.2987 - val_accuracy: 0.0036\n",
            "Epoch 313/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 5.3632 - accuracy: 0.0411 - val_loss: 6.2965 - val_accuracy: 0.0036\n",
            "Epoch 314/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 5.3552 - accuracy: 0.0411 - val_loss: 6.2942 - val_accuracy: 0.0036\n",
            "Epoch 315/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 5.3469 - accuracy: 0.0384 - val_loss: 6.2921 - val_accuracy: 0.0036\n",
            "Epoch 316/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 5.3388 - accuracy: 0.0402 - val_loss: 6.2897 - val_accuracy: 0.0036\n",
            "Epoch 317/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 5.3303 - accuracy: 0.0366 - val_loss: 6.2888 - val_accuracy: 0.0036\n",
            "Epoch 318/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 5.3218 - accuracy: 0.0437 - val_loss: 6.2868 - val_accuracy: 0.0036\n",
            "Epoch 319/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 5.3137 - accuracy: 0.0402 - val_loss: 6.2848 - val_accuracy: 0.0036\n",
            "Epoch 320/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 5.3051 - accuracy: 0.0420 - val_loss: 6.2820 - val_accuracy: 0.0036\n",
            "Epoch 321/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 5.2965 - accuracy: 0.0402 - val_loss: 6.2793 - val_accuracy: 0.0036\n",
            "Epoch 322/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 5.2877 - accuracy: 0.0429 - val_loss: 6.2768 - val_accuracy: 0.0036\n",
            "Epoch 323/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 5.2792 - accuracy: 0.0455 - val_loss: 6.2738 - val_accuracy: 0.0036\n",
            "Epoch 324/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 5.2703 - accuracy: 0.0455 - val_loss: 6.2708 - val_accuracy: 0.0036\n",
            "Epoch 325/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 5.2617 - accuracy: 0.0446 - val_loss: 6.2680 - val_accuracy: 0.0000e+00\n",
            "Epoch 326/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 5.2531 - accuracy: 0.0429 - val_loss: 6.2648 - val_accuracy: 0.0000e+00\n",
            "Epoch 327/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 5.2441 - accuracy: 0.0455 - val_loss: 6.2618 - val_accuracy: 0.0000e+00\n",
            "Epoch 328/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 5.2351 - accuracy: 0.0464 - val_loss: 6.2587 - val_accuracy: 0.0036\n",
            "Epoch 329/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 5.2263 - accuracy: 0.0455 - val_loss: 6.2575 - val_accuracy: 0.0036\n",
            "Epoch 330/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 5.2171 - accuracy: 0.0491 - val_loss: 6.2541 - val_accuracy: 0.0036\n",
            "Epoch 331/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 5.2076 - accuracy: 0.0491 - val_loss: 6.2521 - val_accuracy: 0.0036\n",
            "Epoch 332/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 5.1986 - accuracy: 0.0509 - val_loss: 6.2492 - val_accuracy: 0.0036\n",
            "Epoch 333/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 5.1891 - accuracy: 0.0518 - val_loss: 6.2462 - val_accuracy: 0.0036\n",
            "Epoch 334/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 5.1802 - accuracy: 0.0562 - val_loss: 6.2441 - val_accuracy: 0.0036\n",
            "Epoch 335/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 5.1703 - accuracy: 0.0518 - val_loss: 6.2427 - val_accuracy: 0.0036\n",
            "Epoch 336/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 5.1610 - accuracy: 0.0509 - val_loss: 6.2391 - val_accuracy: 0.0036\n",
            "Epoch 337/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 5.1517 - accuracy: 0.0545 - val_loss: 6.2367 - val_accuracy: 0.0036\n",
            "Epoch 338/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 5.1420 - accuracy: 0.0509 - val_loss: 6.2343 - val_accuracy: 0.0071\n",
            "Epoch 339/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 5.1326 - accuracy: 0.0545 - val_loss: 6.2324 - val_accuracy: 0.0036\n",
            "Epoch 340/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 5.1231 - accuracy: 0.0500 - val_loss: 6.2281 - val_accuracy: 0.0036\n",
            "Epoch 341/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 5.1129 - accuracy: 0.0518 - val_loss: 6.2255 - val_accuracy: 0.0071\n",
            "Epoch 342/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 5.1034 - accuracy: 0.0545 - val_loss: 6.2207 - val_accuracy: 0.0071\n",
            "Epoch 343/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 5.0936 - accuracy: 0.0554 - val_loss: 6.2166 - val_accuracy: 0.0107\n",
            "Epoch 344/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 5.0839 - accuracy: 0.0536 - val_loss: 6.2142 - val_accuracy: 0.0107\n",
            "Epoch 345/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 5.0736 - accuracy: 0.0536 - val_loss: 6.2107 - val_accuracy: 0.0107\n",
            "Epoch 346/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 5.0638 - accuracy: 0.0625 - val_loss: 6.2098 - val_accuracy: 0.0071\n",
            "Epoch 347/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 5.0536 - accuracy: 0.0562 - val_loss: 6.2070 - val_accuracy: 0.0107\n",
            "Epoch 348/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 5.0434 - accuracy: 0.0607 - val_loss: 6.2027 - val_accuracy: 0.0143\n",
            "Epoch 349/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 5.0331 - accuracy: 0.0634 - val_loss: 6.1994 - val_accuracy: 0.0143\n",
            "Epoch 350/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 5.0231 - accuracy: 0.0652 - val_loss: 6.1973 - val_accuracy: 0.0143\n",
            "Epoch 351/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 5.0130 - accuracy: 0.0661 - val_loss: 6.1936 - val_accuracy: 0.0143\n",
            "Epoch 352/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 5.0025 - accuracy: 0.0714 - val_loss: 6.1917 - val_accuracy: 0.0143\n",
            "Epoch 353/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 4.9922 - accuracy: 0.0670 - val_loss: 6.1882 - val_accuracy: 0.0143\n",
            "Epoch 354/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 4.9817 - accuracy: 0.0679 - val_loss: 6.1837 - val_accuracy: 0.0143\n",
            "Epoch 355/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 4.9714 - accuracy: 0.0688 - val_loss: 6.1799 - val_accuracy: 0.0143\n",
            "Epoch 356/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 4.9614 - accuracy: 0.0661 - val_loss: 6.1774 - val_accuracy: 0.0143\n",
            "Epoch 357/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 4.9504 - accuracy: 0.0705 - val_loss: 6.1736 - val_accuracy: 0.0143\n",
            "Epoch 358/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 4.9396 - accuracy: 0.0750 - val_loss: 6.1697 - val_accuracy: 0.0143\n",
            "Epoch 359/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 4.9296 - accuracy: 0.0688 - val_loss: 6.1667 - val_accuracy: 0.0143\n",
            "Epoch 360/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 4.9187 - accuracy: 0.0732 - val_loss: 6.1668 - val_accuracy: 0.0143\n",
            "Epoch 361/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 4.9080 - accuracy: 0.0723 - val_loss: 6.1638 - val_accuracy: 0.0143\n",
            "Epoch 362/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 4.8970 - accuracy: 0.0723 - val_loss: 6.1594 - val_accuracy: 0.0107\n",
            "Epoch 363/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 4.8857 - accuracy: 0.0741 - val_loss: 6.1562 - val_accuracy: 0.0107\n",
            "Epoch 364/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 4.8758 - accuracy: 0.0759 - val_loss: 6.1507 - val_accuracy: 0.0107\n",
            "Epoch 365/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 4.8649 - accuracy: 0.0795 - val_loss: 6.1487 - val_accuracy: 0.0143\n",
            "Epoch 366/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 4.8539 - accuracy: 0.0830 - val_loss: 6.1453 - val_accuracy: 0.0143\n",
            "Epoch 367/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 4.8430 - accuracy: 0.0804 - val_loss: 6.1430 - val_accuracy: 0.0143\n",
            "Epoch 368/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 4.8322 - accuracy: 0.0777 - val_loss: 6.1372 - val_accuracy: 0.0143\n",
            "Epoch 369/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 4.8210 - accuracy: 0.0866 - val_loss: 6.1364 - val_accuracy: 0.0214\n",
            "Epoch 370/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 4.8100 - accuracy: 0.0857 - val_loss: 6.1307 - val_accuracy: 0.0214\n",
            "Epoch 371/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 4.7984 - accuracy: 0.0857 - val_loss: 6.1244 - val_accuracy: 0.0143\n",
            "Epoch 372/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 4.7876 - accuracy: 0.0884 - val_loss: 6.1234 - val_accuracy: 0.0214\n",
            "Epoch 373/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 4.7759 - accuracy: 0.0902 - val_loss: 6.1202 - val_accuracy: 0.0214\n",
            "Epoch 374/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 4.7650 - accuracy: 0.0866 - val_loss: 6.1179 - val_accuracy: 0.0214\n",
            "Epoch 375/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 4.7538 - accuracy: 0.0884 - val_loss: 6.1151 - val_accuracy: 0.0214\n",
            "Epoch 376/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 4.7430 - accuracy: 0.0929 - val_loss: 6.1089 - val_accuracy: 0.0214\n",
            "Epoch 377/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 4.7305 - accuracy: 0.0938 - val_loss: 6.1019 - val_accuracy: 0.0214\n",
            "Epoch 378/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 4.7194 - accuracy: 0.1000 - val_loss: 6.0996 - val_accuracy: 0.0214\n",
            "Epoch 379/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 4.7088 - accuracy: 0.0964 - val_loss: 6.0953 - val_accuracy: 0.0214\n",
            "Epoch 380/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 4.6964 - accuracy: 0.1000 - val_loss: 6.0940 - val_accuracy: 0.0214\n",
            "Epoch 381/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 4.6850 - accuracy: 0.0973 - val_loss: 6.0906 - val_accuracy: 0.0214\n",
            "Epoch 382/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 4.6728 - accuracy: 0.1054 - val_loss: 6.0869 - val_accuracy: 0.0214\n",
            "Epoch 383/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 4.6624 - accuracy: 0.1036 - val_loss: 6.0855 - val_accuracy: 0.0214\n",
            "Epoch 384/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 4.6503 - accuracy: 0.1000 - val_loss: 6.0782 - val_accuracy: 0.0214\n",
            "Epoch 385/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 4.6386 - accuracy: 0.1036 - val_loss: 6.0733 - val_accuracy: 0.0214\n",
            "Epoch 386/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 4.6274 - accuracy: 0.1080 - val_loss: 6.0720 - val_accuracy: 0.0214\n",
            "Epoch 387/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 4.6158 - accuracy: 0.1063 - val_loss: 6.0664 - val_accuracy: 0.0214\n",
            "Epoch 388/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 4.6036 - accuracy: 0.1089 - val_loss: 6.0626 - val_accuracy: 0.0214\n",
            "Epoch 389/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 4.5923 - accuracy: 0.1054 - val_loss: 6.0583 - val_accuracy: 0.0214\n",
            "Epoch 390/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 4.5799 - accuracy: 0.1089 - val_loss: 6.0559 - val_accuracy: 0.0214\n",
            "Epoch 391/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 4.5678 - accuracy: 0.1080 - val_loss: 6.0534 - val_accuracy: 0.0214\n",
            "Epoch 392/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 4.5562 - accuracy: 0.1107 - val_loss: 6.0458 - val_accuracy: 0.0214\n",
            "Epoch 393/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 4.5441 - accuracy: 0.1089 - val_loss: 6.0428 - val_accuracy: 0.0214\n",
            "Epoch 394/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 4.5326 - accuracy: 0.1143 - val_loss: 6.0402 - val_accuracy: 0.0214\n",
            "Epoch 395/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 4.5202 - accuracy: 0.1187 - val_loss: 6.0370 - val_accuracy: 0.0214\n",
            "Epoch 396/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 4.5088 - accuracy: 0.1170 - val_loss: 6.0334 - val_accuracy: 0.0214\n",
            "Epoch 397/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 4.4964 - accuracy: 0.1259 - val_loss: 6.0286 - val_accuracy: 0.0250\n",
            "Epoch 398/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 4.4843 - accuracy: 0.1179 - val_loss: 6.0266 - val_accuracy: 0.0286\n",
            "Epoch 399/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 4.4724 - accuracy: 0.1205 - val_loss: 6.0227 - val_accuracy: 0.0286\n",
            "Epoch 400/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 4.4608 - accuracy: 0.1277 - val_loss: 6.0206 - val_accuracy: 0.0321\n",
            "Epoch 401/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 4.4480 - accuracy: 0.1286 - val_loss: 6.0196 - val_accuracy: 0.0321\n",
            "Epoch 402/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 4.4365 - accuracy: 0.1241 - val_loss: 6.0186 - val_accuracy: 0.0321\n",
            "Epoch 403/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 4.4238 - accuracy: 0.1250 - val_loss: 6.0142 - val_accuracy: 0.0321\n",
            "Epoch 404/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 4.4117 - accuracy: 0.1277 - val_loss: 6.0109 - val_accuracy: 0.0321\n",
            "Epoch 405/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 4.3997 - accuracy: 0.1277 - val_loss: 6.0079 - val_accuracy: 0.0321\n",
            "Epoch 406/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 4.3872 - accuracy: 0.1268 - val_loss: 5.9996 - val_accuracy: 0.0321\n",
            "Epoch 407/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 4.3748 - accuracy: 0.1250 - val_loss: 5.9971 - val_accuracy: 0.0321\n",
            "Epoch 408/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 4.3626 - accuracy: 0.1357 - val_loss: 5.9944 - val_accuracy: 0.0321\n",
            "Epoch 409/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 4.3510 - accuracy: 0.1437 - val_loss: 5.9916 - val_accuracy: 0.0286\n",
            "Epoch 410/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 4.3386 - accuracy: 0.1375 - val_loss: 5.9918 - val_accuracy: 0.0286\n",
            "Epoch 411/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 4.3266 - accuracy: 0.1375 - val_loss: 5.9865 - val_accuracy: 0.0286\n",
            "Epoch 412/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 4.3142 - accuracy: 0.1446 - val_loss: 5.9770 - val_accuracy: 0.0286\n",
            "Epoch 413/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 4.3024 - accuracy: 0.1384 - val_loss: 5.9774 - val_accuracy: 0.0286\n",
            "Epoch 414/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 4.2896 - accuracy: 0.1357 - val_loss: 5.9759 - val_accuracy: 0.0286\n",
            "Epoch 415/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 4.2773 - accuracy: 0.1437 - val_loss: 5.9721 - val_accuracy: 0.0321\n",
            "Epoch 416/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 4.2656 - accuracy: 0.1473 - val_loss: 5.9689 - val_accuracy: 0.0321\n",
            "Epoch 417/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 4.2539 - accuracy: 0.1455 - val_loss: 5.9631 - val_accuracy: 0.0321\n",
            "Epoch 418/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 4.2417 - accuracy: 0.1446 - val_loss: 5.9632 - val_accuracy: 0.0321\n",
            "Epoch 419/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 4.2291 - accuracy: 0.1473 - val_loss: 5.9605 - val_accuracy: 0.0321\n",
            "Epoch 420/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 4.2169 - accuracy: 0.1473 - val_loss: 5.9579 - val_accuracy: 0.0321\n",
            "Epoch 421/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 4.2037 - accuracy: 0.1393 - val_loss: 5.9524 - val_accuracy: 0.0321\n",
            "Epoch 422/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 4.1908 - accuracy: 0.1571 - val_loss: 5.9508 - val_accuracy: 0.0321\n",
            "Epoch 423/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 4.1801 - accuracy: 0.1545 - val_loss: 5.9457 - val_accuracy: 0.0321\n",
            "Epoch 424/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 4.1668 - accuracy: 0.1491 - val_loss: 5.9418 - val_accuracy: 0.0357\n",
            "Epoch 425/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 4.1564 - accuracy: 0.1545 - val_loss: 5.9430 - val_accuracy: 0.0250\n",
            "Epoch 426/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 4.1436 - accuracy: 0.1491 - val_loss: 5.9446 - val_accuracy: 0.0250\n",
            "Epoch 427/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 4.1310 - accuracy: 0.1500 - val_loss: 5.9406 - val_accuracy: 0.0250\n",
            "Epoch 428/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 4.1186 - accuracy: 0.1464 - val_loss: 5.9326 - val_accuracy: 0.0321\n",
            "Epoch 429/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 4.1067 - accuracy: 0.1473 - val_loss: 5.9274 - val_accuracy: 0.0321\n",
            "Epoch 430/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 4.0941 - accuracy: 0.1562 - val_loss: 5.9264 - val_accuracy: 0.0321\n",
            "Epoch 431/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 4.0809 - accuracy: 0.1527 - val_loss: 5.9266 - val_accuracy: 0.0429\n",
            "Epoch 432/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 4.0697 - accuracy: 0.1509 - val_loss: 5.9208 - val_accuracy: 0.0357\n",
            "Epoch 433/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 4.0582 - accuracy: 0.1580 - val_loss: 5.9192 - val_accuracy: 0.0321\n",
            "Epoch 434/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 4.0458 - accuracy: 0.1580 - val_loss: 5.9141 - val_accuracy: 0.0321\n",
            "Epoch 435/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 4.0322 - accuracy: 0.1625 - val_loss: 5.9082 - val_accuracy: 0.0321\n",
            "Epoch 436/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 4.0202 - accuracy: 0.1598 - val_loss: 5.9058 - val_accuracy: 0.0321\n",
            "Epoch 437/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 4.0094 - accuracy: 0.1607 - val_loss: 5.9064 - val_accuracy: 0.0321\n",
            "Epoch 438/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 3.9974 - accuracy: 0.1705 - val_loss: 5.9124 - val_accuracy: 0.0250\n",
            "Epoch 439/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 3.9857 - accuracy: 0.1545 - val_loss: 5.9059 - val_accuracy: 0.0250\n",
            "Epoch 440/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 3.9736 - accuracy: 0.1634 - val_loss: 5.9045 - val_accuracy: 0.0321\n",
            "Epoch 441/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 3.9624 - accuracy: 0.1670 - val_loss: 5.9057 - val_accuracy: 0.0321\n",
            "Epoch 442/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 3.9487 - accuracy: 0.1661 - val_loss: 5.9022 - val_accuracy: 0.0321\n",
            "Epoch 443/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 3.9373 - accuracy: 0.1696 - val_loss: 5.9017 - val_accuracy: 0.0357\n",
            "Epoch 444/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 3.9257 - accuracy: 0.1759 - val_loss: 5.8996 - val_accuracy: 0.0321\n",
            "Epoch 445/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 3.9130 - accuracy: 0.1705 - val_loss: 5.8932 - val_accuracy: 0.0393\n",
            "Epoch 446/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 3.9012 - accuracy: 0.1750 - val_loss: 5.8895 - val_accuracy: 0.0357\n",
            "Epoch 447/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 3.8884 - accuracy: 0.1750 - val_loss: 5.8874 - val_accuracy: 0.0393\n",
            "Epoch 448/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 3.8775 - accuracy: 0.1786 - val_loss: 5.8856 - val_accuracy: 0.0429\n",
            "Epoch 449/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 3.8672 - accuracy: 0.1759 - val_loss: 5.8916 - val_accuracy: 0.0429\n",
            "Epoch 450/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 3.8545 - accuracy: 0.1839 - val_loss: 5.8872 - val_accuracy: 0.0393\n",
            "Epoch 451/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 3.8418 - accuracy: 0.1750 - val_loss: 5.8886 - val_accuracy: 0.0357\n",
            "Epoch 452/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 3.8309 - accuracy: 0.1786 - val_loss: 5.8882 - val_accuracy: 0.0321\n",
            "Epoch 453/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 3.8198 - accuracy: 0.1777 - val_loss: 5.8957 - val_accuracy: 0.0321\n",
            "Epoch 454/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 3.8098 - accuracy: 0.1679 - val_loss: 5.8924 - val_accuracy: 0.0357\n",
            "Epoch 455/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 3.7969 - accuracy: 0.1795 - val_loss: 5.8802 - val_accuracy: 0.0321\n",
            "Epoch 456/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 3.7852 - accuracy: 0.1786 - val_loss: 5.8885 - val_accuracy: 0.0357\n",
            "Epoch 457/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 3.7719 - accuracy: 0.1786 - val_loss: 5.8876 - val_accuracy: 0.0321\n",
            "Epoch 458/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 3.7620 - accuracy: 0.1813 - val_loss: 5.8807 - val_accuracy: 0.0321\n",
            "Epoch 459/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 3.7514 - accuracy: 0.1768 - val_loss: 5.8747 - val_accuracy: 0.0321\n",
            "Epoch 460/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 3.7391 - accuracy: 0.1857 - val_loss: 5.8723 - val_accuracy: 0.0357\n",
            "Epoch 461/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 3.7269 - accuracy: 0.1866 - val_loss: 5.8779 - val_accuracy: 0.0429\n",
            "Epoch 462/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 3.7161 - accuracy: 0.1830 - val_loss: 5.8756 - val_accuracy: 0.0357\n",
            "Epoch 463/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 3.7037 - accuracy: 0.1911 - val_loss: 5.8785 - val_accuracy: 0.0321\n",
            "Epoch 464/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 3.6935 - accuracy: 0.1946 - val_loss: 5.8771 - val_accuracy: 0.0429\n",
            "Epoch 465/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 3.6830 - accuracy: 0.1929 - val_loss: 5.8818 - val_accuracy: 0.0429\n",
            "Epoch 466/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 3.6708 - accuracy: 0.1973 - val_loss: 5.8787 - val_accuracy: 0.0429\n",
            "Epoch 467/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 3.6589 - accuracy: 0.1911 - val_loss: 5.8733 - val_accuracy: 0.0464\n",
            "Epoch 468/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 3.6498 - accuracy: 0.1946 - val_loss: 5.8667 - val_accuracy: 0.0429\n",
            "Epoch 469/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 3.6386 - accuracy: 0.1893 - val_loss: 5.8662 - val_accuracy: 0.0429\n",
            "Epoch 470/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 3.6274 - accuracy: 0.1893 - val_loss: 5.8675 - val_accuracy: 0.0536\n",
            "Epoch 471/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 3.6154 - accuracy: 0.1920 - val_loss: 5.8562 - val_accuracy: 0.0571\n",
            "Epoch 472/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 3.6034 - accuracy: 0.2000 - val_loss: 5.8629 - val_accuracy: 0.0500\n",
            "Epoch 473/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 3.5948 - accuracy: 0.1964 - val_loss: 5.8687 - val_accuracy: 0.0429\n",
            "Epoch 474/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 3.5851 - accuracy: 0.1875 - val_loss: 5.8602 - val_accuracy: 0.0464\n",
            "Epoch 475/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 3.5707 - accuracy: 0.2071 - val_loss: 5.8683 - val_accuracy: 0.0500\n",
            "Epoch 476/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 3.5625 - accuracy: 0.2018 - val_loss: 5.8604 - val_accuracy: 0.0536\n",
            "Epoch 477/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 3.5507 - accuracy: 0.2036 - val_loss: 5.8662 - val_accuracy: 0.0429\n",
            "Epoch 478/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 3.5412 - accuracy: 0.1946 - val_loss: 5.8627 - val_accuracy: 0.0536\n",
            "Epoch 479/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 3.5300 - accuracy: 0.1955 - val_loss: 5.8647 - val_accuracy: 0.0536\n",
            "Epoch 480/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 3.5201 - accuracy: 0.1937 - val_loss: 5.8608 - val_accuracy: 0.0500\n",
            "Epoch 481/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 3.5109 - accuracy: 0.2071 - val_loss: 5.8607 - val_accuracy: 0.0607\n",
            "Epoch 482/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 3.5007 - accuracy: 0.2018 - val_loss: 5.8845 - val_accuracy: 0.0500\n",
            "Epoch 483/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 3.4900 - accuracy: 0.1982 - val_loss: 5.8747 - val_accuracy: 0.0500\n",
            "Epoch 484/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 3.4778 - accuracy: 0.2143 - val_loss: 5.8788 - val_accuracy: 0.0536\n",
            "Epoch 485/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 3.4675 - accuracy: 0.2062 - val_loss: 5.8833 - val_accuracy: 0.0607\n",
            "Epoch 486/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 3.4583 - accuracy: 0.2036 - val_loss: 5.8814 - val_accuracy: 0.0679\n",
            "Epoch 487/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 3.4512 - accuracy: 0.2125 - val_loss: 5.8817 - val_accuracy: 0.0571\n",
            "Epoch 488/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 3.4393 - accuracy: 0.2071 - val_loss: 5.8861 - val_accuracy: 0.0607\n",
            "Epoch 489/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 3.4289 - accuracy: 0.2098 - val_loss: 5.8897 - val_accuracy: 0.0571\n",
            "Epoch 490/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 3.4204 - accuracy: 0.2179 - val_loss: 5.8881 - val_accuracy: 0.0536\n",
            "Epoch 491/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 3.4104 - accuracy: 0.2232 - val_loss: 5.8879 - val_accuracy: 0.0571\n",
            "Epoch 492/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 3.3996 - accuracy: 0.2188 - val_loss: 5.8802 - val_accuracy: 0.0643\n",
            "Epoch 493/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 3.3898 - accuracy: 0.2259 - val_loss: 5.8785 - val_accuracy: 0.0607\n",
            "Epoch 494/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 3.3814 - accuracy: 0.2161 - val_loss: 5.8779 - val_accuracy: 0.0536\n",
            "Epoch 495/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 3.3692 - accuracy: 0.2161 - val_loss: 5.8901 - val_accuracy: 0.0571\n",
            "Epoch 496/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 3.3609 - accuracy: 0.2179 - val_loss: 5.9075 - val_accuracy: 0.0571\n",
            "Epoch 497/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 3.3523 - accuracy: 0.2196 - val_loss: 5.8843 - val_accuracy: 0.0607\n",
            "Epoch 498/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 3.3393 - accuracy: 0.2214 - val_loss: 5.8827 - val_accuracy: 0.0571\n",
            "Epoch 499/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 3.3314 - accuracy: 0.2170 - val_loss: 5.8896 - val_accuracy: 0.0536\n",
            "Epoch 500/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 3.3275 - accuracy: 0.2089 - val_loss: 5.8963 - val_accuracy: 0.0607\n",
            "Epoch 501/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 3.3146 - accuracy: 0.2134 - val_loss: 5.8896 - val_accuracy: 0.0500\n",
            "Epoch 502/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 3.3041 - accuracy: 0.2259 - val_loss: 5.9046 - val_accuracy: 0.0607\n",
            "Epoch 503/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 3.2961 - accuracy: 0.2223 - val_loss: 5.9040 - val_accuracy: 0.0571\n",
            "Epoch 504/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 3.2859 - accuracy: 0.2339 - val_loss: 5.9011 - val_accuracy: 0.0607\n",
            "Epoch 505/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 3.2767 - accuracy: 0.2313 - val_loss: 5.9108 - val_accuracy: 0.0643\n",
            "Epoch 506/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 3.2666 - accuracy: 0.2420 - val_loss: 5.9091 - val_accuracy: 0.0714\n",
            "Epoch 507/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 3.2604 - accuracy: 0.2277 - val_loss: 5.9120 - val_accuracy: 0.0607\n",
            "Epoch 508/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 3.2531 - accuracy: 0.2330 - val_loss: 5.9080 - val_accuracy: 0.0607\n",
            "Epoch 509/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 3.2404 - accuracy: 0.2366 - val_loss: 5.9192 - val_accuracy: 0.0750\n",
            "Epoch 510/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 3.2323 - accuracy: 0.2321 - val_loss: 5.9164 - val_accuracy: 0.0714\n",
            "Epoch 511/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 3.2238 - accuracy: 0.2339 - val_loss: 5.9058 - val_accuracy: 0.0893\n",
            "Epoch 512/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 3.2151 - accuracy: 0.2357 - val_loss: 5.9125 - val_accuracy: 0.0679\n",
            "Epoch 513/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 3.2077 - accuracy: 0.2348 - val_loss: 5.9353 - val_accuracy: 0.0679\n",
            "Epoch 514/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 3.1985 - accuracy: 0.2473 - val_loss: 5.9325 - val_accuracy: 0.0643\n",
            "Epoch 515/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 3.1895 - accuracy: 0.2402 - val_loss: 5.9408 - val_accuracy: 0.0679\n",
            "Epoch 516/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 3.1822 - accuracy: 0.2518 - val_loss: 5.9357 - val_accuracy: 0.0679\n",
            "Epoch 517/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 3.1731 - accuracy: 0.2313 - val_loss: 5.9425 - val_accuracy: 0.0714\n",
            "Epoch 518/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 3.1647 - accuracy: 0.2473 - val_loss: 5.9427 - val_accuracy: 0.0571\n",
            "Epoch 519/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 3.1554 - accuracy: 0.2348 - val_loss: 5.9423 - val_accuracy: 0.0643\n",
            "Epoch 520/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 3.1512 - accuracy: 0.2420 - val_loss: 5.9488 - val_accuracy: 0.0893\n",
            "Epoch 521/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 3.1416 - accuracy: 0.2429 - val_loss: 5.9553 - val_accuracy: 0.0714\n",
            "Epoch 522/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 3.1315 - accuracy: 0.2438 - val_loss: 5.9522 - val_accuracy: 0.0750\n",
            "Epoch 523/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 3.1240 - accuracy: 0.2455 - val_loss: 5.9458 - val_accuracy: 0.0750\n",
            "Epoch 524/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 3.1119 - accuracy: 0.2482 - val_loss: 5.9536 - val_accuracy: 0.0750\n",
            "Epoch 525/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 3.1064 - accuracy: 0.2545 - val_loss: 5.9688 - val_accuracy: 0.0714\n",
            "Epoch 526/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 3.1001 - accuracy: 0.2545 - val_loss: 5.9826 - val_accuracy: 0.0786\n",
            "Epoch 527/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 3.0928 - accuracy: 0.2616 - val_loss: 5.9838 - val_accuracy: 0.0786\n",
            "Epoch 528/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 3.0868 - accuracy: 0.2545 - val_loss: 5.9832 - val_accuracy: 0.0714\n",
            "Epoch 529/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 3.0746 - accuracy: 0.2607 - val_loss: 5.9779 - val_accuracy: 0.0679\n",
            "Epoch 530/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 3.0678 - accuracy: 0.2482 - val_loss: 5.9821 - val_accuracy: 0.0643\n",
            "Epoch 531/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 3.0643 - accuracy: 0.2616 - val_loss: 6.0062 - val_accuracy: 0.0786\n",
            "Epoch 532/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 3.0554 - accuracy: 0.2571 - val_loss: 5.9952 - val_accuracy: 0.0821\n",
            "Epoch 533/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 3.0470 - accuracy: 0.2518 - val_loss: 5.9882 - val_accuracy: 0.0786\n",
            "Epoch 534/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 3.0394 - accuracy: 0.2679 - val_loss: 5.9911 - val_accuracy: 0.0786\n",
            "Epoch 535/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 3.0294 - accuracy: 0.2625 - val_loss: 6.0134 - val_accuracy: 0.0750\n",
            "Epoch 536/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 3.0267 - accuracy: 0.2616 - val_loss: 6.0165 - val_accuracy: 0.0679\n",
            "Epoch 537/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 3.0195 - accuracy: 0.2812 - val_loss: 6.0227 - val_accuracy: 0.0821\n",
            "Epoch 538/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 3.0115 - accuracy: 0.2670 - val_loss: 6.0168 - val_accuracy: 0.0679\n",
            "Epoch 539/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 3.0001 - accuracy: 0.2607 - val_loss: 6.0331 - val_accuracy: 0.0679\n",
            "Epoch 540/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 2.9933 - accuracy: 0.2652 - val_loss: 6.0227 - val_accuracy: 0.0750\n",
            "Epoch 541/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 2.9858 - accuracy: 0.2777 - val_loss: 6.0303 - val_accuracy: 0.0786\n",
            "Epoch 542/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 2.9789 - accuracy: 0.2634 - val_loss: 6.0381 - val_accuracy: 0.0786\n",
            "Epoch 543/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 2.9686 - accuracy: 0.2804 - val_loss: 6.0410 - val_accuracy: 0.0786\n",
            "Epoch 544/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 2.9636 - accuracy: 0.2768 - val_loss: 6.0689 - val_accuracy: 0.0750\n",
            "Epoch 545/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 2.9594 - accuracy: 0.2616 - val_loss: 6.0273 - val_accuracy: 0.0893\n",
            "Epoch 546/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 2.9505 - accuracy: 0.2732 - val_loss: 6.0526 - val_accuracy: 0.0750\n",
            "Epoch 547/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 2.9455 - accuracy: 0.2696 - val_loss: 6.0636 - val_accuracy: 0.0714\n",
            "Epoch 548/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 2.9370 - accuracy: 0.2696 - val_loss: 6.0579 - val_accuracy: 0.0857\n",
            "Epoch 549/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 2.9282 - accuracy: 0.2812 - val_loss: 6.0637 - val_accuracy: 0.0964\n",
            "Epoch 550/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 2.9252 - accuracy: 0.2812 - val_loss: 6.0854 - val_accuracy: 0.0821\n",
            "Epoch 551/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 2.9179 - accuracy: 0.2714 - val_loss: 6.0831 - val_accuracy: 0.0821\n",
            "Epoch 552/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 2.9085 - accuracy: 0.2830 - val_loss: 6.0784 - val_accuracy: 0.0786\n",
            "Epoch 553/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 2.9026 - accuracy: 0.2777 - val_loss: 6.0940 - val_accuracy: 0.0786\n",
            "Epoch 554/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 2.8969 - accuracy: 0.2884 - val_loss: 6.1069 - val_accuracy: 0.0750\n",
            "Epoch 555/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 2.8870 - accuracy: 0.2768 - val_loss: 6.0933 - val_accuracy: 0.0857\n",
            "Epoch 556/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 2.8849 - accuracy: 0.2804 - val_loss: 6.0888 - val_accuracy: 0.1000\n",
            "Epoch 557/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 2.8767 - accuracy: 0.2830 - val_loss: 6.0972 - val_accuracy: 0.0786\n",
            "Epoch 558/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 2.8697 - accuracy: 0.2848 - val_loss: 6.1087 - val_accuracy: 0.0893\n",
            "Epoch 559/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 2.8620 - accuracy: 0.2786 - val_loss: 6.1151 - val_accuracy: 0.0786\n",
            "Epoch 560/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 2.8577 - accuracy: 0.2812 - val_loss: 6.1326 - val_accuracy: 0.0821\n",
            "Epoch 561/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 2.8508 - accuracy: 0.2821 - val_loss: 6.1279 - val_accuracy: 0.0821\n",
            "Epoch 562/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 2.8439 - accuracy: 0.2830 - val_loss: 6.1255 - val_accuracy: 0.0893\n",
            "Epoch 563/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 2.8363 - accuracy: 0.2875 - val_loss: 6.1449 - val_accuracy: 0.0929\n",
            "Epoch 564/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 2.8280 - accuracy: 0.2857 - val_loss: 6.1380 - val_accuracy: 0.0929\n",
            "Epoch 565/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 2.8247 - accuracy: 0.2804 - val_loss: 6.1433 - val_accuracy: 0.0786\n",
            "Epoch 566/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 2.8180 - accuracy: 0.2768 - val_loss: 6.1438 - val_accuracy: 0.0821\n",
            "Epoch 567/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 2.8124 - accuracy: 0.2964 - val_loss: 6.1596 - val_accuracy: 0.0821\n",
            "Epoch 568/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 2.8085 - accuracy: 0.2866 - val_loss: 6.1698 - val_accuracy: 0.1000\n",
            "Epoch 569/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 2.7991 - accuracy: 0.2929 - val_loss: 6.1576 - val_accuracy: 0.0929\n",
            "Epoch 570/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 2.7926 - accuracy: 0.2929 - val_loss: 6.1534 - val_accuracy: 0.1107\n",
            "Epoch 571/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 2.7854 - accuracy: 0.3036 - val_loss: 6.1923 - val_accuracy: 0.0786\n",
            "Epoch 572/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 2.7774 - accuracy: 0.2929 - val_loss: 6.1952 - val_accuracy: 0.0929\n",
            "Epoch 573/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 2.7741 - accuracy: 0.3009 - val_loss: 6.2107 - val_accuracy: 0.0893\n",
            "Epoch 574/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 2.7701 - accuracy: 0.2911 - val_loss: 6.1902 - val_accuracy: 0.1000\n",
            "Epoch 575/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 2.7665 - accuracy: 0.3027 - val_loss: 6.1978 - val_accuracy: 0.0893\n",
            "Epoch 576/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 2.7590 - accuracy: 0.2964 - val_loss: 6.2040 - val_accuracy: 0.0893\n",
            "Epoch 577/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 2.7464 - accuracy: 0.3036 - val_loss: 6.2200 - val_accuracy: 0.0964\n",
            "Epoch 578/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 2.7455 - accuracy: 0.2964 - val_loss: 6.2215 - val_accuracy: 0.0893\n",
            "Epoch 579/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 2.7394 - accuracy: 0.2964 - val_loss: 6.2334 - val_accuracy: 0.1000\n",
            "Epoch 580/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 2.7360 - accuracy: 0.2955 - val_loss: 6.2426 - val_accuracy: 0.0929\n",
            "Epoch 581/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 2.7315 - accuracy: 0.3027 - val_loss: 6.2341 - val_accuracy: 0.0964\n",
            "Epoch 582/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 2.7247 - accuracy: 0.3089 - val_loss: 6.2475 - val_accuracy: 0.0893\n",
            "Epoch 583/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 2.7151 - accuracy: 0.3045 - val_loss: 6.2610 - val_accuracy: 0.0893\n",
            "Epoch 584/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 2.7101 - accuracy: 0.2937 - val_loss: 6.2539 - val_accuracy: 0.0929\n",
            "Epoch 585/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 2.7031 - accuracy: 0.3098 - val_loss: 6.2476 - val_accuracy: 0.1036\n",
            "Epoch 586/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 2.6992 - accuracy: 0.2973 - val_loss: 6.2770 - val_accuracy: 0.0929\n",
            "Epoch 587/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 2.6946 - accuracy: 0.3116 - val_loss: 6.2642 - val_accuracy: 0.0857\n",
            "Epoch 588/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 2.6905 - accuracy: 0.3036 - val_loss: 6.2690 - val_accuracy: 0.0929\n",
            "Epoch 589/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 2.6870 - accuracy: 0.2964 - val_loss: 6.2735 - val_accuracy: 0.0893\n",
            "Epoch 590/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 2.6755 - accuracy: 0.3089 - val_loss: 6.2777 - val_accuracy: 0.0893\n",
            "Epoch 591/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 2.6710 - accuracy: 0.3107 - val_loss: 6.2719 - val_accuracy: 0.1107\n",
            "Epoch 592/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 2.6660 - accuracy: 0.2955 - val_loss: 6.2969 - val_accuracy: 0.1036\n",
            "Epoch 593/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 2.6579 - accuracy: 0.3170 - val_loss: 6.2948 - val_accuracy: 0.1036\n",
            "Epoch 594/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 2.6586 - accuracy: 0.3205 - val_loss: 6.2951 - val_accuracy: 0.1036\n",
            "Epoch 595/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 2.6495 - accuracy: 0.3241 - val_loss: 6.3101 - val_accuracy: 0.1036\n",
            "Epoch 596/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 2.6428 - accuracy: 0.3214 - val_loss: 6.3406 - val_accuracy: 0.0929\n",
            "Epoch 597/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 2.6366 - accuracy: 0.3134 - val_loss: 6.3231 - val_accuracy: 0.1071\n",
            "Epoch 598/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 2.6315 - accuracy: 0.3054 - val_loss: 6.3253 - val_accuracy: 0.1036\n",
            "Epoch 599/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 2.6294 - accuracy: 0.3295 - val_loss: 6.3654 - val_accuracy: 0.0929\n",
            "Epoch 600/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 2.6249 - accuracy: 0.3063 - val_loss: 6.3581 - val_accuracy: 0.0929\n",
            "Epoch 601/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 2.6147 - accuracy: 0.3196 - val_loss: 6.3574 - val_accuracy: 0.1036\n",
            "Epoch 602/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 2.6075 - accuracy: 0.3152 - val_loss: 6.3549 - val_accuracy: 0.1071\n",
            "Epoch 603/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 2.6034 - accuracy: 0.3268 - val_loss: 6.4001 - val_accuracy: 0.0964\n",
            "Epoch 604/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 2.6042 - accuracy: 0.3295 - val_loss: 6.3743 - val_accuracy: 0.1000\n",
            "Epoch 605/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 2.5917 - accuracy: 0.3223 - val_loss: 6.3780 - val_accuracy: 0.1107\n",
            "Epoch 606/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 2.5871 - accuracy: 0.3196 - val_loss: 6.3856 - val_accuracy: 0.1143\n",
            "Epoch 607/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 2.5869 - accuracy: 0.3268 - val_loss: 6.3931 - val_accuracy: 0.1143\n",
            "Epoch 608/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 2.5826 - accuracy: 0.3179 - val_loss: 6.4091 - val_accuracy: 0.0929\n",
            "Epoch 609/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 2.5726 - accuracy: 0.3214 - val_loss: 6.4376 - val_accuracy: 0.1071\n",
            "Epoch 610/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 2.5692 - accuracy: 0.3313 - val_loss: 6.4029 - val_accuracy: 0.1036\n",
            "Epoch 611/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 2.5620 - accuracy: 0.3205 - val_loss: 6.3993 - val_accuracy: 0.1214\n",
            "Epoch 612/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 2.5577 - accuracy: 0.3393 - val_loss: 6.4172 - val_accuracy: 0.0964\n",
            "Epoch 613/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 2.5502 - accuracy: 0.3295 - val_loss: 6.4297 - val_accuracy: 0.1036\n",
            "Epoch 614/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 2.5520 - accuracy: 0.3259 - val_loss: 6.4390 - val_accuracy: 0.1107\n",
            "Epoch 615/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 2.5434 - accuracy: 0.3321 - val_loss: 6.4496 - val_accuracy: 0.1143\n",
            "Epoch 616/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 2.5379 - accuracy: 0.3393 - val_loss: 6.4622 - val_accuracy: 0.0964\n",
            "Epoch 617/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 2.5320 - accuracy: 0.3339 - val_loss: 6.4594 - val_accuracy: 0.1214\n",
            "Epoch 618/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 2.5231 - accuracy: 0.3402 - val_loss: 6.5024 - val_accuracy: 0.1036\n",
            "Epoch 619/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 2.5248 - accuracy: 0.3321 - val_loss: 6.4786 - val_accuracy: 0.1071\n",
            "Epoch 620/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 2.5160 - accuracy: 0.3295 - val_loss: 6.4723 - val_accuracy: 0.1179\n",
            "Epoch 621/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 2.5111 - accuracy: 0.3321 - val_loss: 6.4927 - val_accuracy: 0.1036\n",
            "Epoch 622/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 2.5086 - accuracy: 0.3375 - val_loss: 6.4961 - val_accuracy: 0.1036\n",
            "Epoch 623/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 2.5059 - accuracy: 0.3411 - val_loss: 6.4764 - val_accuracy: 0.1036\n",
            "Epoch 624/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 2.4937 - accuracy: 0.3402 - val_loss: 6.5041 - val_accuracy: 0.1071\n",
            "Epoch 625/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 2.4897 - accuracy: 0.3438 - val_loss: 6.5031 - val_accuracy: 0.1071\n",
            "Epoch 626/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 2.4843 - accuracy: 0.3402 - val_loss: 6.5172 - val_accuracy: 0.1036\n",
            "Epoch 627/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 2.4880 - accuracy: 0.3313 - val_loss: 6.5260 - val_accuracy: 0.1036\n",
            "Epoch 628/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 2.4795 - accuracy: 0.3518 - val_loss: 6.5412 - val_accuracy: 0.1036\n",
            "Epoch 629/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 2.4755 - accuracy: 0.3438 - val_loss: 6.4985 - val_accuracy: 0.1321\n",
            "Epoch 630/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 2.4670 - accuracy: 0.3473 - val_loss: 6.5400 - val_accuracy: 0.1036\n",
            "Epoch 631/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 2.4655 - accuracy: 0.3366 - val_loss: 6.5168 - val_accuracy: 0.1250\n",
            "Epoch 632/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 2.4580 - accuracy: 0.3536 - val_loss: 6.5294 - val_accuracy: 0.1214\n",
            "Epoch 633/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 2.4565 - accuracy: 0.3545 - val_loss: 6.5825 - val_accuracy: 0.1000\n",
            "Epoch 634/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 2.4526 - accuracy: 0.3518 - val_loss: 6.5854 - val_accuracy: 0.1179\n",
            "Epoch 635/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 2.4416 - accuracy: 0.3402 - val_loss: 6.5909 - val_accuracy: 0.1321\n",
            "Epoch 636/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 2.4373 - accuracy: 0.3527 - val_loss: 6.5896 - val_accuracy: 0.1179\n",
            "Epoch 637/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 2.4413 - accuracy: 0.3545 - val_loss: 6.5908 - val_accuracy: 0.1321\n",
            "Epoch 638/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 2.4306 - accuracy: 0.3545 - val_loss: 6.6058 - val_accuracy: 0.1250\n",
            "Epoch 639/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 2.4273 - accuracy: 0.3545 - val_loss: 6.6272 - val_accuracy: 0.1286\n",
            "Epoch 640/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 2.4204 - accuracy: 0.3625 - val_loss: 6.6126 - val_accuracy: 0.1321\n",
            "Epoch 641/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 2.4195 - accuracy: 0.3607 - val_loss: 6.6077 - val_accuracy: 0.1286\n",
            "Epoch 642/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 2.4149 - accuracy: 0.3536 - val_loss: 6.6253 - val_accuracy: 0.1179\n",
            "Epoch 643/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 2.4053 - accuracy: 0.3571 - val_loss: 6.6320 - val_accuracy: 0.1393\n",
            "Epoch 644/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 2.4054 - accuracy: 0.3562 - val_loss: 6.6481 - val_accuracy: 0.1143\n",
            "Epoch 645/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 2.3980 - accuracy: 0.3607 - val_loss: 6.6483 - val_accuracy: 0.1107\n",
            "Epoch 646/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 2.3944 - accuracy: 0.3509 - val_loss: 6.6575 - val_accuracy: 0.1286\n",
            "Epoch 647/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 2.3879 - accuracy: 0.3580 - val_loss: 6.6971 - val_accuracy: 0.1214\n",
            "Epoch 648/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 2.3849 - accuracy: 0.3545 - val_loss: 6.6505 - val_accuracy: 0.1321\n",
            "Epoch 649/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 2.3814 - accuracy: 0.3616 - val_loss: 6.6797 - val_accuracy: 0.1250\n",
            "Epoch 650/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 2.3806 - accuracy: 0.3625 - val_loss: 6.6762 - val_accuracy: 0.1393\n",
            "Epoch 651/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 2.3726 - accuracy: 0.3714 - val_loss: 6.6759 - val_accuracy: 0.1464\n",
            "Epoch 652/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 2.3634 - accuracy: 0.3652 - val_loss: 6.7154 - val_accuracy: 0.1429\n",
            "Epoch 653/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 2.3619 - accuracy: 0.3732 - val_loss: 6.7017 - val_accuracy: 0.1464\n",
            "Epoch 654/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 2.3582 - accuracy: 0.3625 - val_loss: 6.7148 - val_accuracy: 0.1357\n",
            "Epoch 655/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 2.3553 - accuracy: 0.3643 - val_loss: 6.7253 - val_accuracy: 0.1286\n",
            "Epoch 656/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 2.3482 - accuracy: 0.3696 - val_loss: 6.7352 - val_accuracy: 0.1464\n",
            "Epoch 657/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 2.3430 - accuracy: 0.3688 - val_loss: 6.7450 - val_accuracy: 0.1214\n",
            "Epoch 658/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 2.3436 - accuracy: 0.3688 - val_loss: 6.7282 - val_accuracy: 0.1357\n",
            "Epoch 659/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 2.3372 - accuracy: 0.3679 - val_loss: 6.7548 - val_accuracy: 0.1250\n",
            "Epoch 660/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 2.3308 - accuracy: 0.3759 - val_loss: 6.7430 - val_accuracy: 0.1429\n",
            "Epoch 661/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 2.3253 - accuracy: 0.3652 - val_loss: 6.7703 - val_accuracy: 0.1357\n",
            "Epoch 662/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 2.3240 - accuracy: 0.3848 - val_loss: 6.7911 - val_accuracy: 0.1393\n",
            "Epoch 663/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 2.3206 - accuracy: 0.3821 - val_loss: 6.7964 - val_accuracy: 0.1571\n",
            "Epoch 664/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 2.3103 - accuracy: 0.3848 - val_loss: 6.8050 - val_accuracy: 0.1250\n",
            "Epoch 665/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 2.3054 - accuracy: 0.3804 - val_loss: 6.8108 - val_accuracy: 0.1357\n",
            "Epoch 666/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 2.3067 - accuracy: 0.3750 - val_loss: 6.8112 - val_accuracy: 0.1536\n",
            "Epoch 667/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 2.3041 - accuracy: 0.3750 - val_loss: 6.8534 - val_accuracy: 0.1357\n",
            "Epoch 668/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 2.3028 - accuracy: 0.3714 - val_loss: 6.8166 - val_accuracy: 0.1357\n",
            "Epoch 669/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 2.2995 - accuracy: 0.3696 - val_loss: 6.8309 - val_accuracy: 0.1321\n",
            "Epoch 670/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 2.2912 - accuracy: 0.3759 - val_loss: 6.8262 - val_accuracy: 0.1536\n",
            "Epoch 671/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 2.2828 - accuracy: 0.3777 - val_loss: 6.8568 - val_accuracy: 0.1500\n",
            "Epoch 672/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 2.2839 - accuracy: 0.3893 - val_loss: 6.8694 - val_accuracy: 0.1429\n",
            "Epoch 673/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 2.2789 - accuracy: 0.3795 - val_loss: 6.8552 - val_accuracy: 0.1286\n",
            "Epoch 674/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 2.2719 - accuracy: 0.3866 - val_loss: 6.8907 - val_accuracy: 0.1321\n",
            "Epoch 675/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 2.2611 - accuracy: 0.3821 - val_loss: 6.8846 - val_accuracy: 0.1321\n",
            "Epoch 676/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 2.2606 - accuracy: 0.3893 - val_loss: 6.9140 - val_accuracy: 0.1321\n",
            "Epoch 677/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 2.2613 - accuracy: 0.3804 - val_loss: 6.8661 - val_accuracy: 0.1429\n",
            "Epoch 678/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 2.2586 - accuracy: 0.3714 - val_loss: 6.8921 - val_accuracy: 0.1500\n",
            "Epoch 679/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 2.2468 - accuracy: 0.3964 - val_loss: 6.8965 - val_accuracy: 0.1536\n",
            "Epoch 680/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 2.2469 - accuracy: 0.3911 - val_loss: 6.9242 - val_accuracy: 0.1571\n",
            "Epoch 681/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 2.2384 - accuracy: 0.3848 - val_loss: 6.9270 - val_accuracy: 0.1571\n",
            "Epoch 682/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 2.2382 - accuracy: 0.3920 - val_loss: 6.9175 - val_accuracy: 0.1643\n",
            "Epoch 683/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 2.2364 - accuracy: 0.3991 - val_loss: 6.9384 - val_accuracy: 0.1643\n",
            "Epoch 684/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 2.2320 - accuracy: 0.3964 - val_loss: 6.9234 - val_accuracy: 0.1643\n",
            "Epoch 685/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 2.2314 - accuracy: 0.3955 - val_loss: 6.9693 - val_accuracy: 0.1500\n",
            "Epoch 686/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 2.2181 - accuracy: 0.3946 - val_loss: 6.9708 - val_accuracy: 0.1500\n",
            "Epoch 687/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 2.2171 - accuracy: 0.3964 - val_loss: 6.9534 - val_accuracy: 0.1536\n",
            "Epoch 688/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 2.2123 - accuracy: 0.3991 - val_loss: 6.9694 - val_accuracy: 0.1429\n",
            "Epoch 689/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 2.2113 - accuracy: 0.3884 - val_loss: 6.9736 - val_accuracy: 0.1536\n",
            "Epoch 690/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 2.2081 - accuracy: 0.3991 - val_loss: 6.9918 - val_accuracy: 0.1571\n",
            "Epoch 691/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 2.1994 - accuracy: 0.4054 - val_loss: 7.0197 - val_accuracy: 0.1536\n",
            "Epoch 692/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 2.2037 - accuracy: 0.4018 - val_loss: 7.0010 - val_accuracy: 0.1607\n",
            "Epoch 693/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 2.1983 - accuracy: 0.3991 - val_loss: 7.0116 - val_accuracy: 0.1571\n",
            "Epoch 694/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 2.1916 - accuracy: 0.3884 - val_loss: 7.0137 - val_accuracy: 0.1536\n",
            "Epoch 695/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 2.1864 - accuracy: 0.4062 - val_loss: 7.0400 - val_accuracy: 0.1429\n",
            "Epoch 696/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 2.1763 - accuracy: 0.4027 - val_loss: 7.0544 - val_accuracy: 0.1571\n",
            "Epoch 697/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 2.1798 - accuracy: 0.4071 - val_loss: 7.0385 - val_accuracy: 0.1679\n",
            "Epoch 698/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 2.1707 - accuracy: 0.4116 - val_loss: 7.0878 - val_accuracy: 0.1500\n",
            "Epoch 699/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 2.1710 - accuracy: 0.4134 - val_loss: 7.0531 - val_accuracy: 0.1643\n",
            "Epoch 700/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 2.1642 - accuracy: 0.4143 - val_loss: 7.0650 - val_accuracy: 0.1679\n",
            "Epoch 701/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 2.1622 - accuracy: 0.4152 - val_loss: 7.0571 - val_accuracy: 0.1893\n",
            "Epoch 702/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 2.1573 - accuracy: 0.4152 - val_loss: 7.0769 - val_accuracy: 0.1714\n",
            "Epoch 703/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 2.1586 - accuracy: 0.4170 - val_loss: 7.1018 - val_accuracy: 0.1714\n",
            "Epoch 704/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 2.1530 - accuracy: 0.3991 - val_loss: 7.0857 - val_accuracy: 0.1607\n",
            "Epoch 705/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 2.1420 - accuracy: 0.4134 - val_loss: 7.1107 - val_accuracy: 0.1679\n",
            "Epoch 706/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 2.1431 - accuracy: 0.4161 - val_loss: 7.1116 - val_accuracy: 0.1571\n",
            "Epoch 707/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 2.1395 - accuracy: 0.4107 - val_loss: 7.1271 - val_accuracy: 0.1643\n",
            "Epoch 708/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 2.1345 - accuracy: 0.4304 - val_loss: 7.1340 - val_accuracy: 0.1679\n",
            "Epoch 709/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 2.1273 - accuracy: 0.4268 - val_loss: 7.1602 - val_accuracy: 0.1571\n",
            "Epoch 710/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 2.1253 - accuracy: 0.4241 - val_loss: 7.1606 - val_accuracy: 0.1500\n",
            "Epoch 711/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 2.1251 - accuracy: 0.4196 - val_loss: 7.1481 - val_accuracy: 0.1643\n",
            "Epoch 712/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 2.1177 - accuracy: 0.4321 - val_loss: 7.1887 - val_accuracy: 0.1500\n",
            "Epoch 713/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 2.1134 - accuracy: 0.4277 - val_loss: 7.2384 - val_accuracy: 0.1679\n",
            "Epoch 714/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 2.1146 - accuracy: 0.4214 - val_loss: 7.1741 - val_accuracy: 0.1643\n",
            "Epoch 715/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 2.1048 - accuracy: 0.4286 - val_loss: 7.2071 - val_accuracy: 0.1786\n",
            "Epoch 716/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 2.1063 - accuracy: 0.4277 - val_loss: 7.2243 - val_accuracy: 0.1643\n",
            "Epoch 717/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 2.1003 - accuracy: 0.4205 - val_loss: 7.2393 - val_accuracy: 0.1679\n",
            "Epoch 718/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 2.0987 - accuracy: 0.4152 - val_loss: 7.2254 - val_accuracy: 0.1571\n",
            "Epoch 719/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 2.0943 - accuracy: 0.4375 - val_loss: 7.2289 - val_accuracy: 0.1679\n",
            "Epoch 720/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 2.0850 - accuracy: 0.4402 - val_loss: 7.2257 - val_accuracy: 0.1679\n",
            "Epoch 721/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 2.0870 - accuracy: 0.4321 - val_loss: 7.2331 - val_accuracy: 0.1679\n",
            "Epoch 722/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 2.0812 - accuracy: 0.4384 - val_loss: 7.2612 - val_accuracy: 0.1571\n",
            "Epoch 723/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 2.0807 - accuracy: 0.4420 - val_loss: 7.2579 - val_accuracy: 0.1500\n",
            "Epoch 724/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 2.0780 - accuracy: 0.4393 - val_loss: 7.2905 - val_accuracy: 0.1393\n",
            "Epoch 725/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 2.0725 - accuracy: 0.4321 - val_loss: 7.2840 - val_accuracy: 0.1571\n",
            "Epoch 726/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 2.0708 - accuracy: 0.4437 - val_loss: 7.2969 - val_accuracy: 0.1714\n",
            "Epoch 727/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 2.0613 - accuracy: 0.4348 - val_loss: 7.2952 - val_accuracy: 0.1786\n",
            "Epoch 728/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 2.0618 - accuracy: 0.4402 - val_loss: 7.3047 - val_accuracy: 0.1893\n",
            "Epoch 729/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 2.0575 - accuracy: 0.4393 - val_loss: 7.3629 - val_accuracy: 0.1786\n",
            "Epoch 730/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 2.0511 - accuracy: 0.4437 - val_loss: 7.3166 - val_accuracy: 0.1750\n",
            "Epoch 731/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 2.0533 - accuracy: 0.4446 - val_loss: 7.3101 - val_accuracy: 0.1929\n",
            "Epoch 732/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 2.0398 - accuracy: 0.4661 - val_loss: 7.3706 - val_accuracy: 0.1750\n",
            "Epoch 733/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 2.0454 - accuracy: 0.4429 - val_loss: 7.3389 - val_accuracy: 0.1643\n",
            "Epoch 734/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 2.0383 - accuracy: 0.4429 - val_loss: 7.3471 - val_accuracy: 0.1786\n",
            "Epoch 735/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 2.0393 - accuracy: 0.4464 - val_loss: 7.3606 - val_accuracy: 0.1857\n",
            "Epoch 736/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 2.0345 - accuracy: 0.4509 - val_loss: 7.3575 - val_accuracy: 0.1679\n",
            "Epoch 737/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 2.0294 - accuracy: 0.4500 - val_loss: 7.3604 - val_accuracy: 0.1679\n",
            "Epoch 738/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 2.0250 - accuracy: 0.4491 - val_loss: 7.3921 - val_accuracy: 0.1857\n",
            "Epoch 739/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 2.0289 - accuracy: 0.4500 - val_loss: 7.4101 - val_accuracy: 0.1714\n",
            "Epoch 740/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 2.0192 - accuracy: 0.4509 - val_loss: 7.3970 - val_accuracy: 0.1750\n",
            "Epoch 741/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 2.0157 - accuracy: 0.4571 - val_loss: 7.4200 - val_accuracy: 0.1786\n",
            "Epoch 742/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 2.0100 - accuracy: 0.4634 - val_loss: 7.4136 - val_accuracy: 0.1750\n",
            "Epoch 743/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 2.0074 - accuracy: 0.4518 - val_loss: 7.4361 - val_accuracy: 0.1786\n",
            "Epoch 744/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 2.0005 - accuracy: 0.4580 - val_loss: 7.4305 - val_accuracy: 0.1821\n",
            "Epoch 745/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.9963 - accuracy: 0.4589 - val_loss: 7.4298 - val_accuracy: 0.1893\n",
            "Epoch 746/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.9945 - accuracy: 0.4536 - val_loss: 7.4215 - val_accuracy: 0.1893\n",
            "Epoch 747/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.9908 - accuracy: 0.4563 - val_loss: 7.4807 - val_accuracy: 0.1714\n",
            "Epoch 748/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 1.9926 - accuracy: 0.4607 - val_loss: 7.4625 - val_accuracy: 0.1821\n",
            "Epoch 749/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.9862 - accuracy: 0.4571 - val_loss: 7.4772 - val_accuracy: 0.1786\n",
            "Epoch 750/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.9863 - accuracy: 0.4554 - val_loss: 7.4754 - val_accuracy: 0.1821\n",
            "Epoch 751/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.9728 - accuracy: 0.4696 - val_loss: 7.5172 - val_accuracy: 0.1714\n",
            "Epoch 752/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.9765 - accuracy: 0.4616 - val_loss: 7.4949 - val_accuracy: 0.1857\n",
            "Epoch 753/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.9666 - accuracy: 0.4634 - val_loss: 7.5585 - val_accuracy: 0.1571\n",
            "Epoch 754/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.9661 - accuracy: 0.4545 - val_loss: 7.5271 - val_accuracy: 0.1679\n",
            "Epoch 755/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.9655 - accuracy: 0.4670 - val_loss: 7.5301 - val_accuracy: 0.1750\n",
            "Epoch 756/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.9628 - accuracy: 0.4732 - val_loss: 7.5279 - val_accuracy: 0.1750\n",
            "Epoch 757/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.9580 - accuracy: 0.4661 - val_loss: 7.5597 - val_accuracy: 0.1786\n",
            "Epoch 758/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.9495 - accuracy: 0.4812 - val_loss: 7.5702 - val_accuracy: 0.1821\n",
            "Epoch 759/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.9485 - accuracy: 0.4786 - val_loss: 7.5679 - val_accuracy: 0.1750\n",
            "Epoch 760/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.9507 - accuracy: 0.4768 - val_loss: 7.5413 - val_accuracy: 0.1786\n",
            "Epoch 761/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.9455 - accuracy: 0.4670 - val_loss: 7.5927 - val_accuracy: 0.1679\n",
            "Epoch 762/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.9418 - accuracy: 0.4723 - val_loss: 7.6360 - val_accuracy: 0.1750\n",
            "Epoch 763/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.9383 - accuracy: 0.4821 - val_loss: 7.5939 - val_accuracy: 0.1929\n",
            "Epoch 764/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.9336 - accuracy: 0.4804 - val_loss: 7.5970 - val_accuracy: 0.1786\n",
            "Epoch 765/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.9251 - accuracy: 0.4929 - val_loss: 7.6307 - val_accuracy: 0.1714\n",
            "Epoch 766/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.9269 - accuracy: 0.4777 - val_loss: 7.6422 - val_accuracy: 0.1857\n",
            "Epoch 767/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.9203 - accuracy: 0.4866 - val_loss: 7.6282 - val_accuracy: 0.1893\n",
            "Epoch 768/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.9277 - accuracy: 0.4821 - val_loss: 7.6380 - val_accuracy: 0.1929\n",
            "Epoch 769/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.9156 - accuracy: 0.4929 - val_loss: 7.6602 - val_accuracy: 0.1821\n",
            "Epoch 770/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.9141 - accuracy: 0.4911 - val_loss: 7.6604 - val_accuracy: 0.1893\n",
            "Epoch 771/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.9107 - accuracy: 0.4884 - val_loss: 7.6819 - val_accuracy: 0.1821\n",
            "Epoch 772/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.9069 - accuracy: 0.4929 - val_loss: 7.6598 - val_accuracy: 0.1893\n",
            "Epoch 773/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.8998 - accuracy: 0.4920 - val_loss: 7.7163 - val_accuracy: 0.1893\n",
            "Epoch 774/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.8999 - accuracy: 0.4893 - val_loss: 7.7161 - val_accuracy: 0.1893\n",
            "Epoch 775/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.9031 - accuracy: 0.4848 - val_loss: 7.7068 - val_accuracy: 0.1857\n",
            "Epoch 776/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.8943 - accuracy: 0.4929 - val_loss: 7.7208 - val_accuracy: 0.1679\n",
            "Epoch 777/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.8911 - accuracy: 0.4812 - val_loss: 7.7158 - val_accuracy: 0.1714\n",
            "Epoch 778/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.8836 - accuracy: 0.4875 - val_loss: 7.7450 - val_accuracy: 0.1964\n",
            "Epoch 779/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.8819 - accuracy: 0.4929 - val_loss: 7.7589 - val_accuracy: 0.1964\n",
            "Epoch 780/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.8804 - accuracy: 0.4991 - val_loss: 7.7619 - val_accuracy: 0.2036\n",
            "Epoch 781/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.8752 - accuracy: 0.5018 - val_loss: 7.7755 - val_accuracy: 0.1929\n",
            "Epoch 782/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.8710 - accuracy: 0.4893 - val_loss: 7.7431 - val_accuracy: 0.2036\n",
            "Epoch 783/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.8721 - accuracy: 0.4982 - val_loss: 7.7386 - val_accuracy: 0.2036\n",
            "Epoch 784/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.8629 - accuracy: 0.4991 - val_loss: 7.7605 - val_accuracy: 0.2107\n",
            "Epoch 785/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.8600 - accuracy: 0.4857 - val_loss: 7.7893 - val_accuracy: 0.1893\n",
            "Epoch 786/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.8572 - accuracy: 0.5045 - val_loss: 7.7510 - val_accuracy: 0.2143\n",
            "Epoch 787/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.8559 - accuracy: 0.5071 - val_loss: 7.7697 - val_accuracy: 0.2071\n",
            "Epoch 788/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.8493 - accuracy: 0.5027 - val_loss: 7.8181 - val_accuracy: 0.1893\n",
            "Epoch 789/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.8509 - accuracy: 0.4857 - val_loss: 7.8173 - val_accuracy: 0.1893\n",
            "Epoch 790/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.8501 - accuracy: 0.4929 - val_loss: 7.8096 - val_accuracy: 0.1964\n",
            "Epoch 791/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.8439 - accuracy: 0.5196 - val_loss: 7.8265 - val_accuracy: 0.2107\n",
            "Epoch 792/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.8373 - accuracy: 0.5000 - val_loss: 7.8463 - val_accuracy: 0.1857\n",
            "Epoch 793/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.8347 - accuracy: 0.4911 - val_loss: 7.8762 - val_accuracy: 0.1929\n",
            "Epoch 794/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.8369 - accuracy: 0.5125 - val_loss: 7.8551 - val_accuracy: 0.2036\n",
            "Epoch 795/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.8326 - accuracy: 0.5098 - val_loss: 7.8493 - val_accuracy: 0.1893\n",
            "Epoch 796/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.8256 - accuracy: 0.5009 - val_loss: 7.8415 - val_accuracy: 0.2143\n",
            "Epoch 797/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.8304 - accuracy: 0.5125 - val_loss: 7.8939 - val_accuracy: 0.2071\n",
            "Epoch 798/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.8188 - accuracy: 0.5107 - val_loss: 7.9127 - val_accuracy: 0.1929\n",
            "Epoch 799/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.8158 - accuracy: 0.5080 - val_loss: 7.9304 - val_accuracy: 0.1786\n",
            "Epoch 800/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.8168 - accuracy: 0.5027 - val_loss: 7.9383 - val_accuracy: 0.1964\n",
            "Epoch 801/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.8176 - accuracy: 0.5161 - val_loss: 7.9825 - val_accuracy: 0.2036\n",
            "Epoch 802/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.8115 - accuracy: 0.5018 - val_loss: 7.9725 - val_accuracy: 0.2071\n",
            "Epoch 803/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.8019 - accuracy: 0.4964 - val_loss: 7.9429 - val_accuracy: 0.2036\n",
            "Epoch 804/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.8043 - accuracy: 0.5045 - val_loss: 8.0000 - val_accuracy: 0.1929\n",
            "Epoch 805/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.7970 - accuracy: 0.5143 - val_loss: 7.9768 - val_accuracy: 0.2071\n",
            "Epoch 806/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.7963 - accuracy: 0.5009 - val_loss: 7.9766 - val_accuracy: 0.1929\n",
            "Epoch 807/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.7949 - accuracy: 0.5232 - val_loss: 7.9774 - val_accuracy: 0.1929\n",
            "Epoch 808/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.7895 - accuracy: 0.5161 - val_loss: 7.9896 - val_accuracy: 0.2143\n",
            "Epoch 809/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.7852 - accuracy: 0.5107 - val_loss: 7.9987 - val_accuracy: 0.2179\n",
            "Epoch 810/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.7793 - accuracy: 0.5214 - val_loss: 8.0241 - val_accuracy: 0.1964\n",
            "Epoch 811/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.7798 - accuracy: 0.5116 - val_loss: 8.0276 - val_accuracy: 0.2036\n",
            "Epoch 812/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.7762 - accuracy: 0.5250 - val_loss: 8.0251 - val_accuracy: 0.2143\n",
            "Epoch 813/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.7703 - accuracy: 0.5214 - val_loss: 8.0249 - val_accuracy: 0.2000\n",
            "Epoch 814/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.7697 - accuracy: 0.5179 - val_loss: 8.0331 - val_accuracy: 0.1964\n",
            "Epoch 815/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.7683 - accuracy: 0.5205 - val_loss: 8.0912 - val_accuracy: 0.2250\n",
            "Epoch 816/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.7656 - accuracy: 0.5232 - val_loss: 8.0462 - val_accuracy: 0.2250\n",
            "Epoch 817/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.7635 - accuracy: 0.5277 - val_loss: 8.0824 - val_accuracy: 0.1893\n",
            "Epoch 818/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.7542 - accuracy: 0.5143 - val_loss: 8.0781 - val_accuracy: 0.2179\n",
            "Epoch 819/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.7598 - accuracy: 0.5348 - val_loss: 8.0708 - val_accuracy: 0.2214\n",
            "Epoch 820/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.7542 - accuracy: 0.5268 - val_loss: 8.0809 - val_accuracy: 0.2036\n",
            "Epoch 821/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.7523 - accuracy: 0.5304 - val_loss: 8.1054 - val_accuracy: 0.2250\n",
            "Epoch 822/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.7443 - accuracy: 0.5214 - val_loss: 8.1160 - val_accuracy: 0.2250\n",
            "Epoch 823/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.7427 - accuracy: 0.5277 - val_loss: 8.1362 - val_accuracy: 0.2107\n",
            "Epoch 824/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.7405 - accuracy: 0.5321 - val_loss: 8.1288 - val_accuracy: 0.2286\n",
            "Epoch 825/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.7392 - accuracy: 0.5241 - val_loss: 8.1877 - val_accuracy: 0.2143\n",
            "Epoch 826/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.7373 - accuracy: 0.5375 - val_loss: 8.1351 - val_accuracy: 0.2250\n",
            "Epoch 827/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.7234 - accuracy: 0.5304 - val_loss: 8.1845 - val_accuracy: 0.2107\n",
            "Epoch 828/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.7296 - accuracy: 0.5482 - val_loss: 8.1900 - val_accuracy: 0.2143\n",
            "Epoch 829/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.7186 - accuracy: 0.5348 - val_loss: 8.1748 - val_accuracy: 0.2250\n",
            "Epoch 830/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.7253 - accuracy: 0.5286 - val_loss: 8.1822 - val_accuracy: 0.2250\n",
            "Epoch 831/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.7184 - accuracy: 0.5366 - val_loss: 8.2341 - val_accuracy: 0.2143\n",
            "Epoch 832/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.7159 - accuracy: 0.5339 - val_loss: 8.2029 - val_accuracy: 0.2179\n",
            "Epoch 833/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 1.7141 - accuracy: 0.5464 - val_loss: 8.2108 - val_accuracy: 0.2071\n",
            "Epoch 834/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.7137 - accuracy: 0.5375 - val_loss: 8.2235 - val_accuracy: 0.2214\n",
            "Epoch 835/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 1.7057 - accuracy: 0.5429 - val_loss: 8.2203 - val_accuracy: 0.2250\n",
            "Epoch 836/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.7001 - accuracy: 0.5545 - val_loss: 8.2604 - val_accuracy: 0.2357\n",
            "Epoch 837/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 1.6998 - accuracy: 0.5357 - val_loss: 8.2900 - val_accuracy: 0.2214\n",
            "Epoch 838/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.6955 - accuracy: 0.5357 - val_loss: 8.2600 - val_accuracy: 0.2321\n",
            "Epoch 839/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.6885 - accuracy: 0.5446 - val_loss: 8.2687 - val_accuracy: 0.2286\n",
            "Epoch 840/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.6884 - accuracy: 0.5429 - val_loss: 8.2759 - val_accuracy: 0.2357\n",
            "Epoch 841/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.6915 - accuracy: 0.5455 - val_loss: 8.2903 - val_accuracy: 0.2179\n",
            "Epoch 842/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 1.6903 - accuracy: 0.5491 - val_loss: 8.2981 - val_accuracy: 0.2286\n",
            "Epoch 843/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.6769 - accuracy: 0.5411 - val_loss: 8.3139 - val_accuracy: 0.2357\n",
            "Epoch 844/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.6802 - accuracy: 0.5571 - val_loss: 8.3368 - val_accuracy: 0.2179\n",
            "Epoch 845/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.6759 - accuracy: 0.5482 - val_loss: 8.3119 - val_accuracy: 0.2143\n",
            "Epoch 846/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.6730 - accuracy: 0.5393 - val_loss: 8.3305 - val_accuracy: 0.2214\n",
            "Epoch 847/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.6728 - accuracy: 0.5402 - val_loss: 8.3783 - val_accuracy: 0.2286\n",
            "Epoch 848/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.6679 - accuracy: 0.5536 - val_loss: 8.3546 - val_accuracy: 0.2393\n",
            "Epoch 849/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.6613 - accuracy: 0.5679 - val_loss: 8.3601 - val_accuracy: 0.2214\n",
            "Epoch 850/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.6650 - accuracy: 0.5491 - val_loss: 8.4266 - val_accuracy: 0.2179\n",
            "Epoch 851/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.6632 - accuracy: 0.5554 - val_loss: 8.3736 - val_accuracy: 0.2250\n",
            "Epoch 852/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.6492 - accuracy: 0.5643 - val_loss: 8.3993 - val_accuracy: 0.2321\n",
            "Epoch 853/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 1.6496 - accuracy: 0.5625 - val_loss: 8.4397 - val_accuracy: 0.1929\n",
            "Epoch 854/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.6494 - accuracy: 0.5500 - val_loss: 8.4117 - val_accuracy: 0.2143\n",
            "Epoch 855/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.6500 - accuracy: 0.5589 - val_loss: 8.4572 - val_accuracy: 0.2250\n",
            "Epoch 856/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.6432 - accuracy: 0.5455 - val_loss: 8.3968 - val_accuracy: 0.2321\n",
            "Epoch 857/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.6338 - accuracy: 0.5634 - val_loss: 8.4683 - val_accuracy: 0.2250\n",
            "Epoch 858/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.6362 - accuracy: 0.5670 - val_loss: 8.4524 - val_accuracy: 0.2464\n",
            "Epoch 859/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.6362 - accuracy: 0.5482 - val_loss: 8.4569 - val_accuracy: 0.2393\n",
            "Epoch 860/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.6266 - accuracy: 0.5661 - val_loss: 8.4251 - val_accuracy: 0.2214\n",
            "Epoch 861/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.6327 - accuracy: 0.5670 - val_loss: 8.4535 - val_accuracy: 0.2321\n",
            "Epoch 862/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.6274 - accuracy: 0.5634 - val_loss: 8.5057 - val_accuracy: 0.2286\n",
            "Epoch 863/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.6242 - accuracy: 0.5616 - val_loss: 8.4884 - val_accuracy: 0.2321\n",
            "Epoch 864/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 1.6260 - accuracy: 0.5580 - val_loss: 8.4855 - val_accuracy: 0.2464\n",
            "Epoch 865/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.6267 - accuracy: 0.5661 - val_loss: 8.5005 - val_accuracy: 0.2286\n",
            "Epoch 866/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.6180 - accuracy: 0.5679 - val_loss: 8.5376 - val_accuracy: 0.2143\n",
            "Epoch 867/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.6135 - accuracy: 0.5652 - val_loss: 8.5621 - val_accuracy: 0.2429\n",
            "Epoch 868/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.6080 - accuracy: 0.5607 - val_loss: 8.5409 - val_accuracy: 0.2286\n",
            "Epoch 869/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.6045 - accuracy: 0.5777 - val_loss: 8.5412 - val_accuracy: 0.2393\n",
            "Epoch 870/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.6049 - accuracy: 0.5723 - val_loss: 8.5266 - val_accuracy: 0.2429\n",
            "Epoch 871/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.5911 - accuracy: 0.5732 - val_loss: 8.5692 - val_accuracy: 0.2179\n",
            "Epoch 872/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.5996 - accuracy: 0.5750 - val_loss: 8.5660 - val_accuracy: 0.2464\n",
            "Epoch 873/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.5993 - accuracy: 0.5705 - val_loss: 8.6012 - val_accuracy: 0.2250\n",
            "Epoch 874/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.5960 - accuracy: 0.5723 - val_loss: 8.6158 - val_accuracy: 0.2286\n",
            "Epoch 875/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.5883 - accuracy: 0.5723 - val_loss: 8.6312 - val_accuracy: 0.2464\n",
            "Epoch 876/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.5900 - accuracy: 0.5714 - val_loss: 8.6352 - val_accuracy: 0.2250\n",
            "Epoch 877/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.5759 - accuracy: 0.5696 - val_loss: 8.6534 - val_accuracy: 0.2393\n",
            "Epoch 878/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 1.5782 - accuracy: 0.5696 - val_loss: 8.6593 - val_accuracy: 0.2286\n",
            "Epoch 879/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.5844 - accuracy: 0.5804 - val_loss: 8.6228 - val_accuracy: 0.2464\n",
            "Epoch 880/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.5762 - accuracy: 0.5768 - val_loss: 8.7067 - val_accuracy: 0.2179\n",
            "Epoch 881/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.5815 - accuracy: 0.5875 - val_loss: 8.6696 - val_accuracy: 0.2214\n",
            "Epoch 882/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.5748 - accuracy: 0.5821 - val_loss: 8.6523 - val_accuracy: 0.2429\n",
            "Epoch 883/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.5646 - accuracy: 0.5786 - val_loss: 8.6809 - val_accuracy: 0.2357\n",
            "Epoch 884/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.5568 - accuracy: 0.5857 - val_loss: 8.7096 - val_accuracy: 0.2250\n",
            "Epoch 885/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.5545 - accuracy: 0.5857 - val_loss: 8.7067 - val_accuracy: 0.2500\n",
            "Epoch 886/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.5571 - accuracy: 0.5857 - val_loss: 8.6760 - val_accuracy: 0.2643\n",
            "Epoch 887/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.5562 - accuracy: 0.5875 - val_loss: 8.6831 - val_accuracy: 0.2429\n",
            "Epoch 888/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.5560 - accuracy: 0.5857 - val_loss: 8.7188 - val_accuracy: 0.2429\n",
            "Epoch 889/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.5476 - accuracy: 0.5839 - val_loss: 8.7436 - val_accuracy: 0.2429\n",
            "Epoch 890/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.5460 - accuracy: 0.5813 - val_loss: 8.7390 - val_accuracy: 0.2464\n",
            "Epoch 891/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.5436 - accuracy: 0.5848 - val_loss: 8.7712 - val_accuracy: 0.2250\n",
            "Epoch 892/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.5366 - accuracy: 0.5902 - val_loss: 8.7912 - val_accuracy: 0.2179\n",
            "Epoch 893/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.5392 - accuracy: 0.5804 - val_loss: 8.7810 - val_accuracy: 0.2286\n",
            "Epoch 894/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.5350 - accuracy: 0.5830 - val_loss: 8.8197 - val_accuracy: 0.2286\n",
            "Epoch 895/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.5350 - accuracy: 0.5839 - val_loss: 8.7981 - val_accuracy: 0.2536\n",
            "Epoch 896/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.5224 - accuracy: 0.6000 - val_loss: 8.7837 - val_accuracy: 0.2321\n",
            "Epoch 897/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.5282 - accuracy: 0.5768 - val_loss: 8.8112 - val_accuracy: 0.2464\n",
            "Epoch 898/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.5183 - accuracy: 0.5902 - val_loss: 8.8042 - val_accuracy: 0.2536\n",
            "Epoch 899/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.5240 - accuracy: 0.5973 - val_loss: 8.8145 - val_accuracy: 0.2357\n",
            "Epoch 900/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 1.5109 - accuracy: 0.5920 - val_loss: 8.8248 - val_accuracy: 0.2357\n",
            "Epoch 901/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.5121 - accuracy: 0.5902 - val_loss: 8.8649 - val_accuracy: 0.2250\n",
            "Epoch 902/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.5114 - accuracy: 0.5875 - val_loss: 8.8685 - val_accuracy: 0.2429\n",
            "Epoch 903/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.5146 - accuracy: 0.6000 - val_loss: 8.8725 - val_accuracy: 0.2429\n",
            "Epoch 904/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.5081 - accuracy: 0.6071 - val_loss: 8.8460 - val_accuracy: 0.2429\n",
            "Epoch 905/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.4988 - accuracy: 0.6062 - val_loss: 8.8768 - val_accuracy: 0.2429\n",
            "Epoch 906/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.5040 - accuracy: 0.5982 - val_loss: 8.9081 - val_accuracy: 0.2357\n",
            "Epoch 907/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.4961 - accuracy: 0.5991 - val_loss: 8.8941 - val_accuracy: 0.2464\n",
            "Epoch 908/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.4918 - accuracy: 0.5982 - val_loss: 8.9369 - val_accuracy: 0.2536\n",
            "Epoch 909/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 1.4902 - accuracy: 0.6036 - val_loss: 8.9225 - val_accuracy: 0.2464\n",
            "Epoch 910/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.4907 - accuracy: 0.6062 - val_loss: 8.9511 - val_accuracy: 0.2393\n",
            "Epoch 911/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.4892 - accuracy: 0.5929 - val_loss: 8.9427 - val_accuracy: 0.2536\n",
            "Epoch 912/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.4801 - accuracy: 0.6036 - val_loss: 8.9755 - val_accuracy: 0.2393\n",
            "Epoch 913/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.4780 - accuracy: 0.6071 - val_loss: 8.9683 - val_accuracy: 0.2464\n",
            "Epoch 914/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.4747 - accuracy: 0.6161 - val_loss: 8.9525 - val_accuracy: 0.2571\n",
            "Epoch 915/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.4762 - accuracy: 0.6179 - val_loss: 9.0230 - val_accuracy: 0.2393\n",
            "Epoch 916/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.4720 - accuracy: 0.5991 - val_loss: 9.0134 - val_accuracy: 0.2357\n",
            "Epoch 917/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.4722 - accuracy: 0.6027 - val_loss: 9.0190 - val_accuracy: 0.2536\n",
            "Epoch 918/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.4739 - accuracy: 0.6080 - val_loss: 8.9945 - val_accuracy: 0.2429\n",
            "Epoch 919/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 1.4578 - accuracy: 0.6080 - val_loss: 9.0883 - val_accuracy: 0.2500\n",
            "Epoch 920/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.4620 - accuracy: 0.6134 - val_loss: 9.0452 - val_accuracy: 0.2464\n",
            "Epoch 921/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.4577 - accuracy: 0.6009 - val_loss: 9.0752 - val_accuracy: 0.2357\n",
            "Epoch 922/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.4512 - accuracy: 0.6125 - val_loss: 9.0454 - val_accuracy: 0.2429\n",
            "Epoch 923/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.4533 - accuracy: 0.6018 - val_loss: 9.0436 - val_accuracy: 0.2536\n",
            "Epoch 924/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.4532 - accuracy: 0.6187 - val_loss: 9.1127 - val_accuracy: 0.2393\n",
            "Epoch 925/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.4432 - accuracy: 0.5991 - val_loss: 9.0852 - val_accuracy: 0.2500\n",
            "Epoch 926/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.4474 - accuracy: 0.5982 - val_loss: 9.1276 - val_accuracy: 0.2393\n",
            "Epoch 927/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.4399 - accuracy: 0.6170 - val_loss: 9.0963 - val_accuracy: 0.2536\n",
            "Epoch 928/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 1.4389 - accuracy: 0.6214 - val_loss: 9.1013 - val_accuracy: 0.2607\n",
            "Epoch 929/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.4334 - accuracy: 0.6125 - val_loss: 9.1272 - val_accuracy: 0.2536\n",
            "Epoch 930/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.4299 - accuracy: 0.6071 - val_loss: 9.1483 - val_accuracy: 0.2286\n",
            "Epoch 931/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.4296 - accuracy: 0.6062 - val_loss: 9.1524 - val_accuracy: 0.2357\n",
            "Epoch 932/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.4228 - accuracy: 0.6170 - val_loss: 9.1496 - val_accuracy: 0.2571\n",
            "Epoch 933/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.4201 - accuracy: 0.6250 - val_loss: 9.1925 - val_accuracy: 0.2429\n",
            "Epoch 934/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.4140 - accuracy: 0.6214 - val_loss: 9.1584 - val_accuracy: 0.2536\n",
            "Epoch 935/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.4187 - accuracy: 0.6232 - val_loss: 9.1969 - val_accuracy: 0.2464\n",
            "Epoch 936/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.4139 - accuracy: 0.6214 - val_loss: 9.1794 - val_accuracy: 0.2429\n",
            "Epoch 937/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.4170 - accuracy: 0.6116 - val_loss: 9.1986 - val_accuracy: 0.2357\n",
            "Epoch 938/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.4119 - accuracy: 0.6098 - val_loss: 9.1881 - val_accuracy: 0.2536\n",
            "Epoch 939/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.4092 - accuracy: 0.6179 - val_loss: 9.1875 - val_accuracy: 0.2679\n",
            "Epoch 940/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.3980 - accuracy: 0.6357 - val_loss: 9.2460 - val_accuracy: 0.2357\n",
            "Epoch 941/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.3991 - accuracy: 0.6116 - val_loss: 9.2639 - val_accuracy: 0.2500\n",
            "Epoch 942/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.4000 - accuracy: 0.6313 - val_loss: 9.2489 - val_accuracy: 0.2500\n",
            "Epoch 943/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.3942 - accuracy: 0.6277 - val_loss: 9.3066 - val_accuracy: 0.2357\n",
            "Epoch 944/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.3945 - accuracy: 0.6187 - val_loss: 9.2555 - val_accuracy: 0.2500\n",
            "Epoch 945/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.3853 - accuracy: 0.6268 - val_loss: 9.2500 - val_accuracy: 0.2607\n",
            "Epoch 946/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.3905 - accuracy: 0.6339 - val_loss: 9.2812 - val_accuracy: 0.2607\n",
            "Epoch 947/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.3875 - accuracy: 0.6313 - val_loss: 9.2833 - val_accuracy: 0.2571\n",
            "Epoch 948/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 1.3797 - accuracy: 0.6348 - val_loss: 9.2760 - val_accuracy: 0.2679\n",
            "Epoch 949/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.3817 - accuracy: 0.6393 - val_loss: 9.2897 - val_accuracy: 0.2643\n",
            "Epoch 950/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.3757 - accuracy: 0.6179 - val_loss: 9.2858 - val_accuracy: 0.2643\n",
            "Epoch 951/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.3740 - accuracy: 0.6330 - val_loss: 9.2965 - val_accuracy: 0.2571\n",
            "Epoch 952/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.3642 - accuracy: 0.6366 - val_loss: 9.3306 - val_accuracy: 0.2500\n",
            "Epoch 953/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.3701 - accuracy: 0.6268 - val_loss: 9.3249 - val_accuracy: 0.2357\n",
            "Epoch 954/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.3683 - accuracy: 0.6277 - val_loss: 9.3361 - val_accuracy: 0.2536\n",
            "Epoch 955/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.3590 - accuracy: 0.6357 - val_loss: 9.3802 - val_accuracy: 0.2536\n",
            "Epoch 956/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.3606 - accuracy: 0.6348 - val_loss: 9.3951 - val_accuracy: 0.2536\n",
            "Epoch 957/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.3552 - accuracy: 0.6330 - val_loss: 9.3806 - val_accuracy: 0.2464\n",
            "Epoch 958/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.3466 - accuracy: 0.6429 - val_loss: 9.3596 - val_accuracy: 0.2571\n",
            "Epoch 959/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.3455 - accuracy: 0.6500 - val_loss: 9.3457 - val_accuracy: 0.2679\n",
            "Epoch 960/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.3469 - accuracy: 0.6357 - val_loss: 9.3857 - val_accuracy: 0.2429\n",
            "Epoch 961/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 1.3425 - accuracy: 0.6375 - val_loss: 9.4471 - val_accuracy: 0.2357\n",
            "Epoch 962/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.3411 - accuracy: 0.6357 - val_loss: 9.4544 - val_accuracy: 0.2536\n",
            "Epoch 963/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.3329 - accuracy: 0.6420 - val_loss: 9.4114 - val_accuracy: 0.2536\n",
            "Epoch 964/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.3281 - accuracy: 0.6455 - val_loss: 9.4159 - val_accuracy: 0.2607\n",
            "Epoch 965/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 1.3295 - accuracy: 0.6482 - val_loss: 9.4813 - val_accuracy: 0.2571\n",
            "Epoch 966/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.3316 - accuracy: 0.6446 - val_loss: 9.4059 - val_accuracy: 0.2786\n",
            "Epoch 967/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.3240 - accuracy: 0.6321 - val_loss: 9.4509 - val_accuracy: 0.2786\n",
            "Epoch 968/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.3238 - accuracy: 0.6384 - val_loss: 9.4798 - val_accuracy: 0.2679\n",
            "Epoch 969/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 1.3233 - accuracy: 0.6438 - val_loss: 9.4551 - val_accuracy: 0.2643\n",
            "Epoch 970/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.3163 - accuracy: 0.6509 - val_loss: 9.4965 - val_accuracy: 0.2536\n",
            "Epoch 971/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.3102 - accuracy: 0.6518 - val_loss: 9.5200 - val_accuracy: 0.2536\n",
            "Epoch 972/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.3138 - accuracy: 0.6366 - val_loss: 9.5213 - val_accuracy: 0.2714\n",
            "Epoch 973/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.3121 - accuracy: 0.6491 - val_loss: 9.5451 - val_accuracy: 0.2679\n",
            "Epoch 974/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.3035 - accuracy: 0.6536 - val_loss: 9.5483 - val_accuracy: 0.2500\n",
            "Epoch 975/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.3170 - accuracy: 0.6429 - val_loss: 9.5352 - val_accuracy: 0.2536\n",
            "Epoch 976/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.2996 - accuracy: 0.6562 - val_loss: 9.5594 - val_accuracy: 0.2607\n",
            "Epoch 977/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.3004 - accuracy: 0.6482 - val_loss: 9.5603 - val_accuracy: 0.2821\n",
            "Epoch 978/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.2974 - accuracy: 0.6500 - val_loss: 9.5987 - val_accuracy: 0.2643\n",
            "Epoch 979/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.2918 - accuracy: 0.6491 - val_loss: 9.6146 - val_accuracy: 0.2643\n",
            "Epoch 980/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.2943 - accuracy: 0.6491 - val_loss: 9.6132 - val_accuracy: 0.2643\n",
            "Epoch 981/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.2922 - accuracy: 0.6438 - val_loss: 9.5838 - val_accuracy: 0.2821\n",
            "Epoch 982/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.2839 - accuracy: 0.6571 - val_loss: 9.6362 - val_accuracy: 0.2750\n",
            "Epoch 983/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.2851 - accuracy: 0.6545 - val_loss: 9.6451 - val_accuracy: 0.2536\n",
            "Epoch 984/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.2801 - accuracy: 0.6607 - val_loss: 9.6360 - val_accuracy: 0.2714\n",
            "Epoch 985/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.2720 - accuracy: 0.6473 - val_loss: 9.6382 - val_accuracy: 0.2643\n",
            "Epoch 986/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.2725 - accuracy: 0.6705 - val_loss: 9.6463 - val_accuracy: 0.2679\n",
            "Epoch 987/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.2702 - accuracy: 0.6616 - val_loss: 9.6673 - val_accuracy: 0.2643\n",
            "Epoch 988/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.2656 - accuracy: 0.6616 - val_loss: 9.6976 - val_accuracy: 0.2607\n",
            "Epoch 989/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.2705 - accuracy: 0.6705 - val_loss: 9.6898 - val_accuracy: 0.2607\n",
            "Epoch 990/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.2642 - accuracy: 0.6562 - val_loss: 9.6908 - val_accuracy: 0.2571\n",
            "Epoch 991/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.2615 - accuracy: 0.6536 - val_loss: 9.7254 - val_accuracy: 0.2714\n",
            "Epoch 992/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.2542 - accuracy: 0.6580 - val_loss: 9.7424 - val_accuracy: 0.2750\n",
            "Epoch 993/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.2522 - accuracy: 0.6580 - val_loss: 9.7204 - val_accuracy: 0.2679\n",
            "Epoch 994/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.2473 - accuracy: 0.6741 - val_loss: 9.7358 - val_accuracy: 0.2679\n",
            "Epoch 995/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.2478 - accuracy: 0.6777 - val_loss: 9.7493 - val_accuracy: 0.2714\n",
            "Epoch 996/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.2445 - accuracy: 0.6634 - val_loss: 9.7493 - val_accuracy: 0.2643\n",
            "Epoch 997/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.2415 - accuracy: 0.6705 - val_loss: 9.7737 - val_accuracy: 0.2500\n",
            "Epoch 998/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.2426 - accuracy: 0.6634 - val_loss: 9.7542 - val_accuracy: 0.2857\n",
            "Epoch 999/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.2366 - accuracy: 0.6732 - val_loss: 9.7931 - val_accuracy: 0.2714\n",
            "Epoch 1000/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.2368 - accuracy: 0.6562 - val_loss: 9.8137 - val_accuracy: 0.2571\n",
            "Epoch 1001/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.2286 - accuracy: 0.6580 - val_loss: 9.8006 - val_accuracy: 0.2714\n",
            "Epoch 1002/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 1.2320 - accuracy: 0.6705 - val_loss: 9.8067 - val_accuracy: 0.2679\n",
            "Epoch 1003/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.2268 - accuracy: 0.6705 - val_loss: 9.8297 - val_accuracy: 0.2750\n",
            "Epoch 1004/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.2305 - accuracy: 0.6670 - val_loss: 9.8098 - val_accuracy: 0.2750\n",
            "Epoch 1005/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.2198 - accuracy: 0.6875 - val_loss: 9.8803 - val_accuracy: 0.2714\n",
            "Epoch 1006/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.2164 - accuracy: 0.6750 - val_loss: 9.8405 - val_accuracy: 0.2786\n",
            "Epoch 1007/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.2135 - accuracy: 0.6804 - val_loss: 9.8781 - val_accuracy: 0.2714\n",
            "Epoch 1008/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.2098 - accuracy: 0.6714 - val_loss: 9.8947 - val_accuracy: 0.2750\n",
            "Epoch 1009/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.2119 - accuracy: 0.6839 - val_loss: 9.9352 - val_accuracy: 0.2571\n",
            "Epoch 1010/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.2133 - accuracy: 0.6687 - val_loss: 9.9190 - val_accuracy: 0.2714\n",
            "Epoch 1011/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.2038 - accuracy: 0.6750 - val_loss: 9.9266 - val_accuracy: 0.2500\n",
            "Epoch 1012/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.2032 - accuracy: 0.6795 - val_loss: 9.9151 - val_accuracy: 0.2643\n",
            "Epoch 1013/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.1984 - accuracy: 0.6652 - val_loss: 9.9245 - val_accuracy: 0.2679\n",
            "Epoch 1014/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.1975 - accuracy: 0.6911 - val_loss: 9.9320 - val_accuracy: 0.2857\n",
            "Epoch 1015/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.1955 - accuracy: 0.6786 - val_loss: 9.9361 - val_accuracy: 0.2750\n",
            "Epoch 1016/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.1875 - accuracy: 0.6795 - val_loss: 9.9651 - val_accuracy: 0.2643\n",
            "Epoch 1017/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.1942 - accuracy: 0.6625 - val_loss: 9.9395 - val_accuracy: 0.2679\n",
            "Epoch 1018/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 1.1857 - accuracy: 0.6964 - val_loss: 9.9730 - val_accuracy: 0.2679\n",
            "Epoch 1019/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.1790 - accuracy: 0.6982 - val_loss: 9.9613 - val_accuracy: 0.2714\n",
            "Epoch 1020/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.1785 - accuracy: 0.6884 - val_loss: 9.9849 - val_accuracy: 0.2893\n",
            "Epoch 1021/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.1803 - accuracy: 0.6866 - val_loss: 9.9995 - val_accuracy: 0.2750\n",
            "Epoch 1022/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.1722 - accuracy: 0.6911 - val_loss: 10.0315 - val_accuracy: 0.2643\n",
            "Epoch 1023/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.1716 - accuracy: 0.6982 - val_loss: 10.0270 - val_accuracy: 0.2821\n",
            "Epoch 1024/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.1655 - accuracy: 0.6768 - val_loss: 10.0142 - val_accuracy: 0.2929\n",
            "Epoch 1025/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.1721 - accuracy: 0.6848 - val_loss: 10.0277 - val_accuracy: 0.2714\n",
            "Epoch 1026/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 1.1682 - accuracy: 0.6884 - val_loss: 10.0644 - val_accuracy: 0.2786\n",
            "Epoch 1027/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.1589 - accuracy: 0.6839 - val_loss: 10.0629 - val_accuracy: 0.2786\n",
            "Epoch 1028/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.1558 - accuracy: 0.6857 - val_loss: 10.1032 - val_accuracy: 0.2857\n",
            "Epoch 1029/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.1596 - accuracy: 0.6857 - val_loss: 10.1025 - val_accuracy: 0.2786\n",
            "Epoch 1030/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.1474 - accuracy: 0.6929 - val_loss: 10.1336 - val_accuracy: 0.2786\n",
            "Epoch 1031/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.1516 - accuracy: 0.6982 - val_loss: 10.1062 - val_accuracy: 0.2893\n",
            "Epoch 1032/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.1447 - accuracy: 0.6857 - val_loss: 10.1233 - val_accuracy: 0.2821\n",
            "Epoch 1033/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 1.1466 - accuracy: 0.6938 - val_loss: 10.1555 - val_accuracy: 0.2786\n",
            "Epoch 1034/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.1417 - accuracy: 0.6955 - val_loss: 10.1538 - val_accuracy: 0.2893\n",
            "Epoch 1035/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.1413 - accuracy: 0.6991 - val_loss: 10.1777 - val_accuracy: 0.2893\n",
            "Epoch 1036/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.1410 - accuracy: 0.7009 - val_loss: 10.1421 - val_accuracy: 0.3071\n",
            "Epoch 1037/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.1341 - accuracy: 0.7000 - val_loss: 10.1313 - val_accuracy: 0.3071\n",
            "Epoch 1038/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.1285 - accuracy: 0.7000 - val_loss: 10.1748 - val_accuracy: 0.2893\n",
            "Epoch 1039/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.1190 - accuracy: 0.7116 - val_loss: 10.1749 - val_accuracy: 0.2893\n",
            "Epoch 1040/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.1252 - accuracy: 0.6946 - val_loss: 10.2354 - val_accuracy: 0.2893\n",
            "Epoch 1041/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.1226 - accuracy: 0.7036 - val_loss: 10.2213 - val_accuracy: 0.2821\n",
            "Epoch 1042/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.1196 - accuracy: 0.6938 - val_loss: 10.2425 - val_accuracy: 0.2929\n",
            "Epoch 1043/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.1213 - accuracy: 0.7045 - val_loss: 10.2116 - val_accuracy: 0.2893\n",
            "Epoch 1044/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.1159 - accuracy: 0.7063 - val_loss: 10.2366 - val_accuracy: 0.2821\n",
            "Epoch 1045/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.1108 - accuracy: 0.7018 - val_loss: 10.2316 - val_accuracy: 0.2964\n",
            "Epoch 1046/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.1130 - accuracy: 0.7071 - val_loss: 10.2567 - val_accuracy: 0.2893\n",
            "Epoch 1047/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.1112 - accuracy: 0.7027 - val_loss: 10.2583 - val_accuracy: 0.2750\n",
            "Epoch 1048/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.1063 - accuracy: 0.7116 - val_loss: 10.2649 - val_accuracy: 0.3000\n",
            "Epoch 1049/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 1.1047 - accuracy: 0.7161 - val_loss: 10.2697 - val_accuracy: 0.2857\n",
            "Epoch 1050/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.1011 - accuracy: 0.7205 - val_loss: 10.3133 - val_accuracy: 0.2929\n",
            "Epoch 1051/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.0964 - accuracy: 0.7107 - val_loss: 10.3332 - val_accuracy: 0.2964\n",
            "Epoch 1052/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.0983 - accuracy: 0.7080 - val_loss: 10.3086 - val_accuracy: 0.2929\n",
            "Epoch 1053/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.0886 - accuracy: 0.7179 - val_loss: 10.3336 - val_accuracy: 0.2929\n",
            "Epoch 1054/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.0930 - accuracy: 0.7045 - val_loss: 10.3219 - val_accuracy: 0.2929\n",
            "Epoch 1055/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.0883 - accuracy: 0.7134 - val_loss: 10.3497 - val_accuracy: 0.3071\n",
            "Epoch 1056/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.0885 - accuracy: 0.7098 - val_loss: 10.3275 - val_accuracy: 0.2964\n",
            "Epoch 1057/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.0812 - accuracy: 0.7152 - val_loss: 10.3832 - val_accuracy: 0.3036\n",
            "Epoch 1058/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.0809 - accuracy: 0.7152 - val_loss: 10.3530 - val_accuracy: 0.3036\n",
            "Epoch 1059/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.0781 - accuracy: 0.7214 - val_loss: 10.3581 - val_accuracy: 0.3107\n",
            "Epoch 1060/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.0743 - accuracy: 0.7152 - val_loss: 10.3855 - val_accuracy: 0.2929\n",
            "Epoch 1061/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.0715 - accuracy: 0.7089 - val_loss: 10.3917 - val_accuracy: 0.2964\n",
            "Epoch 1062/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.0696 - accuracy: 0.7107 - val_loss: 10.4505 - val_accuracy: 0.2786\n",
            "Epoch 1063/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.0673 - accuracy: 0.7223 - val_loss: 10.3933 - val_accuracy: 0.2929\n",
            "Epoch 1064/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.0575 - accuracy: 0.7250 - val_loss: 10.4275 - val_accuracy: 0.2929\n",
            "Epoch 1065/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.0605 - accuracy: 0.7188 - val_loss: 10.4340 - val_accuracy: 0.3071\n",
            "Epoch 1066/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.0616 - accuracy: 0.7223 - val_loss: 10.5115 - val_accuracy: 0.2964\n",
            "Epoch 1067/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.0591 - accuracy: 0.7107 - val_loss: 10.4833 - val_accuracy: 0.2964\n",
            "Epoch 1068/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.0517 - accuracy: 0.7402 - val_loss: 10.5024 - val_accuracy: 0.2786\n",
            "Epoch 1069/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.0463 - accuracy: 0.7348 - val_loss: 10.4814 - val_accuracy: 0.3000\n",
            "Epoch 1070/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.0490 - accuracy: 0.7223 - val_loss: 10.4977 - val_accuracy: 0.2929\n",
            "Epoch 1071/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.0379 - accuracy: 0.7232 - val_loss: 10.4894 - val_accuracy: 0.2964\n",
            "Epoch 1072/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.0415 - accuracy: 0.7196 - val_loss: 10.5144 - val_accuracy: 0.2857\n",
            "Epoch 1073/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.0399 - accuracy: 0.7241 - val_loss: 10.5345 - val_accuracy: 0.2893\n",
            "Epoch 1074/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.0340 - accuracy: 0.7232 - val_loss: 10.5384 - val_accuracy: 0.3036\n",
            "Epoch 1075/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.0281 - accuracy: 0.7107 - val_loss: 10.5422 - val_accuracy: 0.3000\n",
            "Epoch 1076/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.0293 - accuracy: 0.7473 - val_loss: 10.5284 - val_accuracy: 0.3036\n",
            "Epoch 1077/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 1.0291 - accuracy: 0.7348 - val_loss: 10.5572 - val_accuracy: 0.2964\n",
            "Epoch 1078/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.0205 - accuracy: 0.7286 - val_loss: 10.5911 - val_accuracy: 0.2786\n",
            "Epoch 1079/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.0251 - accuracy: 0.7214 - val_loss: 10.5573 - val_accuracy: 0.3214\n",
            "Epoch 1080/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.0145 - accuracy: 0.7366 - val_loss: 10.5993 - val_accuracy: 0.3071\n",
            "Epoch 1081/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.0192 - accuracy: 0.7179 - val_loss: 10.6305 - val_accuracy: 0.2929\n",
            "Epoch 1082/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.0125 - accuracy: 0.7366 - val_loss: 10.5777 - val_accuracy: 0.3179\n",
            "Epoch 1083/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.0166 - accuracy: 0.7339 - val_loss: 10.6259 - val_accuracy: 0.2964\n",
            "Epoch 1084/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.0083 - accuracy: 0.7339 - val_loss: 10.6382 - val_accuracy: 0.3071\n",
            "Epoch 1085/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.0046 - accuracy: 0.7295 - val_loss: 10.6725 - val_accuracy: 0.3179\n",
            "Epoch 1086/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.0055 - accuracy: 0.7473 - val_loss: 10.6509 - val_accuracy: 0.3250\n",
            "Epoch 1087/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.9961 - accuracy: 0.7411 - val_loss: 10.6824 - val_accuracy: 0.3036\n",
            "Epoch 1088/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.9980 - accuracy: 0.7500 - val_loss: 10.7204 - val_accuracy: 0.3000\n",
            "Epoch 1089/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.9932 - accuracy: 0.7366 - val_loss: 10.7085 - val_accuracy: 0.3000\n",
            "Epoch 1090/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.9950 - accuracy: 0.7482 - val_loss: 10.6909 - val_accuracy: 0.3357\n",
            "Epoch 1091/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.9886 - accuracy: 0.7375 - val_loss: 10.7341 - val_accuracy: 0.3143\n",
            "Epoch 1092/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.9967 - accuracy: 0.7384 - val_loss: 10.7417 - val_accuracy: 0.3107\n",
            "Epoch 1093/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.9871 - accuracy: 0.7455 - val_loss: 10.7352 - val_accuracy: 0.2964\n",
            "Epoch 1094/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.9787 - accuracy: 0.7482 - val_loss: 10.7317 - val_accuracy: 0.3250\n",
            "Epoch 1095/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.9851 - accuracy: 0.7411 - val_loss: 10.7741 - val_accuracy: 0.3000\n",
            "Epoch 1096/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.9765 - accuracy: 0.7446 - val_loss: 10.7994 - val_accuracy: 0.3036\n",
            "Epoch 1097/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.9804 - accuracy: 0.7357 - val_loss: 10.7890 - val_accuracy: 0.3036\n",
            "Epoch 1098/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.9759 - accuracy: 0.7554 - val_loss: 10.8002 - val_accuracy: 0.3179\n",
            "Epoch 1099/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.9648 - accuracy: 0.7446 - val_loss: 10.7931 - val_accuracy: 0.3179\n",
            "Epoch 1100/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.9688 - accuracy: 0.7607 - val_loss: 10.7941 - val_accuracy: 0.3250\n",
            "Epoch 1101/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.9721 - accuracy: 0.7420 - val_loss: 10.8132 - val_accuracy: 0.3286\n",
            "Epoch 1102/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.9695 - accuracy: 0.7554 - val_loss: 10.8094 - val_accuracy: 0.3214\n",
            "Epoch 1103/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.9606 - accuracy: 0.7571 - val_loss: 10.8173 - val_accuracy: 0.3179\n",
            "Epoch 1104/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.9627 - accuracy: 0.7571 - val_loss: 10.8365 - val_accuracy: 0.3250\n",
            "Epoch 1105/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.9524 - accuracy: 0.7518 - val_loss: 10.8520 - val_accuracy: 0.3000\n",
            "Epoch 1106/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.9495 - accuracy: 0.7598 - val_loss: 10.8652 - val_accuracy: 0.3214\n",
            "Epoch 1107/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.9457 - accuracy: 0.7589 - val_loss: 10.8804 - val_accuracy: 0.3071\n",
            "Epoch 1108/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.9515 - accuracy: 0.7589 - val_loss: 10.8975 - val_accuracy: 0.3250\n",
            "Epoch 1109/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.9491 - accuracy: 0.7554 - val_loss: 10.8865 - val_accuracy: 0.3214\n",
            "Epoch 1110/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.9442 - accuracy: 0.7536 - val_loss: 10.9022 - val_accuracy: 0.3321\n",
            "Epoch 1111/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.9385 - accuracy: 0.7607 - val_loss: 10.8829 - val_accuracy: 0.3179\n",
            "Epoch 1112/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.9296 - accuracy: 0.7670 - val_loss: 10.9600 - val_accuracy: 0.3107\n",
            "Epoch 1113/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.9399 - accuracy: 0.7518 - val_loss: 10.9217 - val_accuracy: 0.3286\n",
            "Epoch 1114/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.9364 - accuracy: 0.7509 - val_loss: 10.9524 - val_accuracy: 0.3214\n",
            "Epoch 1115/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.9312 - accuracy: 0.7670 - val_loss: 10.9566 - val_accuracy: 0.3143\n",
            "Epoch 1116/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.9237 - accuracy: 0.7679 - val_loss: 10.9761 - val_accuracy: 0.3321\n",
            "Epoch 1117/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.9277 - accuracy: 0.7634 - val_loss: 10.9959 - val_accuracy: 0.3286\n",
            "Epoch 1118/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.9210 - accuracy: 0.7714 - val_loss: 10.9731 - val_accuracy: 0.3214\n",
            "Epoch 1119/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.9236 - accuracy: 0.7589 - val_loss: 10.9872 - val_accuracy: 0.3357\n",
            "Epoch 1120/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.9209 - accuracy: 0.7598 - val_loss: 11.0061 - val_accuracy: 0.3071\n",
            "Epoch 1121/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.9158 - accuracy: 0.7616 - val_loss: 11.0130 - val_accuracy: 0.3179\n",
            "Epoch 1122/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.9146 - accuracy: 0.7554 - val_loss: 10.9975 - val_accuracy: 0.3429\n",
            "Epoch 1123/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.9060 - accuracy: 0.7679 - val_loss: 11.0088 - val_accuracy: 0.3357\n",
            "Epoch 1124/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.9137 - accuracy: 0.7482 - val_loss: 11.0084 - val_accuracy: 0.3357\n",
            "Epoch 1125/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.9056 - accuracy: 0.7804 - val_loss: 11.0793 - val_accuracy: 0.3214\n",
            "Epoch 1126/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.9036 - accuracy: 0.7705 - val_loss: 11.0790 - val_accuracy: 0.3071\n",
            "Epoch 1127/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.9015 - accuracy: 0.7741 - val_loss: 11.0590 - val_accuracy: 0.3143\n",
            "Epoch 1128/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.8999 - accuracy: 0.7634 - val_loss: 11.0747 - val_accuracy: 0.3357\n",
            "Epoch 1129/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.8973 - accuracy: 0.7723 - val_loss: 11.1218 - val_accuracy: 0.3214\n",
            "Epoch 1130/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.8970 - accuracy: 0.7723 - val_loss: 11.0875 - val_accuracy: 0.3321\n",
            "Epoch 1131/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.8916 - accuracy: 0.7732 - val_loss: 11.1046 - val_accuracy: 0.3214\n",
            "Epoch 1132/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.8938 - accuracy: 0.7759 - val_loss: 11.1138 - val_accuracy: 0.3143\n",
            "Epoch 1133/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.8884 - accuracy: 0.7688 - val_loss: 11.1294 - val_accuracy: 0.3250\n",
            "Epoch 1134/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.8812 - accuracy: 0.7768 - val_loss: 11.1268 - val_accuracy: 0.3250\n",
            "Epoch 1135/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.8812 - accuracy: 0.7750 - val_loss: 11.1760 - val_accuracy: 0.3357\n",
            "Epoch 1136/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.8843 - accuracy: 0.7714 - val_loss: 11.1620 - val_accuracy: 0.3393\n",
            "Epoch 1137/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.8787 - accuracy: 0.7750 - val_loss: 11.1529 - val_accuracy: 0.3286\n",
            "Epoch 1138/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.8736 - accuracy: 0.7812 - val_loss: 11.2580 - val_accuracy: 0.3179\n",
            "Epoch 1139/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.8727 - accuracy: 0.7777 - val_loss: 11.1850 - val_accuracy: 0.3500\n",
            "Epoch 1140/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.8705 - accuracy: 0.7741 - val_loss: 11.2040 - val_accuracy: 0.3429\n",
            "Epoch 1141/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.8656 - accuracy: 0.7830 - val_loss: 11.2775 - val_accuracy: 0.3321\n",
            "Epoch 1142/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.8661 - accuracy: 0.7804 - val_loss: 11.2462 - val_accuracy: 0.3357\n",
            "Epoch 1143/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.8540 - accuracy: 0.7902 - val_loss: 11.2526 - val_accuracy: 0.3250\n",
            "Epoch 1144/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.8586 - accuracy: 0.7857 - val_loss: 11.2776 - val_accuracy: 0.3214\n",
            "Epoch 1145/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.8585 - accuracy: 0.7946 - val_loss: 11.3200 - val_accuracy: 0.3143\n",
            "Epoch 1146/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.8553 - accuracy: 0.7786 - val_loss: 11.2524 - val_accuracy: 0.3393\n",
            "Epoch 1147/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.8534 - accuracy: 0.7902 - val_loss: 11.3293 - val_accuracy: 0.3107\n",
            "Epoch 1148/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.8515 - accuracy: 0.7937 - val_loss: 11.2911 - val_accuracy: 0.3286\n",
            "Epoch 1149/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.8472 - accuracy: 0.7866 - val_loss: 11.3073 - val_accuracy: 0.3214\n",
            "Epoch 1150/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.8518 - accuracy: 0.7893 - val_loss: 11.3352 - val_accuracy: 0.3357\n",
            "Epoch 1151/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.8384 - accuracy: 0.8027 - val_loss: 11.2910 - val_accuracy: 0.3321\n",
            "Epoch 1152/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.8447 - accuracy: 0.7946 - val_loss: 11.3444 - val_accuracy: 0.3321\n",
            "Epoch 1153/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.8386 - accuracy: 0.7768 - val_loss: 11.3445 - val_accuracy: 0.3393\n",
            "Epoch 1154/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.8360 - accuracy: 0.8045 - val_loss: 11.3421 - val_accuracy: 0.3357\n",
            "Epoch 1155/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.8407 - accuracy: 0.7884 - val_loss: 11.3806 - val_accuracy: 0.3393\n",
            "Epoch 1156/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.8392 - accuracy: 0.7848 - val_loss: 11.3967 - val_accuracy: 0.3357\n",
            "Epoch 1157/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.8381 - accuracy: 0.7920 - val_loss: 11.4068 - val_accuracy: 0.3214\n",
            "Epoch 1158/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.8295 - accuracy: 0.7955 - val_loss: 11.3754 - val_accuracy: 0.3357\n",
            "Epoch 1159/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.8289 - accuracy: 0.7982 - val_loss: 11.3748 - val_accuracy: 0.3357\n",
            "Epoch 1160/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.8288 - accuracy: 0.8000 - val_loss: 11.4289 - val_accuracy: 0.3286\n",
            "Epoch 1161/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.8237 - accuracy: 0.7902 - val_loss: 11.4251 - val_accuracy: 0.3357\n",
            "Epoch 1162/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.8185 - accuracy: 0.8036 - val_loss: 11.4337 - val_accuracy: 0.3500\n",
            "Epoch 1163/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.8191 - accuracy: 0.7982 - val_loss: 11.4591 - val_accuracy: 0.3214\n",
            "Epoch 1164/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.8156 - accuracy: 0.7982 - val_loss: 11.4895 - val_accuracy: 0.3357\n",
            "Epoch 1165/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.8145 - accuracy: 0.7982 - val_loss: 11.4872 - val_accuracy: 0.3250\n",
            "Epoch 1166/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.8119 - accuracy: 0.8036 - val_loss: 11.4673 - val_accuracy: 0.3393\n",
            "Epoch 1167/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.8077 - accuracy: 0.8027 - val_loss: 11.5007 - val_accuracy: 0.3321\n",
            "Epoch 1168/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.8168 - accuracy: 0.7982 - val_loss: 11.4977 - val_accuracy: 0.3143\n",
            "Epoch 1169/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.8061 - accuracy: 0.8036 - val_loss: 11.4959 - val_accuracy: 0.3393\n",
            "Epoch 1170/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.8010 - accuracy: 0.8080 - val_loss: 11.5484 - val_accuracy: 0.3286\n",
            "Epoch 1171/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7977 - accuracy: 0.8009 - val_loss: 11.5473 - val_accuracy: 0.3286\n",
            "Epoch 1172/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.8023 - accuracy: 0.8027 - val_loss: 11.5408 - val_accuracy: 0.3357\n",
            "Epoch 1173/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.7865 - accuracy: 0.8080 - val_loss: 11.5542 - val_accuracy: 0.3321\n",
            "Epoch 1174/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7906 - accuracy: 0.8143 - val_loss: 11.6069 - val_accuracy: 0.3429\n",
            "Epoch 1175/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7923 - accuracy: 0.8000 - val_loss: 11.5497 - val_accuracy: 0.3357\n",
            "Epoch 1176/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7860 - accuracy: 0.8116 - val_loss: 11.5306 - val_accuracy: 0.3393\n",
            "Epoch 1177/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7851 - accuracy: 0.8107 - val_loss: 11.5933 - val_accuracy: 0.3286\n",
            "Epoch 1178/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7851 - accuracy: 0.8179 - val_loss: 11.6182 - val_accuracy: 0.3357\n",
            "Epoch 1179/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7834 - accuracy: 0.8045 - val_loss: 11.6456 - val_accuracy: 0.3536\n",
            "Epoch 1180/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7752 - accuracy: 0.8089 - val_loss: 11.6476 - val_accuracy: 0.3357\n",
            "Epoch 1181/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7797 - accuracy: 0.8036 - val_loss: 11.6614 - val_accuracy: 0.3321\n",
            "Epoch 1182/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7772 - accuracy: 0.8196 - val_loss: 11.6310 - val_accuracy: 0.3429\n",
            "Epoch 1183/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7780 - accuracy: 0.8188 - val_loss: 11.6261 - val_accuracy: 0.3643\n",
            "Epoch 1184/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7676 - accuracy: 0.8277 - val_loss: 11.6590 - val_accuracy: 0.3464\n",
            "Epoch 1185/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7716 - accuracy: 0.8179 - val_loss: 11.6746 - val_accuracy: 0.3429\n",
            "Epoch 1186/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.7674 - accuracy: 0.8125 - val_loss: 11.6535 - val_accuracy: 0.3357\n",
            "Epoch 1187/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7613 - accuracy: 0.8214 - val_loss: 11.6806 - val_accuracy: 0.3500\n",
            "Epoch 1188/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7590 - accuracy: 0.8170 - val_loss: 11.7151 - val_accuracy: 0.3357\n",
            "Epoch 1189/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7588 - accuracy: 0.8179 - val_loss: 11.7115 - val_accuracy: 0.3429\n",
            "Epoch 1190/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7566 - accuracy: 0.8241 - val_loss: 11.7433 - val_accuracy: 0.3429\n",
            "Epoch 1191/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7539 - accuracy: 0.8348 - val_loss: 11.7061 - val_accuracy: 0.3429\n",
            "Epoch 1192/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7490 - accuracy: 0.8277 - val_loss: 11.7243 - val_accuracy: 0.3393\n",
            "Epoch 1193/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7540 - accuracy: 0.8304 - val_loss: 11.7673 - val_accuracy: 0.3393\n",
            "Epoch 1194/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7475 - accuracy: 0.8295 - val_loss: 11.7456 - val_accuracy: 0.3429\n",
            "Epoch 1195/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7452 - accuracy: 0.8205 - val_loss: 11.7553 - val_accuracy: 0.3393\n",
            "Epoch 1196/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.7437 - accuracy: 0.8196 - val_loss: 11.8179 - val_accuracy: 0.3286\n",
            "Epoch 1197/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7439 - accuracy: 0.8277 - val_loss: 11.8069 - val_accuracy: 0.3250\n",
            "Epoch 1198/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7381 - accuracy: 0.8330 - val_loss: 11.8082 - val_accuracy: 0.3250\n",
            "Epoch 1199/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7321 - accuracy: 0.8205 - val_loss: 11.7823 - val_accuracy: 0.3464\n",
            "Epoch 1200/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7346 - accuracy: 0.8313 - val_loss: 11.8290 - val_accuracy: 0.3357\n",
            "Epoch 1201/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7379 - accuracy: 0.8170 - val_loss: 11.8581 - val_accuracy: 0.3500\n",
            "Epoch 1202/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7328 - accuracy: 0.8205 - val_loss: 11.8575 - val_accuracy: 0.3429\n",
            "Epoch 1203/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7264 - accuracy: 0.8330 - val_loss: 11.8580 - val_accuracy: 0.3607\n",
            "Epoch 1204/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7224 - accuracy: 0.8339 - val_loss: 11.8551 - val_accuracy: 0.3464\n",
            "Epoch 1205/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7230 - accuracy: 0.8357 - val_loss: 11.9179 - val_accuracy: 0.3607\n",
            "Epoch 1206/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7206 - accuracy: 0.8304 - val_loss: 11.8787 - val_accuracy: 0.3500\n",
            "Epoch 1207/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.7191 - accuracy: 0.8259 - val_loss: 11.8872 - val_accuracy: 0.3607\n",
            "Epoch 1208/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7200 - accuracy: 0.8330 - val_loss: 11.8875 - val_accuracy: 0.3571\n",
            "Epoch 1209/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.7163 - accuracy: 0.8321 - val_loss: 11.9277 - val_accuracy: 0.3500\n",
            "Epoch 1210/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7139 - accuracy: 0.8304 - val_loss: 11.9224 - val_accuracy: 0.3571\n",
            "Epoch 1211/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7134 - accuracy: 0.8420 - val_loss: 11.9360 - val_accuracy: 0.3643\n",
            "Epoch 1212/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7065 - accuracy: 0.8357 - val_loss: 11.9653 - val_accuracy: 0.3464\n",
            "Epoch 1213/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7112 - accuracy: 0.8393 - val_loss: 11.9404 - val_accuracy: 0.3607\n",
            "Epoch 1214/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7097 - accuracy: 0.8366 - val_loss: 11.9451 - val_accuracy: 0.3607\n",
            "Epoch 1215/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7029 - accuracy: 0.8241 - val_loss: 11.9670 - val_accuracy: 0.3500\n",
            "Epoch 1216/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.6981 - accuracy: 0.8375 - val_loss: 12.0015 - val_accuracy: 0.3500\n",
            "Epoch 1217/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.6976 - accuracy: 0.8393 - val_loss: 12.0133 - val_accuracy: 0.3571\n",
            "Epoch 1218/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.6994 - accuracy: 0.8339 - val_loss: 12.0651 - val_accuracy: 0.3500\n",
            "Epoch 1219/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.6983 - accuracy: 0.8357 - val_loss: 12.0447 - val_accuracy: 0.3429\n",
            "Epoch 1220/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.6916 - accuracy: 0.8438 - val_loss: 12.0248 - val_accuracy: 0.3643\n",
            "Epoch 1221/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.6921 - accuracy: 0.8339 - val_loss: 12.0511 - val_accuracy: 0.3571\n",
            "Epoch 1222/2000\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 0.6926 - accuracy: 0.8420 - val_loss: 12.0682 - val_accuracy: 0.3500\n",
            "Epoch 1223/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.6852 - accuracy: 0.8402 - val_loss: 12.0487 - val_accuracy: 0.3500\n",
            "Epoch 1224/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.6796 - accuracy: 0.8393 - val_loss: 12.0577 - val_accuracy: 0.3571\n",
            "Epoch 1225/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.6818 - accuracy: 0.8473 - val_loss: 12.0892 - val_accuracy: 0.3429\n",
            "Epoch 1226/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.6823 - accuracy: 0.8455 - val_loss: 12.1127 - val_accuracy: 0.3536\n",
            "Epoch 1227/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.6768 - accuracy: 0.8509 - val_loss: 12.1171 - val_accuracy: 0.3607\n",
            "Epoch 1228/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.6755 - accuracy: 0.8482 - val_loss: 12.1691 - val_accuracy: 0.3500\n",
            "Epoch 1229/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.6744 - accuracy: 0.8518 - val_loss: 12.1399 - val_accuracy: 0.3536\n",
            "Epoch 1230/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.6673 - accuracy: 0.8429 - val_loss: 12.1062 - val_accuracy: 0.3643\n",
            "Epoch 1231/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.6630 - accuracy: 0.8491 - val_loss: 12.1513 - val_accuracy: 0.3571\n",
            "Epoch 1232/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.6704 - accuracy: 0.8527 - val_loss: 12.1780 - val_accuracy: 0.3607\n",
            "Epoch 1233/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.6643 - accuracy: 0.8473 - val_loss: 12.2248 - val_accuracy: 0.3429\n",
            "Epoch 1234/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.6706 - accuracy: 0.8500 - val_loss: 12.2113 - val_accuracy: 0.3607\n",
            "Epoch 1235/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.6598 - accuracy: 0.8473 - val_loss: 12.1937 - val_accuracy: 0.3643\n",
            "Epoch 1236/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.6644 - accuracy: 0.8446 - val_loss: 12.2137 - val_accuracy: 0.3643\n",
            "Epoch 1237/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.6561 - accuracy: 0.8625 - val_loss: 12.2207 - val_accuracy: 0.3679\n",
            "Epoch 1238/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.6580 - accuracy: 0.8500 - val_loss: 12.1825 - val_accuracy: 0.3571\n",
            "Epoch 1239/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.6561 - accuracy: 0.8545 - val_loss: 12.2452 - val_accuracy: 0.3571\n",
            "Epoch 1240/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.6565 - accuracy: 0.8482 - val_loss: 12.2690 - val_accuracy: 0.3500\n",
            "Epoch 1241/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.6508 - accuracy: 0.8464 - val_loss: 12.2656 - val_accuracy: 0.3643\n",
            "Epoch 1242/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.6471 - accuracy: 0.8589 - val_loss: 12.2617 - val_accuracy: 0.3571\n",
            "Epoch 1243/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.6494 - accuracy: 0.8491 - val_loss: 12.2779 - val_accuracy: 0.3536\n",
            "Epoch 1244/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.6389 - accuracy: 0.8661 - val_loss: 12.2998 - val_accuracy: 0.3464\n",
            "Epoch 1245/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.6459 - accuracy: 0.8634 - val_loss: 12.2735 - val_accuracy: 0.3500\n",
            "Epoch 1246/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.6372 - accuracy: 0.8589 - val_loss: 12.2980 - val_accuracy: 0.3643\n",
            "Epoch 1247/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.6388 - accuracy: 0.8527 - val_loss: 12.3171 - val_accuracy: 0.3643\n",
            "Epoch 1248/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.6385 - accuracy: 0.8634 - val_loss: 12.2952 - val_accuracy: 0.3607\n",
            "Epoch 1249/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.6377 - accuracy: 0.8580 - val_loss: 12.3169 - val_accuracy: 0.3679\n",
            "Epoch 1250/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.6337 - accuracy: 0.8607 - val_loss: 12.3397 - val_accuracy: 0.3679\n",
            "Epoch 1251/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.6320 - accuracy: 0.8616 - val_loss: 12.3574 - val_accuracy: 0.3500\n",
            "Epoch 1252/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.6315 - accuracy: 0.8643 - val_loss: 12.3675 - val_accuracy: 0.3643\n",
            "Epoch 1253/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.6309 - accuracy: 0.8589 - val_loss: 12.3897 - val_accuracy: 0.3500\n",
            "Epoch 1254/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.6242 - accuracy: 0.8562 - val_loss: 12.4443 - val_accuracy: 0.3679\n",
            "Epoch 1255/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.6270 - accuracy: 0.8634 - val_loss: 12.4032 - val_accuracy: 0.3500\n",
            "Epoch 1256/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.6249 - accuracy: 0.8562 - val_loss: 12.4206 - val_accuracy: 0.3643\n",
            "Epoch 1257/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.6166 - accuracy: 0.8652 - val_loss: 12.3853 - val_accuracy: 0.3643\n",
            "Epoch 1258/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.6195 - accuracy: 0.8723 - val_loss: 12.4343 - val_accuracy: 0.3679\n",
            "Epoch 1259/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.6116 - accuracy: 0.8679 - val_loss: 12.4460 - val_accuracy: 0.3571\n",
            "Epoch 1260/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.6110 - accuracy: 0.8705 - val_loss: 12.4495 - val_accuracy: 0.3750\n",
            "Epoch 1261/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.6161 - accuracy: 0.8643 - val_loss: 12.4583 - val_accuracy: 0.3500\n",
            "Epoch 1262/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.6093 - accuracy: 0.8670 - val_loss: 12.4918 - val_accuracy: 0.3571\n",
            "Epoch 1263/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.6155 - accuracy: 0.8670 - val_loss: 12.4763 - val_accuracy: 0.3679\n",
            "Epoch 1264/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.6021 - accuracy: 0.8750 - val_loss: 12.5071 - val_accuracy: 0.3571\n",
            "Epoch 1265/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.6031 - accuracy: 0.8607 - val_loss: 12.5179 - val_accuracy: 0.3536\n",
            "Epoch 1266/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.6084 - accuracy: 0.8714 - val_loss: 12.5103 - val_accuracy: 0.3714\n",
            "Epoch 1267/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.6075 - accuracy: 0.8634 - val_loss: 12.5238 - val_accuracy: 0.3750\n",
            "Epoch 1268/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.5980 - accuracy: 0.8804 - val_loss: 12.5366 - val_accuracy: 0.3607\n",
            "Epoch 1269/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.5952 - accuracy: 0.8616 - val_loss: 12.5836 - val_accuracy: 0.3714\n",
            "Epoch 1270/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.5950 - accuracy: 0.8705 - val_loss: 12.5548 - val_accuracy: 0.3679\n",
            "Epoch 1271/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.5902 - accuracy: 0.8687 - val_loss: 12.5887 - val_accuracy: 0.3750\n",
            "Epoch 1272/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.5973 - accuracy: 0.8705 - val_loss: 12.5896 - val_accuracy: 0.3607\n",
            "Epoch 1273/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.5893 - accuracy: 0.8759 - val_loss: 12.5615 - val_accuracy: 0.3679\n",
            "Epoch 1274/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.5876 - accuracy: 0.8768 - val_loss: 12.5961 - val_accuracy: 0.3643\n",
            "Epoch 1275/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.5861 - accuracy: 0.8741 - val_loss: 12.6166 - val_accuracy: 0.3750\n",
            "Epoch 1276/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.5821 - accuracy: 0.8821 - val_loss: 12.6309 - val_accuracy: 0.3786\n",
            "Epoch 1277/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.5872 - accuracy: 0.8830 - val_loss: 12.6539 - val_accuracy: 0.3571\n",
            "Epoch 1278/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.5808 - accuracy: 0.8687 - val_loss: 12.6406 - val_accuracy: 0.3714\n",
            "Epoch 1279/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.5794 - accuracy: 0.8839 - val_loss: 12.6209 - val_accuracy: 0.3821\n",
            "Epoch 1280/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.5763 - accuracy: 0.8777 - val_loss: 12.6536 - val_accuracy: 0.3643\n",
            "Epoch 1281/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.5769 - accuracy: 0.8741 - val_loss: 12.6641 - val_accuracy: 0.3714\n",
            "Epoch 1282/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.5700 - accuracy: 0.8839 - val_loss: 12.7313 - val_accuracy: 0.3571\n",
            "Epoch 1283/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.5743 - accuracy: 0.8750 - val_loss: 12.6869 - val_accuracy: 0.3536\n",
            "Epoch 1284/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.5714 - accuracy: 0.8759 - val_loss: 12.6770 - val_accuracy: 0.3714\n",
            "Epoch 1285/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.5675 - accuracy: 0.8839 - val_loss: 12.7469 - val_accuracy: 0.3607\n",
            "Epoch 1286/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.5641 - accuracy: 0.8866 - val_loss: 12.7186 - val_accuracy: 0.3643\n",
            "Epoch 1287/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.5620 - accuracy: 0.8866 - val_loss: 12.7251 - val_accuracy: 0.3643\n",
            "Epoch 1288/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.5572 - accuracy: 0.8929 - val_loss: 12.7627 - val_accuracy: 0.3571\n",
            "Epoch 1289/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.5638 - accuracy: 0.8920 - val_loss: 12.7544 - val_accuracy: 0.3714\n",
            "Epoch 1290/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.5608 - accuracy: 0.8875 - val_loss: 12.7733 - val_accuracy: 0.3821\n",
            "Epoch 1291/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.5607 - accuracy: 0.8848 - val_loss: 12.7787 - val_accuracy: 0.3643\n",
            "Epoch 1292/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.5603 - accuracy: 0.8777 - val_loss: 12.7979 - val_accuracy: 0.3643\n",
            "Epoch 1293/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.5585 - accuracy: 0.8830 - val_loss: 12.7907 - val_accuracy: 0.3750\n",
            "Epoch 1294/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.5506 - accuracy: 0.8813 - val_loss: 12.8541 - val_accuracy: 0.3714\n",
            "Epoch 1295/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.5565 - accuracy: 0.8830 - val_loss: 12.8153 - val_accuracy: 0.3679\n",
            "Epoch 1296/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.5471 - accuracy: 0.8911 - val_loss: 12.8327 - val_accuracy: 0.3643\n",
            "Epoch 1297/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.5503 - accuracy: 0.8795 - val_loss: 12.8244 - val_accuracy: 0.3643\n",
            "Epoch 1298/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.5438 - accuracy: 0.8875 - val_loss: 12.8625 - val_accuracy: 0.3750\n",
            "Epoch 1299/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.5461 - accuracy: 0.8813 - val_loss: 12.8606 - val_accuracy: 0.3750\n",
            "Epoch 1300/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.5419 - accuracy: 0.8920 - val_loss: 12.8741 - val_accuracy: 0.3571\n",
            "Epoch 1301/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.5473 - accuracy: 0.8839 - val_loss: 12.8691 - val_accuracy: 0.3750\n",
            "Epoch 1302/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.5369 - accuracy: 0.8991 - val_loss: 12.8694 - val_accuracy: 0.3679\n",
            "Epoch 1303/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.5386 - accuracy: 0.8964 - val_loss: 12.8724 - val_accuracy: 0.3714\n",
            "Epoch 1304/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.5405 - accuracy: 0.8946 - val_loss: 12.9167 - val_accuracy: 0.3714\n",
            "Epoch 1305/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.5347 - accuracy: 0.8875 - val_loss: 12.9554 - val_accuracy: 0.3643\n",
            "Epoch 1306/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.5350 - accuracy: 0.8866 - val_loss: 12.9384 - val_accuracy: 0.3786\n",
            "Epoch 1307/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.5443 - accuracy: 0.8875 - val_loss: 12.9214 - val_accuracy: 0.3500\n",
            "Epoch 1308/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.5293 - accuracy: 0.8920 - val_loss: 12.9401 - val_accuracy: 0.3714\n",
            "Epoch 1309/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.5224 - accuracy: 0.9018 - val_loss: 12.9558 - val_accuracy: 0.3643\n",
            "Epoch 1310/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.5256 - accuracy: 0.8973 - val_loss: 12.9657 - val_accuracy: 0.3679\n",
            "Epoch 1311/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.5221 - accuracy: 0.9036 - val_loss: 12.9730 - val_accuracy: 0.3679\n",
            "Epoch 1312/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.5286 - accuracy: 0.8911 - val_loss: 12.9921 - val_accuracy: 0.3643\n",
            "Epoch 1313/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.5215 - accuracy: 0.8991 - val_loss: 12.9999 - val_accuracy: 0.3607\n",
            "Epoch 1314/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.5135 - accuracy: 0.9018 - val_loss: 13.0048 - val_accuracy: 0.3643\n",
            "Epoch 1315/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.5224 - accuracy: 0.8875 - val_loss: 13.0365 - val_accuracy: 0.3750\n",
            "Epoch 1316/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.5078 - accuracy: 0.9080 - val_loss: 13.0310 - val_accuracy: 0.3607\n",
            "Epoch 1317/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.5101 - accuracy: 0.8929 - val_loss: 13.0714 - val_accuracy: 0.3750\n",
            "Epoch 1318/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.5166 - accuracy: 0.8920 - val_loss: 13.0118 - val_accuracy: 0.3750\n",
            "Epoch 1319/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.5032 - accuracy: 0.9045 - val_loss: 13.0549 - val_accuracy: 0.3679\n",
            "Epoch 1320/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.5113 - accuracy: 0.9062 - val_loss: 13.0508 - val_accuracy: 0.3750\n",
            "Epoch 1321/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.5039 - accuracy: 0.8991 - val_loss: 13.0736 - val_accuracy: 0.3750\n",
            "Epoch 1322/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.5092 - accuracy: 0.9009 - val_loss: 13.0594 - val_accuracy: 0.3821\n",
            "Epoch 1323/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.5025 - accuracy: 0.9062 - val_loss: 13.0775 - val_accuracy: 0.3714\n",
            "Epoch 1324/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.5030 - accuracy: 0.9054 - val_loss: 13.1364 - val_accuracy: 0.3714\n",
            "Epoch 1325/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.5053 - accuracy: 0.9000 - val_loss: 13.1032 - val_accuracy: 0.3750\n",
            "Epoch 1326/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.4945 - accuracy: 0.8991 - val_loss: 13.1169 - val_accuracy: 0.3821\n",
            "Epoch 1327/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.4955 - accuracy: 0.9000 - val_loss: 13.1209 - val_accuracy: 0.3786\n",
            "Epoch 1328/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.4971 - accuracy: 0.9045 - val_loss: 13.1627 - val_accuracy: 0.3679\n",
            "Epoch 1329/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.4989 - accuracy: 0.8955 - val_loss: 13.1313 - val_accuracy: 0.3679\n",
            "Epoch 1330/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.4928 - accuracy: 0.8955 - val_loss: 13.1859 - val_accuracy: 0.3750\n",
            "Epoch 1331/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.4912 - accuracy: 0.9098 - val_loss: 13.1852 - val_accuracy: 0.3786\n",
            "Epoch 1332/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.4908 - accuracy: 0.9080 - val_loss: 13.1721 - val_accuracy: 0.3750\n",
            "Epoch 1333/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.4861 - accuracy: 0.9134 - val_loss: 13.2061 - val_accuracy: 0.3750\n",
            "Epoch 1334/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.4877 - accuracy: 0.9062 - val_loss: 13.1941 - val_accuracy: 0.3750\n",
            "Epoch 1335/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.4867 - accuracy: 0.9071 - val_loss: 13.2153 - val_accuracy: 0.3821\n",
            "Epoch 1336/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.4835 - accuracy: 0.9098 - val_loss: 13.2543 - val_accuracy: 0.3679\n",
            "Epoch 1337/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.4833 - accuracy: 0.9107 - val_loss: 13.2491 - val_accuracy: 0.3786\n",
            "Epoch 1338/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.4828 - accuracy: 0.9134 - val_loss: 13.2251 - val_accuracy: 0.3857\n",
            "Epoch 1339/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.4841 - accuracy: 0.9000 - val_loss: 13.2577 - val_accuracy: 0.3857\n",
            "Epoch 1340/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.4802 - accuracy: 0.9080 - val_loss: 13.3160 - val_accuracy: 0.3714\n",
            "Epoch 1341/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.4785 - accuracy: 0.9000 - val_loss: 13.2829 - val_accuracy: 0.3786\n",
            "Epoch 1342/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.4765 - accuracy: 0.9098 - val_loss: 13.3024 - val_accuracy: 0.3714\n",
            "Epoch 1343/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.4738 - accuracy: 0.9071 - val_loss: 13.3311 - val_accuracy: 0.3643\n",
            "Epoch 1344/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.4705 - accuracy: 0.9045 - val_loss: 13.2950 - val_accuracy: 0.3750\n",
            "Epoch 1345/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.4692 - accuracy: 0.9143 - val_loss: 13.3129 - val_accuracy: 0.3750\n",
            "Epoch 1346/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.4652 - accuracy: 0.9152 - val_loss: 13.3222 - val_accuracy: 0.3714\n",
            "Epoch 1347/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.4623 - accuracy: 0.9089 - val_loss: 13.3354 - val_accuracy: 0.3857\n",
            "Epoch 1348/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.4692 - accuracy: 0.9134 - val_loss: 13.3859 - val_accuracy: 0.3821\n",
            "Epoch 1349/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.4669 - accuracy: 0.9143 - val_loss: 13.3970 - val_accuracy: 0.3786\n",
            "Epoch 1350/2000\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 0.4716 - accuracy: 0.9196 - val_loss: 13.3620 - val_accuracy: 0.3714\n",
            "Epoch 1351/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.4571 - accuracy: 0.9187 - val_loss: 13.3611 - val_accuracy: 0.3857\n",
            "Epoch 1352/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.4621 - accuracy: 0.9196 - val_loss: 13.4036 - val_accuracy: 0.3714\n",
            "Epoch 1353/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.4580 - accuracy: 0.9196 - val_loss: 13.3969 - val_accuracy: 0.3857\n",
            "Epoch 1354/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.4606 - accuracy: 0.9116 - val_loss: 13.3996 - val_accuracy: 0.3821\n",
            "Epoch 1355/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.4546 - accuracy: 0.9152 - val_loss: 13.4030 - val_accuracy: 0.3750\n",
            "Epoch 1356/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.4559 - accuracy: 0.9134 - val_loss: 13.4301 - val_accuracy: 0.3821\n",
            "Epoch 1357/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.4497 - accuracy: 0.9170 - val_loss: 13.4567 - val_accuracy: 0.3714\n",
            "Epoch 1358/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.4564 - accuracy: 0.9098 - val_loss: 13.4573 - val_accuracy: 0.3750\n",
            "Epoch 1359/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.4503 - accuracy: 0.9196 - val_loss: 13.4494 - val_accuracy: 0.3821\n",
            "Epoch 1360/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.4469 - accuracy: 0.9179 - val_loss: 13.5009 - val_accuracy: 0.3714\n",
            "Epoch 1361/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.4490 - accuracy: 0.9152 - val_loss: 13.4705 - val_accuracy: 0.3750\n",
            "Epoch 1362/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.4507 - accuracy: 0.9214 - val_loss: 13.4847 - val_accuracy: 0.3714\n",
            "Epoch 1363/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.4465 - accuracy: 0.9187 - val_loss: 13.5086 - val_accuracy: 0.3786\n",
            "Epoch 1364/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.4378 - accuracy: 0.9241 - val_loss: 13.5063 - val_accuracy: 0.3750\n",
            "Epoch 1365/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.4443 - accuracy: 0.9295 - val_loss: 13.5105 - val_accuracy: 0.3679\n",
            "Epoch 1366/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.4407 - accuracy: 0.9161 - val_loss: 13.4741 - val_accuracy: 0.3821\n",
            "Epoch 1367/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.4373 - accuracy: 0.9223 - val_loss: 13.5391 - val_accuracy: 0.3750\n",
            "Epoch 1368/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.4290 - accuracy: 0.9330 - val_loss: 13.5383 - val_accuracy: 0.3893\n",
            "Epoch 1369/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.4364 - accuracy: 0.9187 - val_loss: 13.5375 - val_accuracy: 0.3786\n",
            "Epoch 1370/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.4315 - accuracy: 0.9241 - val_loss: 13.5485 - val_accuracy: 0.3857\n",
            "Epoch 1371/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.4299 - accuracy: 0.9187 - val_loss: 13.5717 - val_accuracy: 0.3821\n",
            "Epoch 1372/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.4300 - accuracy: 0.9241 - val_loss: 13.6065 - val_accuracy: 0.3750\n",
            "Epoch 1373/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.4271 - accuracy: 0.9241 - val_loss: 13.6010 - val_accuracy: 0.3750\n",
            "Epoch 1374/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.4315 - accuracy: 0.9179 - val_loss: 13.5756 - val_accuracy: 0.3786\n",
            "Epoch 1375/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.4248 - accuracy: 0.9277 - val_loss: 13.5925 - val_accuracy: 0.3857\n",
            "Epoch 1376/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.4205 - accuracy: 0.9259 - val_loss: 13.6170 - val_accuracy: 0.3679\n",
            "Epoch 1377/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.4238 - accuracy: 0.9187 - val_loss: 13.6376 - val_accuracy: 0.3821\n",
            "Epoch 1378/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.4150 - accuracy: 0.9295 - val_loss: 13.6393 - val_accuracy: 0.3786\n",
            "Epoch 1379/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.4202 - accuracy: 0.9250 - val_loss: 13.6855 - val_accuracy: 0.3643\n",
            "Epoch 1380/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.4257 - accuracy: 0.9205 - val_loss: 13.6531 - val_accuracy: 0.3750\n",
            "Epoch 1381/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.4156 - accuracy: 0.9277 - val_loss: 13.6521 - val_accuracy: 0.3857\n",
            "Epoch 1382/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.4163 - accuracy: 0.9321 - val_loss: 13.6706 - val_accuracy: 0.3857\n",
            "Epoch 1383/2000\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 0.4168 - accuracy: 0.9259 - val_loss: 13.6750 - val_accuracy: 0.3857\n",
            "Epoch 1384/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.4174 - accuracy: 0.9268 - val_loss: 13.6838 - val_accuracy: 0.3786\n",
            "Epoch 1385/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.4124 - accuracy: 0.9250 - val_loss: 13.7092 - val_accuracy: 0.3786\n",
            "Epoch 1386/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.4093 - accuracy: 0.9366 - val_loss: 13.7235 - val_accuracy: 0.3821\n",
            "Epoch 1387/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.4095 - accuracy: 0.9277 - val_loss: 13.7411 - val_accuracy: 0.3750\n",
            "Epoch 1388/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.4052 - accuracy: 0.9304 - val_loss: 13.7491 - val_accuracy: 0.3679\n",
            "Epoch 1389/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.4122 - accuracy: 0.9196 - val_loss: 13.7398 - val_accuracy: 0.3786\n",
            "Epoch 1390/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.4032 - accuracy: 0.9348 - val_loss: 13.7538 - val_accuracy: 0.3786\n",
            "Epoch 1391/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.4074 - accuracy: 0.9348 - val_loss: 13.7508 - val_accuracy: 0.3750\n",
            "Epoch 1392/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.4011 - accuracy: 0.9321 - val_loss: 13.7907 - val_accuracy: 0.3750\n",
            "Epoch 1393/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.4075 - accuracy: 0.9259 - val_loss: 13.7714 - val_accuracy: 0.3857\n",
            "Epoch 1394/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.3938 - accuracy: 0.9429 - val_loss: 13.8093 - val_accuracy: 0.3893\n",
            "Epoch 1395/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.4011 - accuracy: 0.9312 - val_loss: 13.8241 - val_accuracy: 0.3821\n",
            "Epoch 1396/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.3977 - accuracy: 0.9277 - val_loss: 13.8463 - val_accuracy: 0.3679\n",
            "Epoch 1397/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.4000 - accuracy: 0.9304 - val_loss: 13.8441 - val_accuracy: 0.3857\n",
            "Epoch 1398/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.4000 - accuracy: 0.9268 - val_loss: 13.8250 - val_accuracy: 0.3893\n",
            "Epoch 1399/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.3997 - accuracy: 0.9375 - val_loss: 13.8652 - val_accuracy: 0.3786\n",
            "Epoch 1400/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.3917 - accuracy: 0.9375 - val_loss: 13.8764 - val_accuracy: 0.3893\n",
            "Epoch 1401/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.3944 - accuracy: 0.9330 - val_loss: 13.8641 - val_accuracy: 0.3857\n",
            "Epoch 1402/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.3889 - accuracy: 0.9339 - val_loss: 13.8890 - val_accuracy: 0.3821\n",
            "Epoch 1403/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.3887 - accuracy: 0.9411 - val_loss: 13.8791 - val_accuracy: 0.3929\n",
            "Epoch 1404/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.3852 - accuracy: 0.9429 - val_loss: 13.8923 - val_accuracy: 0.3786\n",
            "Epoch 1405/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.3851 - accuracy: 0.9402 - val_loss: 13.9399 - val_accuracy: 0.3821\n",
            "Epoch 1406/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.3895 - accuracy: 0.9295 - val_loss: 13.8754 - val_accuracy: 0.3893\n",
            "Epoch 1407/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.3792 - accuracy: 0.9411 - val_loss: 13.9163 - val_accuracy: 0.3821\n",
            "Epoch 1408/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.3875 - accuracy: 0.9286 - val_loss: 13.9574 - val_accuracy: 0.3929\n",
            "Epoch 1409/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.3822 - accuracy: 0.9384 - val_loss: 13.9415 - val_accuracy: 0.3714\n",
            "Epoch 1410/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.3808 - accuracy: 0.9402 - val_loss: 13.9298 - val_accuracy: 0.3786\n",
            "Epoch 1411/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.3820 - accuracy: 0.9321 - val_loss: 13.9401 - val_accuracy: 0.3821\n",
            "Epoch 1412/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.3798 - accuracy: 0.9420 - val_loss: 13.9610 - val_accuracy: 0.3857\n",
            "Epoch 1413/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.3745 - accuracy: 0.9384 - val_loss: 13.9596 - val_accuracy: 0.3821\n",
            "Epoch 1414/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.3758 - accuracy: 0.9339 - val_loss: 14.0084 - val_accuracy: 0.3821\n",
            "Epoch 1415/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.3763 - accuracy: 0.9464 - val_loss: 13.9642 - val_accuracy: 0.3857\n",
            "Epoch 1416/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.3737 - accuracy: 0.9375 - val_loss: 13.9879 - val_accuracy: 0.3893\n",
            "Epoch 1417/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.3657 - accuracy: 0.9500 - val_loss: 14.0505 - val_accuracy: 0.3893\n",
            "Epoch 1418/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.3744 - accuracy: 0.9366 - val_loss: 14.0161 - val_accuracy: 0.3893\n",
            "Epoch 1419/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.3672 - accuracy: 0.9429 - val_loss: 14.0572 - val_accuracy: 0.3857\n",
            "Epoch 1420/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.3717 - accuracy: 0.9438 - val_loss: 14.0264 - val_accuracy: 0.3821\n",
            "Epoch 1421/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.3680 - accuracy: 0.9438 - val_loss: 14.1275 - val_accuracy: 0.3607\n",
            "Epoch 1422/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.3774 - accuracy: 0.9393 - val_loss: 14.0367 - val_accuracy: 0.3893\n",
            "Epoch 1423/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.3672 - accuracy: 0.9393 - val_loss: 14.1068 - val_accuracy: 0.3750\n",
            "Epoch 1424/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.3687 - accuracy: 0.9375 - val_loss: 14.1208 - val_accuracy: 0.3893\n",
            "Epoch 1425/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.3621 - accuracy: 0.9420 - val_loss: 14.1115 - val_accuracy: 0.3893\n",
            "Epoch 1426/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.3665 - accuracy: 0.9438 - val_loss: 14.0831 - val_accuracy: 0.3929\n",
            "Epoch 1427/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.3632 - accuracy: 0.9348 - val_loss: 14.1225 - val_accuracy: 0.3857\n",
            "Epoch 1428/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.3595 - accuracy: 0.9482 - val_loss: 14.1205 - val_accuracy: 0.3857\n",
            "Epoch 1429/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.3617 - accuracy: 0.9420 - val_loss: 14.1405 - val_accuracy: 0.3714\n",
            "Epoch 1430/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.3635 - accuracy: 0.9402 - val_loss: 14.1373 - val_accuracy: 0.3786\n",
            "Epoch 1431/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.3559 - accuracy: 0.9357 - val_loss: 14.1704 - val_accuracy: 0.3893\n",
            "Epoch 1432/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.3497 - accuracy: 0.9411 - val_loss: 14.1500 - val_accuracy: 0.3893\n",
            "Epoch 1433/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.3555 - accuracy: 0.9464 - val_loss: 14.1799 - val_accuracy: 0.3821\n",
            "Epoch 1434/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.3507 - accuracy: 0.9482 - val_loss: 14.1865 - val_accuracy: 0.3857\n",
            "Epoch 1435/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.3471 - accuracy: 0.9580 - val_loss: 14.1906 - val_accuracy: 0.3821\n",
            "Epoch 1436/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.3502 - accuracy: 0.9473 - val_loss: 14.1839 - val_accuracy: 0.3893\n",
            "Epoch 1437/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.3521 - accuracy: 0.9455 - val_loss: 14.2283 - val_accuracy: 0.3786\n",
            "Epoch 1438/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.3497 - accuracy: 0.9438 - val_loss: 14.2331 - val_accuracy: 0.3964\n",
            "Epoch 1439/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.3498 - accuracy: 0.9420 - val_loss: 14.2329 - val_accuracy: 0.3857\n",
            "Epoch 1440/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.3466 - accuracy: 0.9527 - val_loss: 14.2511 - val_accuracy: 0.3857\n",
            "Epoch 1441/2000\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 0.3437 - accuracy: 0.9455 - val_loss: 14.2331 - val_accuracy: 0.3929\n",
            "Epoch 1442/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.3430 - accuracy: 0.9464 - val_loss: 14.2608 - val_accuracy: 0.3893\n",
            "Epoch 1443/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.3390 - accuracy: 0.9527 - val_loss: 14.2569 - val_accuracy: 0.3964\n",
            "Epoch 1444/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.3389 - accuracy: 0.9536 - val_loss: 14.3316 - val_accuracy: 0.3893\n",
            "Epoch 1445/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.3465 - accuracy: 0.9464 - val_loss: 14.2777 - val_accuracy: 0.3786\n",
            "Epoch 1446/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.3379 - accuracy: 0.9446 - val_loss: 14.3177 - val_accuracy: 0.3964\n",
            "Epoch 1447/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.3371 - accuracy: 0.9473 - val_loss: 14.2910 - val_accuracy: 0.3893\n",
            "Epoch 1448/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.3371 - accuracy: 0.9491 - val_loss: 14.3225 - val_accuracy: 0.4000\n",
            "Epoch 1449/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.3382 - accuracy: 0.9482 - val_loss: 14.3163 - val_accuracy: 0.3929\n",
            "Epoch 1450/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.3303 - accuracy: 0.9527 - val_loss: 14.3764 - val_accuracy: 0.3893\n",
            "Epoch 1451/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.3346 - accuracy: 0.9464 - val_loss: 14.3847 - val_accuracy: 0.3821\n",
            "Epoch 1452/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.3348 - accuracy: 0.9509 - val_loss: 14.4024 - val_accuracy: 0.3857\n",
            "Epoch 1453/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.3308 - accuracy: 0.9536 - val_loss: 14.3767 - val_accuracy: 0.3929\n",
            "Epoch 1454/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.3274 - accuracy: 0.9545 - val_loss: 14.3539 - val_accuracy: 0.3857\n",
            "Epoch 1455/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.3269 - accuracy: 0.9607 - val_loss: 14.3902 - val_accuracy: 0.3893\n",
            "Epoch 1456/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.3283 - accuracy: 0.9491 - val_loss: 14.4432 - val_accuracy: 0.3857\n",
            "Epoch 1457/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.3308 - accuracy: 0.9545 - val_loss: 14.3935 - val_accuracy: 0.3821\n",
            "Epoch 1458/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.3279 - accuracy: 0.9527 - val_loss: 14.3933 - val_accuracy: 0.3857\n",
            "Epoch 1459/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.3228 - accuracy: 0.9545 - val_loss: 14.3952 - val_accuracy: 0.3857\n",
            "Epoch 1460/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.3247 - accuracy: 0.9491 - val_loss: 14.4397 - val_accuracy: 0.3964\n",
            "Epoch 1461/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.3241 - accuracy: 0.9500 - val_loss: 14.4254 - val_accuracy: 0.3893\n",
            "Epoch 1462/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.3206 - accuracy: 0.9589 - val_loss: 14.4490 - val_accuracy: 0.3964\n",
            "Epoch 1463/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.3186 - accuracy: 0.9536 - val_loss: 14.4390 - val_accuracy: 0.3893\n",
            "Epoch 1464/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.3195 - accuracy: 0.9589 - val_loss: 14.4543 - val_accuracy: 0.3893\n",
            "Epoch 1465/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.3203 - accuracy: 0.9518 - val_loss: 14.5049 - val_accuracy: 0.3929\n",
            "Epoch 1466/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.3188 - accuracy: 0.9554 - val_loss: 14.5422 - val_accuracy: 0.3821\n",
            "Epoch 1467/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.3181 - accuracy: 0.9563 - val_loss: 14.4792 - val_accuracy: 0.3893\n",
            "Epoch 1468/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.3151 - accuracy: 0.9527 - val_loss: 14.5152 - val_accuracy: 0.4000\n",
            "Epoch 1469/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.3128 - accuracy: 0.9589 - val_loss: 14.5146 - val_accuracy: 0.3857\n",
            "Epoch 1470/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.3167 - accuracy: 0.9536 - val_loss: 14.5379 - val_accuracy: 0.3857\n",
            "Epoch 1471/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.3118 - accuracy: 0.9580 - val_loss: 14.5343 - val_accuracy: 0.3821\n",
            "Epoch 1472/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.3129 - accuracy: 0.9536 - val_loss: 14.5979 - val_accuracy: 0.3857\n",
            "Epoch 1473/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.3128 - accuracy: 0.9554 - val_loss: 14.5728 - val_accuracy: 0.3893\n",
            "Epoch 1474/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.3098 - accuracy: 0.9616 - val_loss: 14.5637 - val_accuracy: 0.3964\n",
            "Epoch 1475/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.3071 - accuracy: 0.9536 - val_loss: 14.5735 - val_accuracy: 0.3929\n",
            "Epoch 1476/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.3068 - accuracy: 0.9643 - val_loss: 14.6106 - val_accuracy: 0.3893\n",
            "Epoch 1477/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.3057 - accuracy: 0.9536 - val_loss: 14.5649 - val_accuracy: 0.3857\n",
            "Epoch 1478/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.3058 - accuracy: 0.9598 - val_loss: 14.5859 - val_accuracy: 0.3893\n",
            "Epoch 1479/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.3043 - accuracy: 0.9563 - val_loss: 14.5950 - val_accuracy: 0.3964\n",
            "Epoch 1480/2000\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 0.3059 - accuracy: 0.9589 - val_loss: 14.6188 - val_accuracy: 0.3857\n",
            "Epoch 1481/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.3046 - accuracy: 0.9518 - val_loss: 14.6286 - val_accuracy: 0.3964\n",
            "Epoch 1482/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.3034 - accuracy: 0.9563 - val_loss: 14.6393 - val_accuracy: 0.3857\n",
            "Epoch 1483/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.3027 - accuracy: 0.9563 - val_loss: 14.6427 - val_accuracy: 0.3750\n",
            "Epoch 1484/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.3032 - accuracy: 0.9527 - val_loss: 14.6522 - val_accuracy: 0.3857\n",
            "Epoch 1485/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2975 - accuracy: 0.9652 - val_loss: 14.6776 - val_accuracy: 0.3893\n",
            "Epoch 1486/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2928 - accuracy: 0.9554 - val_loss: 14.6737 - val_accuracy: 0.3893\n",
            "Epoch 1487/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2975 - accuracy: 0.9563 - val_loss: 14.6755 - val_accuracy: 0.3857\n",
            "Epoch 1488/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.2959 - accuracy: 0.9580 - val_loss: 14.6766 - val_accuracy: 0.3929\n",
            "Epoch 1489/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.2944 - accuracy: 0.9661 - val_loss: 14.7226 - val_accuracy: 0.3929\n",
            "Epoch 1490/2000\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 0.2954 - accuracy: 0.9580 - val_loss: 14.6879 - val_accuracy: 0.3893\n",
            "Epoch 1491/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2939 - accuracy: 0.9625 - val_loss: 14.7764 - val_accuracy: 0.3821\n",
            "Epoch 1492/2000\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 0.3007 - accuracy: 0.9580 - val_loss: 14.7069 - val_accuracy: 0.3857\n",
            "Epoch 1493/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2926 - accuracy: 0.9589 - val_loss: 14.7388 - val_accuracy: 0.3929\n",
            "Epoch 1494/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.2952 - accuracy: 0.9536 - val_loss: 14.7517 - val_accuracy: 0.3964\n",
            "Epoch 1495/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.2906 - accuracy: 0.9563 - val_loss: 14.7690 - val_accuracy: 0.4000\n",
            "Epoch 1496/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2926 - accuracy: 0.9616 - val_loss: 14.7932 - val_accuracy: 0.3929\n",
            "Epoch 1497/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.2905 - accuracy: 0.9589 - val_loss: 14.7626 - val_accuracy: 0.4000\n",
            "Epoch 1498/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.2842 - accuracy: 0.9643 - val_loss: 14.7645 - val_accuracy: 0.3964\n",
            "Epoch 1499/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2847 - accuracy: 0.9598 - val_loss: 14.8185 - val_accuracy: 0.3929\n",
            "Epoch 1500/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2892 - accuracy: 0.9625 - val_loss: 14.8388 - val_accuracy: 0.3964\n",
            "Epoch 1501/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2882 - accuracy: 0.9661 - val_loss: 14.7920 - val_accuracy: 0.3929\n",
            "Epoch 1502/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2848 - accuracy: 0.9616 - val_loss: 14.8188 - val_accuracy: 0.4000\n",
            "Epoch 1503/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.2860 - accuracy: 0.9670 - val_loss: 14.8329 - val_accuracy: 0.3893\n",
            "Epoch 1504/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2798 - accuracy: 0.9652 - val_loss: 14.8735 - val_accuracy: 0.4000\n",
            "Epoch 1505/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.2816 - accuracy: 0.9598 - val_loss: 14.8437 - val_accuracy: 0.3857\n",
            "Epoch 1506/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.2836 - accuracy: 0.9580 - val_loss: 14.8593 - val_accuracy: 0.3893\n",
            "Epoch 1507/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2783 - accuracy: 0.9652 - val_loss: 14.8719 - val_accuracy: 0.3964\n",
            "Epoch 1508/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.2789 - accuracy: 0.9643 - val_loss: 14.9000 - val_accuracy: 0.3821\n",
            "Epoch 1509/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2734 - accuracy: 0.9634 - val_loss: 14.8706 - val_accuracy: 0.3929\n",
            "Epoch 1510/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.2760 - accuracy: 0.9571 - val_loss: 14.9253 - val_accuracy: 0.4000\n",
            "Epoch 1511/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2757 - accuracy: 0.9634 - val_loss: 14.8833 - val_accuracy: 0.4000\n",
            "Epoch 1512/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.2758 - accuracy: 0.9643 - val_loss: 14.8896 - val_accuracy: 0.4000\n",
            "Epoch 1513/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2739 - accuracy: 0.9705 - val_loss: 14.9145 - val_accuracy: 0.3929\n",
            "Epoch 1514/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2738 - accuracy: 0.9607 - val_loss: 14.9239 - val_accuracy: 0.4036\n",
            "Epoch 1515/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2731 - accuracy: 0.9661 - val_loss: 14.9517 - val_accuracy: 0.3821\n",
            "Epoch 1516/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2772 - accuracy: 0.9625 - val_loss: 14.9565 - val_accuracy: 0.3964\n",
            "Epoch 1517/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2710 - accuracy: 0.9607 - val_loss: 14.9684 - val_accuracy: 0.3964\n",
            "Epoch 1518/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.2721 - accuracy: 0.9688 - val_loss: 14.9414 - val_accuracy: 0.3964\n",
            "Epoch 1519/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.2658 - accuracy: 0.9688 - val_loss: 14.9840 - val_accuracy: 0.3893\n",
            "Epoch 1520/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2711 - accuracy: 0.9661 - val_loss: 14.9803 - val_accuracy: 0.4000\n",
            "Epoch 1521/2000\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 0.2692 - accuracy: 0.9714 - val_loss: 14.9790 - val_accuracy: 0.3929\n",
            "Epoch 1522/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2611 - accuracy: 0.9714 - val_loss: 15.0664 - val_accuracy: 0.3857\n",
            "Epoch 1523/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2733 - accuracy: 0.9616 - val_loss: 15.0050 - val_accuracy: 0.3964\n",
            "Epoch 1524/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2616 - accuracy: 0.9670 - val_loss: 15.0157 - val_accuracy: 0.4000\n",
            "Epoch 1525/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2663 - accuracy: 0.9661 - val_loss: 15.0255 - val_accuracy: 0.3964\n",
            "Epoch 1526/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2648 - accuracy: 0.9670 - val_loss: 15.0428 - val_accuracy: 0.4000\n",
            "Epoch 1527/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2646 - accuracy: 0.9661 - val_loss: 15.0737 - val_accuracy: 0.3893\n",
            "Epoch 1528/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2633 - accuracy: 0.9696 - val_loss: 15.0495 - val_accuracy: 0.3964\n",
            "Epoch 1529/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.2623 - accuracy: 0.9652 - val_loss: 15.0789 - val_accuracy: 0.3964\n",
            "Epoch 1530/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2624 - accuracy: 0.9732 - val_loss: 15.1287 - val_accuracy: 0.3964\n",
            "Epoch 1531/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2638 - accuracy: 0.9652 - val_loss: 15.1355 - val_accuracy: 0.3857\n",
            "Epoch 1532/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.2560 - accuracy: 0.9714 - val_loss: 15.0993 - val_accuracy: 0.4036\n",
            "Epoch 1533/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.2588 - accuracy: 0.9741 - val_loss: 15.1029 - val_accuracy: 0.3893\n",
            "Epoch 1534/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2573 - accuracy: 0.9696 - val_loss: 15.1170 - val_accuracy: 0.4000\n",
            "Epoch 1535/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.2595 - accuracy: 0.9643 - val_loss: 15.1218 - val_accuracy: 0.3964\n",
            "Epoch 1536/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2555 - accuracy: 0.9679 - val_loss: 15.1154 - val_accuracy: 0.3964\n",
            "Epoch 1537/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2548 - accuracy: 0.9688 - val_loss: 15.1373 - val_accuracy: 0.3929\n",
            "Epoch 1538/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.2559 - accuracy: 0.9696 - val_loss: 15.1585 - val_accuracy: 0.4071\n",
            "Epoch 1539/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.2514 - accuracy: 0.9714 - val_loss: 15.1446 - val_accuracy: 0.3964\n",
            "Epoch 1540/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2519 - accuracy: 0.9732 - val_loss: 15.1753 - val_accuracy: 0.3893\n",
            "Epoch 1541/2000\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 0.2545 - accuracy: 0.9723 - val_loss: 15.1496 - val_accuracy: 0.3964\n",
            "Epoch 1542/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.2512 - accuracy: 0.9732 - val_loss: 15.1711 - val_accuracy: 0.3964\n",
            "Epoch 1543/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.2474 - accuracy: 0.9723 - val_loss: 15.1745 - val_accuracy: 0.4036\n",
            "Epoch 1544/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.2498 - accuracy: 0.9705 - val_loss: 15.1993 - val_accuracy: 0.3964\n",
            "Epoch 1545/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.2491 - accuracy: 0.9714 - val_loss: 15.1909 - val_accuracy: 0.4036\n",
            "Epoch 1546/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2477 - accuracy: 0.9723 - val_loss: 15.2196 - val_accuracy: 0.3929\n",
            "Epoch 1547/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2487 - accuracy: 0.9732 - val_loss: 15.2296 - val_accuracy: 0.3929\n",
            "Epoch 1548/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2475 - accuracy: 0.9679 - val_loss: 15.2440 - val_accuracy: 0.3964\n",
            "Epoch 1549/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.2471 - accuracy: 0.9661 - val_loss: 15.2655 - val_accuracy: 0.3964\n",
            "Epoch 1550/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2500 - accuracy: 0.9732 - val_loss: 15.2510 - val_accuracy: 0.3929\n",
            "Epoch 1551/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2437 - accuracy: 0.9732 - val_loss: 15.2637 - val_accuracy: 0.4036\n",
            "Epoch 1552/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2474 - accuracy: 0.9723 - val_loss: 15.2614 - val_accuracy: 0.4000\n",
            "Epoch 1553/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2417 - accuracy: 0.9741 - val_loss: 15.2881 - val_accuracy: 0.3893\n",
            "Epoch 1554/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2441 - accuracy: 0.9705 - val_loss: 15.3502 - val_accuracy: 0.3964\n",
            "Epoch 1555/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2451 - accuracy: 0.9723 - val_loss: 15.3433 - val_accuracy: 0.3964\n",
            "Epoch 1556/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2396 - accuracy: 0.9732 - val_loss: 15.3154 - val_accuracy: 0.4036\n",
            "Epoch 1557/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.2418 - accuracy: 0.9759 - val_loss: 15.3145 - val_accuracy: 0.3964\n",
            "Epoch 1558/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2377 - accuracy: 0.9741 - val_loss: 15.3289 - val_accuracy: 0.4000\n",
            "Epoch 1559/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2459 - accuracy: 0.9652 - val_loss: 15.3754 - val_accuracy: 0.4000\n",
            "Epoch 1560/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2418 - accuracy: 0.9670 - val_loss: 15.3434 - val_accuracy: 0.3929\n",
            "Epoch 1561/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2381 - accuracy: 0.9768 - val_loss: 15.3642 - val_accuracy: 0.3929\n",
            "Epoch 1562/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2337 - accuracy: 0.9786 - val_loss: 15.3669 - val_accuracy: 0.3964\n",
            "Epoch 1563/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2334 - accuracy: 0.9768 - val_loss: 15.3839 - val_accuracy: 0.3964\n",
            "Epoch 1564/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2332 - accuracy: 0.9839 - val_loss: 15.3720 - val_accuracy: 0.4036\n",
            "Epoch 1565/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.2338 - accuracy: 0.9768 - val_loss: 15.3942 - val_accuracy: 0.3857\n",
            "Epoch 1566/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2343 - accuracy: 0.9634 - val_loss: 15.4028 - val_accuracy: 0.4000\n",
            "Epoch 1567/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2334 - accuracy: 0.9777 - val_loss: 15.3924 - val_accuracy: 0.4036\n",
            "Epoch 1568/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2290 - accuracy: 0.9786 - val_loss: 15.4221 - val_accuracy: 0.4000\n",
            "Epoch 1569/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2322 - accuracy: 0.9777 - val_loss: 15.4283 - val_accuracy: 0.4000\n",
            "Epoch 1570/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2290 - accuracy: 0.9804 - val_loss: 15.4602 - val_accuracy: 0.4000\n",
            "Epoch 1571/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.2294 - accuracy: 0.9750 - val_loss: 15.4111 - val_accuracy: 0.4000\n",
            "Epoch 1572/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.2259 - accuracy: 0.9759 - val_loss: 15.4696 - val_accuracy: 0.3893\n",
            "Epoch 1573/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.2319 - accuracy: 0.9705 - val_loss: 15.4402 - val_accuracy: 0.4000\n",
            "Epoch 1574/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.2295 - accuracy: 0.9750 - val_loss: 15.4826 - val_accuracy: 0.4000\n",
            "Epoch 1575/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2300 - accuracy: 0.9777 - val_loss: 15.4914 - val_accuracy: 0.3964\n",
            "Epoch 1576/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.2262 - accuracy: 0.9786 - val_loss: 15.4688 - val_accuracy: 0.3929\n",
            "Epoch 1577/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2222 - accuracy: 0.9777 - val_loss: 15.5026 - val_accuracy: 0.4000\n",
            "Epoch 1578/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2277 - accuracy: 0.9759 - val_loss: 15.5030 - val_accuracy: 0.3964\n",
            "Epoch 1579/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2266 - accuracy: 0.9795 - val_loss: 15.4999 - val_accuracy: 0.3964\n",
            "Epoch 1580/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.2243 - accuracy: 0.9741 - val_loss: 15.5274 - val_accuracy: 0.4000\n",
            "Epoch 1581/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2227 - accuracy: 0.9759 - val_loss: 15.5440 - val_accuracy: 0.3964\n",
            "Epoch 1582/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2235 - accuracy: 0.9777 - val_loss: 15.5119 - val_accuracy: 0.3929\n",
            "Epoch 1583/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.2216 - accuracy: 0.9750 - val_loss: 15.5321 - val_accuracy: 0.4000\n",
            "Epoch 1584/2000\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 0.2207 - accuracy: 0.9821 - val_loss: 15.5923 - val_accuracy: 0.4000\n",
            "Epoch 1585/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2232 - accuracy: 0.9786 - val_loss: 15.5766 - val_accuracy: 0.4000\n",
            "Epoch 1586/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2204 - accuracy: 0.9821 - val_loss: 15.5468 - val_accuracy: 0.4000\n",
            "Epoch 1587/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2186 - accuracy: 0.9812 - val_loss: 15.5801 - val_accuracy: 0.3857\n",
            "Epoch 1588/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2178 - accuracy: 0.9750 - val_loss: 15.5883 - val_accuracy: 0.3964\n",
            "Epoch 1589/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2171 - accuracy: 0.9830 - val_loss: 15.6058 - val_accuracy: 0.4036\n",
            "Epoch 1590/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.2153 - accuracy: 0.9821 - val_loss: 15.5804 - val_accuracy: 0.4036\n",
            "Epoch 1591/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.2167 - accuracy: 0.9768 - val_loss: 15.6192 - val_accuracy: 0.4036\n",
            "Epoch 1592/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.2138 - accuracy: 0.9830 - val_loss: 15.6296 - val_accuracy: 0.4000\n",
            "Epoch 1593/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2110 - accuracy: 0.9804 - val_loss: 15.6127 - val_accuracy: 0.3929\n",
            "Epoch 1594/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2134 - accuracy: 0.9839 - val_loss: 15.6333 - val_accuracy: 0.4000\n",
            "Epoch 1595/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.2171 - accuracy: 0.9830 - val_loss: 15.6317 - val_accuracy: 0.3929\n",
            "Epoch 1596/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.2101 - accuracy: 0.9795 - val_loss: 15.6540 - val_accuracy: 0.3929\n",
            "Epoch 1597/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2193 - accuracy: 0.9741 - val_loss: 15.6660 - val_accuracy: 0.4071\n",
            "Epoch 1598/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2136 - accuracy: 0.9812 - val_loss: 15.6947 - val_accuracy: 0.3964\n",
            "Epoch 1599/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.2148 - accuracy: 0.9750 - val_loss: 15.6657 - val_accuracy: 0.4036\n",
            "Epoch 1600/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2119 - accuracy: 0.9804 - val_loss: 15.6789 - val_accuracy: 0.4000\n",
            "Epoch 1601/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.2109 - accuracy: 0.9759 - val_loss: 15.6914 - val_accuracy: 0.4000\n",
            "Epoch 1602/2000\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 0.2099 - accuracy: 0.9795 - val_loss: 15.7384 - val_accuracy: 0.3964\n",
            "Epoch 1603/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.2094 - accuracy: 0.9812 - val_loss: 15.6929 - val_accuracy: 0.4036\n",
            "Epoch 1604/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.2089 - accuracy: 0.9812 - val_loss: 15.7234 - val_accuracy: 0.3964\n",
            "Epoch 1605/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2099 - accuracy: 0.9795 - val_loss: 15.7173 - val_accuracy: 0.3964\n",
            "Epoch 1606/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2069 - accuracy: 0.9821 - val_loss: 15.7493 - val_accuracy: 0.4000\n",
            "Epoch 1607/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2045 - accuracy: 0.9821 - val_loss: 15.7711 - val_accuracy: 0.3929\n",
            "Epoch 1608/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2086 - accuracy: 0.9821 - val_loss: 15.7510 - val_accuracy: 0.4036\n",
            "Epoch 1609/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2043 - accuracy: 0.9786 - val_loss: 15.7615 - val_accuracy: 0.3964\n",
            "Epoch 1610/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.2059 - accuracy: 0.9839 - val_loss: 15.7861 - val_accuracy: 0.3964\n",
            "Epoch 1611/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2045 - accuracy: 0.9812 - val_loss: 15.7768 - val_accuracy: 0.4000\n",
            "Epoch 1612/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2047 - accuracy: 0.9741 - val_loss: 15.7938 - val_accuracy: 0.3893\n",
            "Epoch 1613/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2019 - accuracy: 0.9812 - val_loss: 15.8276 - val_accuracy: 0.4000\n",
            "Epoch 1614/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.2003 - accuracy: 0.9821 - val_loss: 15.8129 - val_accuracy: 0.4000\n",
            "Epoch 1615/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2018 - accuracy: 0.9839 - val_loss: 15.8028 - val_accuracy: 0.4071\n",
            "Epoch 1616/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2007 - accuracy: 0.9875 - val_loss: 15.8127 - val_accuracy: 0.4000\n",
            "Epoch 1617/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.2005 - accuracy: 0.9812 - val_loss: 15.8313 - val_accuracy: 0.4000\n",
            "Epoch 1618/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.1976 - accuracy: 0.9812 - val_loss: 15.8584 - val_accuracy: 0.4036\n",
            "Epoch 1619/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.1964 - accuracy: 0.9893 - val_loss: 15.8320 - val_accuracy: 0.4071\n",
            "Epoch 1620/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.1985 - accuracy: 0.9804 - val_loss: 15.8548 - val_accuracy: 0.4036\n",
            "Epoch 1621/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2015 - accuracy: 0.9830 - val_loss: 15.8539 - val_accuracy: 0.4000\n",
            "Epoch 1622/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.1944 - accuracy: 0.9866 - val_loss: 15.9226 - val_accuracy: 0.3929\n",
            "Epoch 1623/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2030 - accuracy: 0.9795 - val_loss: 15.8660 - val_accuracy: 0.4036\n",
            "Epoch 1624/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.1911 - accuracy: 0.9884 - val_loss: 15.8666 - val_accuracy: 0.4000\n",
            "Epoch 1625/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.1955 - accuracy: 0.9830 - val_loss: 15.8815 - val_accuracy: 0.4000\n",
            "Epoch 1626/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.1944 - accuracy: 0.9821 - val_loss: 15.9093 - val_accuracy: 0.3964\n",
            "Epoch 1627/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.1932 - accuracy: 0.9839 - val_loss: 15.9074 - val_accuracy: 0.4071\n",
            "Epoch 1628/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.1916 - accuracy: 0.9857 - val_loss: 15.9208 - val_accuracy: 0.3964\n",
            "Epoch 1629/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.1952 - accuracy: 0.9857 - val_loss: 15.9149 - val_accuracy: 0.4000\n",
            "Epoch 1630/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.1938 - accuracy: 0.9830 - val_loss: 15.9399 - val_accuracy: 0.3964\n",
            "Epoch 1631/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.1941 - accuracy: 0.9786 - val_loss: 15.9658 - val_accuracy: 0.4000\n",
            "Epoch 1632/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.1955 - accuracy: 0.9804 - val_loss: 15.9405 - val_accuracy: 0.4036\n",
            "Epoch 1633/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.1876 - accuracy: 0.9866 - val_loss: 15.9468 - val_accuracy: 0.4000\n",
            "Epoch 1634/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.1900 - accuracy: 0.9857 - val_loss: 15.9830 - val_accuracy: 0.4000\n",
            "Epoch 1635/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.1898 - accuracy: 0.9839 - val_loss: 15.9757 - val_accuracy: 0.4071\n",
            "Epoch 1636/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.1936 - accuracy: 0.9848 - val_loss: 15.9650 - val_accuracy: 0.4036\n",
            "Epoch 1637/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.1898 - accuracy: 0.9812 - val_loss: 15.9796 - val_accuracy: 0.4036\n",
            "Epoch 1638/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.1865 - accuracy: 0.9848 - val_loss: 15.9907 - val_accuracy: 0.4000\n",
            "Epoch 1639/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.1855 - accuracy: 0.9884 - val_loss: 16.0083 - val_accuracy: 0.4036\n",
            "Epoch 1640/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.1840 - accuracy: 0.9875 - val_loss: 15.9873 - val_accuracy: 0.4036\n",
            "Epoch 1641/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.1862 - accuracy: 0.9821 - val_loss: 16.0266 - val_accuracy: 0.4071\n",
            "Epoch 1642/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.1841 - accuracy: 0.9866 - val_loss: 16.0225 - val_accuracy: 0.4036\n",
            "Epoch 1643/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.1855 - accuracy: 0.9839 - val_loss: 16.0263 - val_accuracy: 0.4036\n",
            "Epoch 1644/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.1855 - accuracy: 0.9893 - val_loss: 16.0202 - val_accuracy: 0.4071\n",
            "Epoch 1645/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.1825 - accuracy: 0.9866 - val_loss: 16.0439 - val_accuracy: 0.4000\n",
            "Epoch 1646/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.1845 - accuracy: 0.9821 - val_loss: 16.0547 - val_accuracy: 0.4000\n",
            "Epoch 1647/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.1829 - accuracy: 0.9848 - val_loss: 16.0780 - val_accuracy: 0.3964\n",
            "Epoch 1648/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.1802 - accuracy: 0.9884 - val_loss: 16.0842 - val_accuracy: 0.3929\n",
            "Epoch 1649/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.1792 - accuracy: 0.9902 - val_loss: 16.0856 - val_accuracy: 0.4071\n",
            "Epoch 1650/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.1808 - accuracy: 0.9866 - val_loss: 16.0975 - val_accuracy: 0.4000\n",
            "Epoch 1651/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.1767 - accuracy: 0.9893 - val_loss: 16.1153 - val_accuracy: 0.4000\n",
            "Epoch 1652/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.1842 - accuracy: 0.9857 - val_loss: 16.0998 - val_accuracy: 0.4036\n",
            "Epoch 1653/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.1824 - accuracy: 0.9857 - val_loss: 16.1141 - val_accuracy: 0.4036\n",
            "Epoch 1654/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.1751 - accuracy: 0.9884 - val_loss: 16.1083 - val_accuracy: 0.4071\n",
            "Epoch 1655/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.1777 - accuracy: 0.9857 - val_loss: 16.1124 - val_accuracy: 0.3964\n",
            "Epoch 1656/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.1787 - accuracy: 0.9839 - val_loss: 16.1717 - val_accuracy: 0.3929\n",
            "Epoch 1657/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.1833 - accuracy: 0.9857 - val_loss: 16.1369 - val_accuracy: 0.4071\n",
            "Epoch 1658/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.1801 - accuracy: 0.9866 - val_loss: 16.1435 - val_accuracy: 0.3964\n",
            "Epoch 1659/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.1775 - accuracy: 0.9902 - val_loss: 16.1689 - val_accuracy: 0.4036\n",
            "Epoch 1660/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.1738 - accuracy: 0.9929 - val_loss: 16.1552 - val_accuracy: 0.4036\n",
            "Epoch 1661/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.1769 - accuracy: 0.9848 - val_loss: 16.1870 - val_accuracy: 0.4071\n",
            "Epoch 1662/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.1756 - accuracy: 0.9884 - val_loss: 16.1971 - val_accuracy: 0.3964\n",
            "Epoch 1663/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.1781 - accuracy: 0.9821 - val_loss: 16.1965 - val_accuracy: 0.4036\n",
            "Epoch 1664/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.1712 - accuracy: 0.9857 - val_loss: 16.1833 - val_accuracy: 0.4071\n",
            "Epoch 1665/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.1706 - accuracy: 0.9884 - val_loss: 16.2121 - val_accuracy: 0.4036\n",
            "Epoch 1666/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.1741 - accuracy: 0.9911 - val_loss: 16.2178 - val_accuracy: 0.4036\n",
            "Epoch 1667/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.1730 - accuracy: 0.9902 - val_loss: 16.2282 - val_accuracy: 0.4036\n",
            "Epoch 1668/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.1710 - accuracy: 0.9857 - val_loss: 16.2248 - val_accuracy: 0.4000\n",
            "Epoch 1669/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.1719 - accuracy: 0.9839 - val_loss: 16.2553 - val_accuracy: 0.4071\n",
            "Epoch 1670/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.1704 - accuracy: 0.9893 - val_loss: 16.2258 - val_accuracy: 0.4071\n",
            "Epoch 1671/2000\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 0.1696 - accuracy: 0.9902 - val_loss: 16.2499 - val_accuracy: 0.4071\n",
            "Epoch 1672/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.1684 - accuracy: 0.9929 - val_loss: 16.2658 - val_accuracy: 0.4071\n",
            "Epoch 1673/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.1691 - accuracy: 0.9875 - val_loss: 16.2655 - val_accuracy: 0.4000\n",
            "Epoch 1674/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.1673 - accuracy: 0.9911 - val_loss: 16.2784 - val_accuracy: 0.4071\n",
            "Epoch 1675/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.1694 - accuracy: 0.9902 - val_loss: 16.2728 - val_accuracy: 0.4036\n",
            "Epoch 1676/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.1688 - accuracy: 0.9866 - val_loss: 16.2904 - val_accuracy: 0.4036\n",
            "Epoch 1677/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.1682 - accuracy: 0.9884 - val_loss: 16.2928 - val_accuracy: 0.4071\n",
            "Epoch 1678/2000\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 0.1676 - accuracy: 0.9929 - val_loss: 16.3065 - val_accuracy: 0.4036\n",
            "Epoch 1679/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.1677 - accuracy: 0.9848 - val_loss: 16.3121 - val_accuracy: 0.4036\n",
            "Epoch 1680/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.1662 - accuracy: 0.9902 - val_loss: 16.3172 - val_accuracy: 0.4000\n",
            "Epoch 1681/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.1640 - accuracy: 0.9911 - val_loss: 16.3390 - val_accuracy: 0.4036\n",
            "Epoch 1682/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.1659 - accuracy: 0.9893 - val_loss: 16.3272 - val_accuracy: 0.4071\n",
            "Epoch 1683/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.1632 - accuracy: 0.9937 - val_loss: 16.3457 - val_accuracy: 0.4036\n",
            "Epoch 1684/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.1635 - accuracy: 0.9902 - val_loss: 16.3522 - val_accuracy: 0.4036\n",
            "Epoch 1685/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.1644 - accuracy: 0.9893 - val_loss: 16.3576 - val_accuracy: 0.4071\n",
            "Epoch 1686/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.1627 - accuracy: 0.9911 - val_loss: 16.3592 - val_accuracy: 0.4071\n",
            "Epoch 1687/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.1620 - accuracy: 0.9920 - val_loss: 16.3591 - val_accuracy: 0.4071\n",
            "Epoch 1688/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.1605 - accuracy: 0.9946 - val_loss: 16.3900 - val_accuracy: 0.4036\n",
            "Epoch 1689/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.1604 - accuracy: 0.9911 - val_loss: 16.3885 - val_accuracy: 0.4071\n",
            "Epoch 1690/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.1608 - accuracy: 0.9937 - val_loss: 16.4049 - val_accuracy: 0.4036\n",
            "Epoch 1691/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.1614 - accuracy: 0.9893 - val_loss: 16.4110 - val_accuracy: 0.4000\n",
            "Epoch 1692/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.1606 - accuracy: 0.9929 - val_loss: 16.4007 - val_accuracy: 0.4036\n",
            "Epoch 1693/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.1588 - accuracy: 0.9911 - val_loss: 16.4361 - val_accuracy: 0.4071\n",
            "Epoch 1694/2000\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 0.1627 - accuracy: 0.9875 - val_loss: 16.4087 - val_accuracy: 0.4036\n",
            "Epoch 1695/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.1588 - accuracy: 0.9920 - val_loss: 16.4605 - val_accuracy: 0.4036\n",
            "Epoch 1696/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.1611 - accuracy: 0.9920 - val_loss: 16.4219 - val_accuracy: 0.4071\n",
            "Epoch 1697/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.1589 - accuracy: 0.9884 - val_loss: 16.4709 - val_accuracy: 0.4071\n",
            "Epoch 1698/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.1566 - accuracy: 0.9920 - val_loss: 16.4716 - val_accuracy: 0.4036\n",
            "Epoch 1699/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.1602 - accuracy: 0.9902 - val_loss: 16.4686 - val_accuracy: 0.4071\n",
            "Epoch 1700/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.1614 - accuracy: 0.9866 - val_loss: 16.4674 - val_accuracy: 0.4071\n",
            "Epoch 1701/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.1554 - accuracy: 0.9911 - val_loss: 16.4595 - val_accuracy: 0.4036\n",
            "Epoch 1702/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.1567 - accuracy: 0.9937 - val_loss: 16.4983 - val_accuracy: 0.4000\n",
            "Epoch 1703/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.1584 - accuracy: 0.9911 - val_loss: 16.5187 - val_accuracy: 0.4036\n",
            "Epoch 1704/2000\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 0.1558 - accuracy: 0.9929 - val_loss: 16.4977 - val_accuracy: 0.4036\n",
            "Epoch 1705/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.1567 - accuracy: 0.9893 - val_loss: 16.4783 - val_accuracy: 0.4071\n",
            "Epoch 1706/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.1543 - accuracy: 0.9911 - val_loss: 16.5417 - val_accuracy: 0.4036\n",
            "Epoch 1707/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.1558 - accuracy: 0.9929 - val_loss: 16.5131 - val_accuracy: 0.4071\n",
            "Epoch 1708/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.1564 - accuracy: 0.9929 - val_loss: 16.5394 - val_accuracy: 0.4071\n",
            "Epoch 1709/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.1525 - accuracy: 0.9920 - val_loss: 16.5315 - val_accuracy: 0.4036\n",
            "Epoch 1710/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.1561 - accuracy: 0.9875 - val_loss: 16.5603 - val_accuracy: 0.4036\n",
            "Epoch 1711/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.1528 - accuracy: 0.9911 - val_loss: 16.5203 - val_accuracy: 0.4036\n",
            "Epoch 1712/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.1531 - accuracy: 0.9937 - val_loss: 16.5522 - val_accuracy: 0.4036\n",
            "Epoch 1713/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.1528 - accuracy: 0.9911 - val_loss: 16.5599 - val_accuracy: 0.4036\n",
            "Epoch 1714/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.1509 - accuracy: 0.9946 - val_loss: 16.5697 - val_accuracy: 0.4036\n",
            "Epoch 1715/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.1503 - accuracy: 0.9929 - val_loss: 16.5598 - val_accuracy: 0.4071\n",
            "Epoch 1716/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.1496 - accuracy: 0.9937 - val_loss: 16.5800 - val_accuracy: 0.4036\n",
            "Epoch 1717/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.1502 - accuracy: 0.9911 - val_loss: 16.6018 - val_accuracy: 0.4071\n",
            "Epoch 1718/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.1478 - accuracy: 0.9946 - val_loss: 16.5913 - val_accuracy: 0.4071\n",
            "Epoch 1719/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.1494 - accuracy: 0.9937 - val_loss: 16.6329 - val_accuracy: 0.4071\n",
            "Epoch 1720/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.1463 - accuracy: 0.9964 - val_loss: 16.6184 - val_accuracy: 0.3929\n",
            "Epoch 1721/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.1491 - accuracy: 0.9920 - val_loss: 16.6187 - val_accuracy: 0.4000\n",
            "Epoch 1722/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.1478 - accuracy: 0.9937 - val_loss: 16.6278 - val_accuracy: 0.4071\n",
            "Epoch 1723/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.1469 - accuracy: 0.9929 - val_loss: 16.6450 - val_accuracy: 0.4036\n",
            "Epoch 1724/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.1480 - accuracy: 0.9955 - val_loss: 16.6287 - val_accuracy: 0.4036\n",
            "Epoch 1725/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.1444 - accuracy: 0.9893 - val_loss: 16.6609 - val_accuracy: 0.4000\n",
            "Epoch 1726/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.1474 - accuracy: 0.9902 - val_loss: 16.6586 - val_accuracy: 0.4071\n",
            "Epoch 1727/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.1472 - accuracy: 0.9937 - val_loss: 16.6651 - val_accuracy: 0.4000\n",
            "Epoch 1728/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.1457 - accuracy: 0.9937 - val_loss: 16.6726 - val_accuracy: 0.4071\n",
            "Epoch 1729/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.1444 - accuracy: 0.9955 - val_loss: 16.6727 - val_accuracy: 0.4071\n",
            "Epoch 1730/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.1439 - accuracy: 0.9964 - val_loss: 16.6728 - val_accuracy: 0.4036\n",
            "Epoch 1731/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.1420 - accuracy: 0.9946 - val_loss: 16.6797 - val_accuracy: 0.4036\n",
            "Epoch 1732/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.1455 - accuracy: 0.9946 - val_loss: 16.7138 - val_accuracy: 0.4071\n",
            "Epoch 1733/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.1445 - accuracy: 0.9937 - val_loss: 16.7043 - val_accuracy: 0.4071\n",
            "Epoch 1734/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.1426 - accuracy: 0.9929 - val_loss: 16.7091 - val_accuracy: 0.4036\n",
            "Epoch 1735/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.1410 - accuracy: 0.9937 - val_loss: 16.7285 - val_accuracy: 0.4071\n",
            "Epoch 1736/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.1442 - accuracy: 0.9946 - val_loss: 16.7483 - val_accuracy: 0.4071\n",
            "Epoch 1737/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.1442 - accuracy: 0.9964 - val_loss: 16.7340 - val_accuracy: 0.4071\n",
            "Epoch 1738/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.1420 - accuracy: 0.9929 - val_loss: 16.7627 - val_accuracy: 0.4036\n",
            "Epoch 1739/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.1415 - accuracy: 0.9955 - val_loss: 16.7474 - val_accuracy: 0.4071\n",
            "Epoch 1740/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.1385 - accuracy: 0.9955 - val_loss: 16.7566 - val_accuracy: 0.4071\n",
            "Epoch 1741/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.1415 - accuracy: 0.9946 - val_loss: 16.7725 - val_accuracy: 0.4071\n",
            "Epoch 1742/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.1431 - accuracy: 0.9955 - val_loss: 16.7698 - val_accuracy: 0.4071\n",
            "Epoch 1743/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.1393 - accuracy: 0.9946 - val_loss: 16.7852 - val_accuracy: 0.4071\n",
            "Epoch 1744/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.1393 - accuracy: 0.9955 - val_loss: 16.8002 - val_accuracy: 0.4036\n",
            "Epoch 1745/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.1387 - accuracy: 0.9911 - val_loss: 16.7978 - val_accuracy: 0.4036\n",
            "Epoch 1746/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.1393 - accuracy: 0.9964 - val_loss: 16.7923 - val_accuracy: 0.4071\n",
            "Epoch 1747/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.1374 - accuracy: 0.9946 - val_loss: 16.8139 - val_accuracy: 0.4071\n",
            "Epoch 1748/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.1399 - accuracy: 0.9937 - val_loss: 16.8375 - val_accuracy: 0.4000\n",
            "Epoch 1749/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.1401 - accuracy: 0.9929 - val_loss: 16.8309 - val_accuracy: 0.4071\n",
            "Epoch 1750/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.1367 - accuracy: 0.9973 - val_loss: 16.8208 - val_accuracy: 0.4071\n",
            "Epoch 1751/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.1367 - accuracy: 0.9955 - val_loss: 16.8385 - val_accuracy: 0.4000\n",
            "Epoch 1752/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.1402 - accuracy: 0.9902 - val_loss: 16.8350 - val_accuracy: 0.4000\n",
            "Epoch 1753/2000\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 0.1394 - accuracy: 0.9937 - val_loss: 16.8459 - val_accuracy: 0.4071\n",
            "Epoch 1754/2000\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 0.1378 - accuracy: 0.9955 - val_loss: 16.8656 - val_accuracy: 0.4000\n",
            "Epoch 1755/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.1333 - accuracy: 0.9929 - val_loss: 16.8591 - val_accuracy: 0.4071\n",
            "Epoch 1756/2000\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 0.1359 - accuracy: 0.9973 - val_loss: 16.8693 - val_accuracy: 0.4071\n",
            "Epoch 1757/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.1312 - accuracy: 0.9973 - val_loss: 16.8861 - val_accuracy: 0.4071\n",
            "Epoch 1758/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.1358 - accuracy: 0.9955 - val_loss: 16.8793 - val_accuracy: 0.4071\n",
            "Epoch 1759/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.1323 - accuracy: 0.9973 - val_loss: 16.8839 - val_accuracy: 0.4036\n",
            "Epoch 1760/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.1355 - accuracy: 0.9911 - val_loss: 16.8862 - val_accuracy: 0.4071\n",
            "Epoch 1761/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.1308 - accuracy: 0.9973 - val_loss: 16.9138 - val_accuracy: 0.4000\n",
            "Epoch 1762/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.1334 - accuracy: 0.9946 - val_loss: 16.9049 - val_accuracy: 0.4036\n",
            "Epoch 1763/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.1323 - accuracy: 0.9946 - val_loss: 16.9204 - val_accuracy: 0.4036\n",
            "Epoch 1764/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.1293 - accuracy: 0.9982 - val_loss: 16.9074 - val_accuracy: 0.4036\n",
            "Epoch 1765/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.1310 - accuracy: 0.9929 - val_loss: 16.9340 - val_accuracy: 0.4071\n",
            "Epoch 1766/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.1310 - accuracy: 0.9964 - val_loss: 16.9177 - val_accuracy: 0.4036\n",
            "Epoch 1767/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.1323 - accuracy: 0.9946 - val_loss: 16.9338 - val_accuracy: 0.4071\n",
            "Epoch 1768/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.1304 - accuracy: 0.9946 - val_loss: 16.9362 - val_accuracy: 0.4036\n",
            "Epoch 1769/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.1283 - accuracy: 0.9973 - val_loss: 16.9514 - val_accuracy: 0.4071\n",
            "Epoch 1770/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.1301 - accuracy: 0.9964 - val_loss: 16.9549 - val_accuracy: 0.4071\n",
            "Epoch 1771/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.1281 - accuracy: 0.9973 - val_loss: 16.9569 - val_accuracy: 0.4071\n",
            "Epoch 1772/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.1278 - accuracy: 0.9955 - val_loss: 16.9636 - val_accuracy: 0.4071\n",
            "Epoch 1773/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.1298 - accuracy: 0.9955 - val_loss: 16.9937 - val_accuracy: 0.4071\n",
            "Epoch 1774/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.1288 - accuracy: 0.9982 - val_loss: 17.0103 - val_accuracy: 0.4036\n",
            "Epoch 1775/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.1288 - accuracy: 0.9964 - val_loss: 16.9992 - val_accuracy: 0.4036\n",
            "Epoch 1776/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.1297 - accuracy: 0.9955 - val_loss: 17.0053 - val_accuracy: 0.4071\n",
            "Epoch 1777/2000\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 0.1272 - accuracy: 0.9982 - val_loss: 17.0055 - val_accuracy: 0.4071\n",
            "Epoch 1778/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.1268 - accuracy: 0.9982 - val_loss: 17.0088 - val_accuracy: 0.4071\n",
            "Epoch 1779/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.1272 - accuracy: 0.9946 - val_loss: 17.0436 - val_accuracy: 0.4071\n",
            "Epoch 1780/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.1250 - accuracy: 0.9982 - val_loss: 17.0353 - val_accuracy: 0.4071\n",
            "Epoch 1781/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.1272 - accuracy: 0.9964 - val_loss: 17.0424 - val_accuracy: 0.4071\n",
            "Epoch 1782/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.1245 - accuracy: 0.9973 - val_loss: 17.0475 - val_accuracy: 0.4000\n",
            "Epoch 1783/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.1273 - accuracy: 0.9964 - val_loss: 17.0504 - val_accuracy: 0.4071\n",
            "Epoch 1784/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.1245 - accuracy: 0.9946 - val_loss: 17.0431 - val_accuracy: 0.4071\n",
            "Epoch 1785/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.1225 - accuracy: 0.9982 - val_loss: 17.0608 - val_accuracy: 0.4036\n",
            "Epoch 1786/2000\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 0.1255 - accuracy: 0.9973 - val_loss: 17.0961 - val_accuracy: 0.4000\n",
            "Epoch 1787/2000\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 0.1274 - accuracy: 0.9955 - val_loss: 17.0761 - val_accuracy: 0.4071\n",
            "Epoch 1788/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.1247 - accuracy: 0.9982 - val_loss: 17.0864 - val_accuracy: 0.4071\n",
            "Epoch 1789/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.1234 - accuracy: 0.9982 - val_loss: 17.1018 - val_accuracy: 0.4071\n",
            "Epoch 1790/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.1241 - accuracy: 0.9946 - val_loss: 17.0943 - val_accuracy: 0.4071\n",
            "Epoch 1791/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.1234 - accuracy: 0.9955 - val_loss: 17.0965 - val_accuracy: 0.4071\n",
            "Epoch 1792/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.1228 - accuracy: 0.9973 - val_loss: 17.1276 - val_accuracy: 0.4071\n",
            "Epoch 1793/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.1230 - accuracy: 0.9964 - val_loss: 17.1067 - val_accuracy: 0.4071\n",
            "Epoch 1794/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.1199 - accuracy: 0.9982 - val_loss: 17.1192 - val_accuracy: 0.4071\n",
            "Epoch 1795/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.1224 - accuracy: 0.9973 - val_loss: 17.1375 - val_accuracy: 0.4071\n",
            "Epoch 1796/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.1223 - accuracy: 0.9964 - val_loss: 17.1388 - val_accuracy: 0.4071\n",
            "Epoch 1797/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.1230 - accuracy: 0.9955 - val_loss: 17.1357 - val_accuracy: 0.4071\n",
            "Epoch 1798/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.1206 - accuracy: 0.9982 - val_loss: 17.1375 - val_accuracy: 0.4036\n",
            "Epoch 1799/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.1196 - accuracy: 0.9964 - val_loss: 17.1686 - val_accuracy: 0.4071\n",
            "Epoch 1800/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.1205 - accuracy: 0.9982 - val_loss: 17.1472 - val_accuracy: 0.4071\n",
            "Epoch 1801/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.1188 - accuracy: 0.9982 - val_loss: 17.1506 - val_accuracy: 0.4071\n",
            "Epoch 1802/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.1191 - accuracy: 0.9982 - val_loss: 17.1794 - val_accuracy: 0.4071\n",
            "Epoch 1803/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.1179 - accuracy: 0.9991 - val_loss: 17.1679 - val_accuracy: 0.4071\n",
            "Epoch 1804/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.1198 - accuracy: 0.9982 - val_loss: 17.1669 - val_accuracy: 0.4071\n",
            "Epoch 1805/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.1172 - accuracy: 0.9991 - val_loss: 17.1896 - val_accuracy: 0.4071\n",
            "Epoch 1806/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.1187 - accuracy: 0.9982 - val_loss: 17.2000 - val_accuracy: 0.4071\n",
            "Epoch 1807/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.1184 - accuracy: 0.9955 - val_loss: 17.1872 - val_accuracy: 0.4071\n",
            "Epoch 1808/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.1153 - accuracy: 0.9973 - val_loss: 17.2325 - val_accuracy: 0.4071\n",
            "Epoch 1809/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.1186 - accuracy: 0.9973 - val_loss: 17.1850 - val_accuracy: 0.4071\n",
            "Epoch 1810/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.1165 - accuracy: 0.9964 - val_loss: 17.2178 - val_accuracy: 0.4071\n",
            "Epoch 1811/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.1193 - accuracy: 0.9955 - val_loss: 17.2526 - val_accuracy: 0.4071\n",
            "Epoch 1812/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.1165 - accuracy: 0.9973 - val_loss: 17.2259 - val_accuracy: 0.4071\n",
            "Epoch 1813/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.1147 - accuracy: 0.9982 - val_loss: 17.2334 - val_accuracy: 0.4036\n",
            "Epoch 1814/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.1165 - accuracy: 0.9982 - val_loss: 17.2602 - val_accuracy: 0.4071\n",
            "Epoch 1815/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.1171 - accuracy: 0.9982 - val_loss: 17.2599 - val_accuracy: 0.4071\n",
            "Epoch 1816/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.1139 - accuracy: 0.9991 - val_loss: 17.2586 - val_accuracy: 0.4071\n",
            "Epoch 1817/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.1148 - accuracy: 0.9964 - val_loss: 17.2778 - val_accuracy: 0.4071\n",
            "Epoch 1818/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.1141 - accuracy: 0.9973 - val_loss: 17.2728 - val_accuracy: 0.4071\n",
            "Epoch 1819/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.1147 - accuracy: 0.9991 - val_loss: 17.2768 - val_accuracy: 0.4071\n",
            "Epoch 1820/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.1140 - accuracy: 1.0000 - val_loss: 17.2976 - val_accuracy: 0.4071\n",
            "Epoch 1821/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.1125 - accuracy: 0.9973 - val_loss: 17.2838 - val_accuracy: 0.4071\n",
            "Epoch 1822/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.1117 - accuracy: 0.9982 - val_loss: 17.3029 - val_accuracy: 0.4036\n",
            "Epoch 1823/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.1134 - accuracy: 0.9982 - val_loss: 17.2942 - val_accuracy: 0.4071\n",
            "Epoch 1824/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.1103 - accuracy: 0.9991 - val_loss: 17.3278 - val_accuracy: 0.4071\n",
            "Epoch 1825/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.1123 - accuracy: 0.9991 - val_loss: 17.3142 - val_accuracy: 0.4071\n",
            "Epoch 1826/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.1116 - accuracy: 0.9991 - val_loss: 17.3402 - val_accuracy: 0.4071\n",
            "Epoch 1827/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.1129 - accuracy: 0.9991 - val_loss: 17.3396 - val_accuracy: 0.4071\n",
            "Epoch 1828/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.1119 - accuracy: 0.9973 - val_loss: 17.3398 - val_accuracy: 0.4071\n",
            "Epoch 1829/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.1108 - accuracy: 0.9982 - val_loss: 17.3410 - val_accuracy: 0.4071\n",
            "Epoch 1830/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.1104 - accuracy: 0.9982 - val_loss: 17.3439 - val_accuracy: 0.4036\n",
            "Epoch 1831/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.1107 - accuracy: 0.9991 - val_loss: 17.3896 - val_accuracy: 0.4071\n",
            "Epoch 1832/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.1120 - accuracy: 0.9973 - val_loss: 17.3780 - val_accuracy: 0.4071\n",
            "Epoch 1833/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.1093 - accuracy: 0.9991 - val_loss: 17.3655 - val_accuracy: 0.4071\n",
            "Epoch 1834/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.1113 - accuracy: 0.9973 - val_loss: 17.3750 - val_accuracy: 0.4071\n",
            "Epoch 1835/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.1081 - accuracy: 1.0000 - val_loss: 17.3659 - val_accuracy: 0.4071\n",
            "Epoch 1836/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.1095 - accuracy: 0.9991 - val_loss: 17.3995 - val_accuracy: 0.4036\n",
            "Epoch 1837/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.1091 - accuracy: 0.9982 - val_loss: 17.3959 - val_accuracy: 0.4071\n",
            "Epoch 1838/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.1085 - accuracy: 0.9991 - val_loss: 17.4014 - val_accuracy: 0.4071\n",
            "Epoch 1839/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.1083 - accuracy: 0.9982 - val_loss: 17.4035 - val_accuracy: 0.4071\n",
            "Epoch 1840/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.1088 - accuracy: 0.9973 - val_loss: 17.4256 - val_accuracy: 0.4071\n",
            "Epoch 1841/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.1086 - accuracy: 0.9982 - val_loss: 17.4108 - val_accuracy: 0.4071\n",
            "Epoch 1842/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.1087 - accuracy: 0.9973 - val_loss: 17.4327 - val_accuracy: 0.4071\n",
            "Epoch 1843/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.1064 - accuracy: 0.9982 - val_loss: 17.4155 - val_accuracy: 0.4071\n",
            "Epoch 1844/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.1072 - accuracy: 0.9982 - val_loss: 17.4398 - val_accuracy: 0.4036\n",
            "Epoch 1845/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.1061 - accuracy: 1.0000 - val_loss: 17.4473 - val_accuracy: 0.4071\n",
            "Epoch 1846/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.1079 - accuracy: 0.9973 - val_loss: 17.4546 - val_accuracy: 0.4071\n",
            "Epoch 1847/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.1059 - accuracy: 0.9973 - val_loss: 17.4476 - val_accuracy: 0.4036\n",
            "Epoch 1848/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.1047 - accuracy: 0.9982 - val_loss: 17.4642 - val_accuracy: 0.4071\n",
            "Epoch 1849/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.1075 - accuracy: 0.9982 - val_loss: 17.4808 - val_accuracy: 0.4071\n",
            "Epoch 1850/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.1048 - accuracy: 0.9982 - val_loss: 17.5032 - val_accuracy: 0.4036\n",
            "Epoch 1851/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.1099 - accuracy: 0.9946 - val_loss: 17.4822 - val_accuracy: 0.4071\n",
            "Epoch 1852/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.1049 - accuracy: 0.9991 - val_loss: 17.4824 - val_accuracy: 0.4071\n",
            "Epoch 1853/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.1035 - accuracy: 0.9991 - val_loss: 17.4783 - val_accuracy: 0.4071\n",
            "Epoch 1854/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.1049 - accuracy: 1.0000 - val_loss: 17.4936 - val_accuracy: 0.4071\n",
            "Epoch 1855/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.1047 - accuracy: 0.9991 - val_loss: 17.5122 - val_accuracy: 0.4071\n",
            "Epoch 1856/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.1017 - accuracy: 1.0000 - val_loss: 17.5192 - val_accuracy: 0.4071\n",
            "Epoch 1857/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.1050 - accuracy: 0.9973 - val_loss: 17.5075 - val_accuracy: 0.4071\n",
            "Epoch 1858/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.1051 - accuracy: 0.9955 - val_loss: 17.5186 - val_accuracy: 0.4071\n",
            "Epoch 1859/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.1030 - accuracy: 0.9991 - val_loss: 17.5284 - val_accuracy: 0.4071\n",
            "Epoch 1860/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.1031 - accuracy: 0.9982 - val_loss: 17.5094 - val_accuracy: 0.4071\n",
            "Epoch 1861/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.1038 - accuracy: 0.9982 - val_loss: 17.5392 - val_accuracy: 0.4071\n",
            "Epoch 1862/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.1024 - accuracy: 1.0000 - val_loss: 17.5462 - val_accuracy: 0.4071\n",
            "Epoch 1863/2000\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 0.1025 - accuracy: 0.9991 - val_loss: 17.5850 - val_accuracy: 0.4071\n",
            "Epoch 1864/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.1048 - accuracy: 0.9982 - val_loss: 17.5651 - val_accuracy: 0.4071\n",
            "Epoch 1865/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.1010 - accuracy: 0.9991 - val_loss: 17.5703 - val_accuracy: 0.4071\n",
            "Epoch 1866/2000\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 0.1013 - accuracy: 0.9991 - val_loss: 17.5818 - val_accuracy: 0.4071\n",
            "Epoch 1867/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.1031 - accuracy: 0.9991 - val_loss: 17.5778 - val_accuracy: 0.4071\n",
            "Epoch 1868/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.1005 - accuracy: 0.9991 - val_loss: 17.5854 - val_accuracy: 0.4071\n",
            "Epoch 1869/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.1014 - accuracy: 0.9991 - val_loss: 17.5973 - val_accuracy: 0.4071\n",
            "Epoch 1870/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.1001 - accuracy: 0.9991 - val_loss: 17.6137 - val_accuracy: 0.4071\n",
            "Epoch 1871/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.0987 - accuracy: 0.9991 - val_loss: 17.6059 - val_accuracy: 0.4071\n",
            "Epoch 1872/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.1001 - accuracy: 0.9991 - val_loss: 17.6062 - val_accuracy: 0.4071\n",
            "Epoch 1873/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.0996 - accuracy: 0.9982 - val_loss: 17.6185 - val_accuracy: 0.4071\n",
            "Epoch 1874/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.1000 - accuracy: 0.9982 - val_loss: 17.6242 - val_accuracy: 0.4071\n",
            "Epoch 1875/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.0985 - accuracy: 0.9991 - val_loss: 17.6242 - val_accuracy: 0.4071\n",
            "Epoch 1876/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.0987 - accuracy: 0.9991 - val_loss: 17.6291 - val_accuracy: 0.4071\n",
            "Epoch 1877/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.0986 - accuracy: 0.9982 - val_loss: 17.6253 - val_accuracy: 0.4071\n",
            "Epoch 1878/2000\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 0.0992 - accuracy: 0.9991 - val_loss: 17.6521 - val_accuracy: 0.4071\n",
            "Epoch 1879/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.0982 - accuracy: 0.9991 - val_loss: 17.6436 - val_accuracy: 0.4071\n",
            "Epoch 1880/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.0981 - accuracy: 0.9982 - val_loss: 17.6615 - val_accuracy: 0.4071\n",
            "Epoch 1881/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.0982 - accuracy: 0.9982 - val_loss: 17.6759 - val_accuracy: 0.4036\n",
            "Epoch 1882/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.0988 - accuracy: 1.0000 - val_loss: 17.6572 - val_accuracy: 0.4071\n",
            "Epoch 1883/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.0984 - accuracy: 1.0000 - val_loss: 17.6708 - val_accuracy: 0.4071\n",
            "Epoch 1884/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.0972 - accuracy: 0.9991 - val_loss: 17.6746 - val_accuracy: 0.4071\n",
            "Epoch 1885/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.1002 - accuracy: 0.9982 - val_loss: 17.6802 - val_accuracy: 0.4071\n",
            "Epoch 1886/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.0957 - accuracy: 0.9982 - val_loss: 17.7188 - val_accuracy: 0.4071\n",
            "Epoch 1887/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.0980 - accuracy: 0.9982 - val_loss: 17.6958 - val_accuracy: 0.4071\n",
            "Epoch 1888/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.0951 - accuracy: 1.0000 - val_loss: 17.6976 - val_accuracy: 0.4071\n",
            "Epoch 1889/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.0973 - accuracy: 1.0000 - val_loss: 17.6929 - val_accuracy: 0.4071\n",
            "Epoch 1890/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.0957 - accuracy: 0.9982 - val_loss: 17.7143 - val_accuracy: 0.4036\n",
            "Epoch 1891/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.0961 - accuracy: 0.9982 - val_loss: 17.7064 - val_accuracy: 0.4071\n",
            "Epoch 1892/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.0956 - accuracy: 0.9991 - val_loss: 17.7211 - val_accuracy: 0.4071\n",
            "Epoch 1893/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.0952 - accuracy: 1.0000 - val_loss: 17.7458 - val_accuracy: 0.4071\n",
            "Epoch 1894/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.0949 - accuracy: 1.0000 - val_loss: 17.7293 - val_accuracy: 0.4071\n",
            "Epoch 1895/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.0949 - accuracy: 0.9973 - val_loss: 17.7413 - val_accuracy: 0.4071\n",
            "Epoch 1896/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.0955 - accuracy: 0.9991 - val_loss: 17.7397 - val_accuracy: 0.4071\n",
            "Epoch 1897/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.0943 - accuracy: 0.9991 - val_loss: 17.7461 - val_accuracy: 0.4071\n",
            "Epoch 1898/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.0937 - accuracy: 0.9991 - val_loss: 17.7651 - val_accuracy: 0.4071\n",
            "Epoch 1899/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.0928 - accuracy: 0.9991 - val_loss: 17.7603 - val_accuracy: 0.4071\n",
            "Epoch 1900/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.0938 - accuracy: 0.9991 - val_loss: 17.7481 - val_accuracy: 0.4071\n",
            "Epoch 1901/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.0940 - accuracy: 0.9982 - val_loss: 17.7641 - val_accuracy: 0.4071\n",
            "Epoch 1902/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.0921 - accuracy: 1.0000 - val_loss: 17.7741 - val_accuracy: 0.4071\n",
            "Epoch 1903/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.0920 - accuracy: 0.9991 - val_loss: 17.7776 - val_accuracy: 0.4071\n",
            "Epoch 1904/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.0926 - accuracy: 1.0000 - val_loss: 17.7877 - val_accuracy: 0.4071\n",
            "Epoch 1905/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.0935 - accuracy: 0.9991 - val_loss: 17.8098 - val_accuracy: 0.4071\n",
            "Epoch 1906/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.0943 - accuracy: 0.9991 - val_loss: 17.8024 - val_accuracy: 0.4071\n",
            "Epoch 1907/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.0917 - accuracy: 1.0000 - val_loss: 17.8021 - val_accuracy: 0.4071\n",
            "Epoch 1908/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.0914 - accuracy: 1.0000 - val_loss: 17.8150 - val_accuracy: 0.4071\n",
            "Epoch 1909/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.0909 - accuracy: 0.9991 - val_loss: 17.8133 - val_accuracy: 0.4036\n",
            "Epoch 1910/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.0936 - accuracy: 1.0000 - val_loss: 17.8159 - val_accuracy: 0.4071\n",
            "Epoch 1911/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.0919 - accuracy: 0.9982 - val_loss: 17.8239 - val_accuracy: 0.4071\n",
            "Epoch 1912/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.0916 - accuracy: 0.9991 - val_loss: 17.8189 - val_accuracy: 0.4071\n",
            "Epoch 1913/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.0900 - accuracy: 1.0000 - val_loss: 17.8427 - val_accuracy: 0.4036\n",
            "Epoch 1914/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.0924 - accuracy: 0.9982 - val_loss: 17.8411 - val_accuracy: 0.4036\n",
            "Epoch 1915/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.0912 - accuracy: 0.9991 - val_loss: 17.8394 - val_accuracy: 0.4071\n",
            "Epoch 1916/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.0896 - accuracy: 1.0000 - val_loss: 17.8530 - val_accuracy: 0.4071\n",
            "Epoch 1917/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.0899 - accuracy: 1.0000 - val_loss: 17.8649 - val_accuracy: 0.4071\n",
            "Epoch 1918/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.0901 - accuracy: 0.9991 - val_loss: 17.8592 - val_accuracy: 0.4071\n",
            "Epoch 1919/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.0894 - accuracy: 1.0000 - val_loss: 17.8741 - val_accuracy: 0.4071\n",
            "Epoch 1920/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.0890 - accuracy: 0.9982 - val_loss: 17.8790 - val_accuracy: 0.4071\n",
            "Epoch 1921/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.0888 - accuracy: 1.0000 - val_loss: 17.8813 - val_accuracy: 0.4071\n",
            "Epoch 1922/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.0884 - accuracy: 0.9991 - val_loss: 17.8973 - val_accuracy: 0.4071\n",
            "Epoch 1923/2000\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 0.0883 - accuracy: 1.0000 - val_loss: 17.9060 - val_accuracy: 0.4071\n",
            "Epoch 1924/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.0881 - accuracy: 1.0000 - val_loss: 17.8983 - val_accuracy: 0.4071\n",
            "Epoch 1925/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.0885 - accuracy: 0.9982 - val_loss: 17.9095 - val_accuracy: 0.4071\n",
            "Epoch 1926/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.0886 - accuracy: 1.0000 - val_loss: 17.9024 - val_accuracy: 0.4071\n",
            "Epoch 1927/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.0884 - accuracy: 0.9991 - val_loss: 17.9260 - val_accuracy: 0.4071\n",
            "Epoch 1928/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.0879 - accuracy: 0.9991 - val_loss: 17.9256 - val_accuracy: 0.4071\n",
            "Epoch 1929/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.0874 - accuracy: 0.9991 - val_loss: 17.9349 - val_accuracy: 0.4071\n",
            "Epoch 1930/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.0890 - accuracy: 0.9991 - val_loss: 17.9428 - val_accuracy: 0.4071\n",
            "Epoch 1931/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.0870 - accuracy: 1.0000 - val_loss: 17.9357 - val_accuracy: 0.4071\n",
            "Epoch 1932/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.0870 - accuracy: 1.0000 - val_loss: 17.9560 - val_accuracy: 0.4071\n",
            "Epoch 1933/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.0863 - accuracy: 1.0000 - val_loss: 17.9716 - val_accuracy: 0.4071\n",
            "Epoch 1934/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.0863 - accuracy: 0.9991 - val_loss: 17.9576 - val_accuracy: 0.4071\n",
            "Epoch 1935/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.0871 - accuracy: 1.0000 - val_loss: 17.9667 - val_accuracy: 0.4071\n",
            "Epoch 1936/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.0865 - accuracy: 1.0000 - val_loss: 17.9660 - val_accuracy: 0.4071\n",
            "Epoch 1937/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.0854 - accuracy: 1.0000 - val_loss: 17.9758 - val_accuracy: 0.4071\n",
            "Epoch 1938/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.0873 - accuracy: 1.0000 - val_loss: 17.9790 - val_accuracy: 0.4071\n",
            "Epoch 1939/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.0862 - accuracy: 1.0000 - val_loss: 17.9857 - val_accuracy: 0.4036\n",
            "Epoch 1940/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.0863 - accuracy: 1.0000 - val_loss: 17.9927 - val_accuracy: 0.4036\n",
            "Epoch 1941/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.0859 - accuracy: 1.0000 - val_loss: 17.9879 - val_accuracy: 0.4071\n",
            "Epoch 1942/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.0854 - accuracy: 0.9991 - val_loss: 18.0123 - val_accuracy: 0.4071\n",
            "Epoch 1943/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.0855 - accuracy: 1.0000 - val_loss: 18.0088 - val_accuracy: 0.4071\n",
            "Epoch 1944/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.0844 - accuracy: 1.0000 - val_loss: 18.0238 - val_accuracy: 0.4036\n",
            "Epoch 1945/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.0855 - accuracy: 0.9982 - val_loss: 18.0072 - val_accuracy: 0.4071\n",
            "Epoch 1946/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.0846 - accuracy: 1.0000 - val_loss: 18.0203 - val_accuracy: 0.4071\n",
            "Epoch 1947/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.0840 - accuracy: 1.0000 - val_loss: 18.0277 - val_accuracy: 0.4071\n",
            "Epoch 1948/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.0839 - accuracy: 1.0000 - val_loss: 18.0374 - val_accuracy: 0.4071\n",
            "Epoch 1949/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.0850 - accuracy: 0.9991 - val_loss: 18.0356 - val_accuracy: 0.4071\n",
            "Epoch 1950/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.0845 - accuracy: 1.0000 - val_loss: 18.0404 - val_accuracy: 0.4071\n",
            "Epoch 1951/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.0841 - accuracy: 1.0000 - val_loss: 18.0402 - val_accuracy: 0.4071\n",
            "Epoch 1952/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.0842 - accuracy: 0.9982 - val_loss: 18.0510 - val_accuracy: 0.4071\n",
            "Epoch 1953/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.0834 - accuracy: 1.0000 - val_loss: 18.0653 - val_accuracy: 0.4071\n",
            "Epoch 1954/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.0855 - accuracy: 0.9991 - val_loss: 18.0602 - val_accuracy: 0.4071\n",
            "Epoch 1955/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.0832 - accuracy: 1.0000 - val_loss: 18.0717 - val_accuracy: 0.4071\n",
            "Epoch 1956/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.0825 - accuracy: 0.9991 - val_loss: 18.0807 - val_accuracy: 0.4071\n",
            "Epoch 1957/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.0824 - accuracy: 1.0000 - val_loss: 18.0780 - val_accuracy: 0.4071\n",
            "Epoch 1958/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.0827 - accuracy: 1.0000 - val_loss: 18.0912 - val_accuracy: 0.4071\n",
            "Epoch 1959/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.0815 - accuracy: 1.0000 - val_loss: 18.0874 - val_accuracy: 0.4071\n",
            "Epoch 1960/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.0830 - accuracy: 1.0000 - val_loss: 18.0976 - val_accuracy: 0.4071\n",
            "Epoch 1961/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.0814 - accuracy: 1.0000 - val_loss: 18.1003 - val_accuracy: 0.4071\n",
            "Epoch 1962/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.0821 - accuracy: 1.0000 - val_loss: 18.1000 - val_accuracy: 0.4071\n",
            "Epoch 1963/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.0807 - accuracy: 1.0000 - val_loss: 18.1029 - val_accuracy: 0.4071\n",
            "Epoch 1964/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.0825 - accuracy: 0.9991 - val_loss: 18.0923 - val_accuracy: 0.4071\n",
            "Epoch 1965/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.0816 - accuracy: 0.9991 - val_loss: 18.1150 - val_accuracy: 0.4071\n",
            "Epoch 1966/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.0811 - accuracy: 1.0000 - val_loss: 18.1270 - val_accuracy: 0.4071\n",
            "Epoch 1967/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.0796 - accuracy: 1.0000 - val_loss: 18.1320 - val_accuracy: 0.4071\n",
            "Epoch 1968/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.0805 - accuracy: 1.0000 - val_loss: 18.1371 - val_accuracy: 0.4071\n",
            "Epoch 1969/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.0797 - accuracy: 1.0000 - val_loss: 18.1380 - val_accuracy: 0.4071\n",
            "Epoch 1970/2000\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 0.0806 - accuracy: 1.0000 - val_loss: 18.1416 - val_accuracy: 0.4071\n",
            "Epoch 1971/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.0792 - accuracy: 1.0000 - val_loss: 18.1522 - val_accuracy: 0.4071\n",
            "Epoch 1972/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.0803 - accuracy: 1.0000 - val_loss: 18.1636 - val_accuracy: 0.4071\n",
            "Epoch 1973/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.0794 - accuracy: 1.0000 - val_loss: 18.1577 - val_accuracy: 0.4071\n",
            "Epoch 1974/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.0794 - accuracy: 1.0000 - val_loss: 18.1762 - val_accuracy: 0.4071\n",
            "Epoch 1975/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.0807 - accuracy: 0.9991 - val_loss: 18.1682 - val_accuracy: 0.4071\n",
            "Epoch 1976/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.0802 - accuracy: 1.0000 - val_loss: 18.1785 - val_accuracy: 0.4071\n",
            "Epoch 1977/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.0789 - accuracy: 1.0000 - val_loss: 18.2068 - val_accuracy: 0.4071\n",
            "Epoch 1978/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.0793 - accuracy: 0.9991 - val_loss: 18.1957 - val_accuracy: 0.4071\n",
            "Epoch 1979/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.0786 - accuracy: 1.0000 - val_loss: 18.2038 - val_accuracy: 0.4071\n",
            "Epoch 1980/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.0778 - accuracy: 1.0000 - val_loss: 18.2043 - val_accuracy: 0.4071\n",
            "Epoch 1981/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.0780 - accuracy: 1.0000 - val_loss: 18.2122 - val_accuracy: 0.4071\n",
            "Epoch 1982/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.0778 - accuracy: 1.0000 - val_loss: 18.2197 - val_accuracy: 0.4071\n",
            "Epoch 1983/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.0786 - accuracy: 1.0000 - val_loss: 18.2304 - val_accuracy: 0.4071\n",
            "Epoch 1984/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.0785 - accuracy: 1.0000 - val_loss: 18.2344 - val_accuracy: 0.4071\n",
            "Epoch 1985/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.0771 - accuracy: 1.0000 - val_loss: 18.2359 - val_accuracy: 0.4071\n",
            "Epoch 1986/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.0774 - accuracy: 1.0000 - val_loss: 18.2359 - val_accuracy: 0.4071\n",
            "Epoch 1987/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.0764 - accuracy: 1.0000 - val_loss: 18.2272 - val_accuracy: 0.4071\n",
            "Epoch 1988/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.0771 - accuracy: 1.0000 - val_loss: 18.2379 - val_accuracy: 0.4071\n",
            "Epoch 1989/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.0768 - accuracy: 1.0000 - val_loss: 18.2392 - val_accuracy: 0.4071\n",
            "Epoch 1990/2000\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 0.0771 - accuracy: 0.9991 - val_loss: 18.2518 - val_accuracy: 0.4071\n",
            "Epoch 1991/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.0768 - accuracy: 1.0000 - val_loss: 18.2533 - val_accuracy: 0.4071\n",
            "Epoch 1992/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.0766 - accuracy: 1.0000 - val_loss: 18.2697 - val_accuracy: 0.4071\n",
            "Epoch 1993/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.0759 - accuracy: 0.9991 - val_loss: 18.2599 - val_accuracy: 0.4071\n",
            "Epoch 1994/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.0770 - accuracy: 1.0000 - val_loss: 18.2701 - val_accuracy: 0.4071\n",
            "Epoch 1995/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.0762 - accuracy: 1.0000 - val_loss: 18.2755 - val_accuracy: 0.4071\n",
            "Epoch 1996/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.0750 - accuracy: 1.0000 - val_loss: 18.2893 - val_accuracy: 0.4071\n",
            "Epoch 1997/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.0753 - accuracy: 1.0000 - val_loss: 18.2960 - val_accuracy: 0.4071\n",
            "Epoch 1998/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.0755 - accuracy: 1.0000 - val_loss: 18.2987 - val_accuracy: 0.4071\n",
            "Epoch 1999/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.0761 - accuracy: 0.9991 - val_loss: 18.3027 - val_accuracy: 0.4071\n",
            "Epoch 2000/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.0760 - accuracy: 0.9991 - val_loss: 18.3099 - val_accuracy: 0.4071\n",
            "Total accuracy:\n",
            "0.43166666666666664\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x360 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dLz_cDAXqich"
      },
      "source": [
        "### Model 4: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "srRdMd4MnCdY",
        "outputId": "1058067e-cd6a-4524-cdfa-8c31ab74fe67"
      },
      "source": [
        "import keras.models\n",
        "import numpy as np\n",
        "from python_toolbox import random_tools\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "RADIX = 500\n",
        "FEATURE_BITS = 10\n",
        "\n",
        "def _get_number(vector):\n",
        "    return sum(x * 2 ** i for i, x in enumerate(vector))\n",
        "\n",
        "def _get_mod_result(vector):\n",
        "    return _get_number(vector) % RADIX\n",
        "\n",
        "def _number_to_vector(number):\n",
        "    binary_string = bin(number)[2:]\n",
        "    if len(binary_string) > FEATURE_BITS:\n",
        "        raise NotImplementedError\n",
        "    bits = (((0,) * (FEATURE_BITS - len(binary_string))) +\n",
        "            tuple(map(int, binary_string)))[::-1]\n",
        "    assert len(bits) == FEATURE_BITS\n",
        "    return np.c_[bits]\n",
        "\n",
        "\n",
        "def get_mod_result_vector(vector):\n",
        "    v = np.repeat(0, 500)\n",
        "    v[_get_mod_result(vector)] = 1\n",
        "    return v\n",
        "\n",
        "# data generation and splitting into train, validation and test data\n",
        "data = np.random.randint(2, size=(2000, FEATURE_BITS))\n",
        "labels = np.vstack(map(get_mod_result_vector, data))\n",
        "\n",
        "train_inputs, test_inputs, train_labels, test_labels = train_test_split(\n",
        "data, labels, test_size=0.3, random_state=42)\n",
        "\n",
        "train_inputs, valid_inputs, train_labels, valid_labels = train_test_split(\n",
        "train_inputs, train_labels, test_size=0.2, random_state=42)\n",
        "\n",
        "model = keras.models.Sequential([\n",
        "        keras.layers.Dense(10, activation='relu', input_dim=FEATURE_BITS),\n",
        "        keras.layers.Dense(10, activation='relu'),\n",
        "        keras.layers.Dense(10, activation='relu'),\n",
        "        keras.layers.Dense(10, activation='relu'),\n",
        "        keras.layers.Dense(10, activation='relu'),\n",
        "        keras.layers.Dense(500, activation='softmax')\n",
        "])\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "\n",
        "epochs = 2000\n",
        "history = model.fit(train_inputs, train_labels, \n",
        "                    epochs=epochs, batch_size=50, \n",
        "                    verbose = 1,\n",
        "                    validation_data = (valid_inputs, valid_labels))\n",
        "\n",
        "preds = model.predict(test_inputs)\n",
        "test_preds = [np.argmax(preds[i]) for i in range(preds.shape[0])]\n",
        "test_true_labels = [np.argmax(test_labels[i]) for i in range(test_labels.shape[0])]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:33: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2000\n",
            "23/23 [==============================] - 1s 9ms/step - loss: 6.2143 - accuracy: 0.0018 - val_loss: 6.2144 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 6.2042 - accuracy: 0.0045 - val_loss: 6.2119 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 6.1877 - accuracy: 0.0125 - val_loss: 6.2076 - val_accuracy: 0.0000e+00\n",
            "Epoch 4/2000\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 6.1439 - accuracy: 0.0036 - val_loss: 6.2065 - val_accuracy: 0.0036\n",
            "Epoch 5/2000\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 6.0453 - accuracy: 0.0045 - val_loss: 6.2659 - val_accuracy: 0.0036\n",
            "Epoch 6/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 5.9236 - accuracy: 0.0089 - val_loss: 6.3570 - val_accuracy: 0.0000e+00\n",
            "Epoch 7/2000\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 5.8224 - accuracy: 0.0143 - val_loss: 6.4306 - val_accuracy: 0.0036\n",
            "Epoch 8/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 5.7211 - accuracy: 0.0170 - val_loss: 6.4226 - val_accuracy: 0.0000e+00\n",
            "Epoch 9/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 5.6126 - accuracy: 0.0170 - val_loss: 6.4718 - val_accuracy: 0.0000e+00\n",
            "Epoch 10/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 5.4928 - accuracy: 0.0277 - val_loss: 6.4818 - val_accuracy: 0.0107\n",
            "Epoch 11/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 5.3732 - accuracy: 0.0286 - val_loss: 6.5294 - val_accuracy: 0.0107\n",
            "Epoch 12/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 5.2502 - accuracy: 0.0277 - val_loss: 6.6100 - val_accuracy: 0.0143\n",
            "Epoch 13/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 5.1330 - accuracy: 0.0268 - val_loss: 6.6275 - val_accuracy: 0.0071\n",
            "Epoch 14/2000\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 5.0279 - accuracy: 0.0339 - val_loss: 6.6828 - val_accuracy: 0.0179\n",
            "Epoch 15/2000\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 4.9219 - accuracy: 0.0384 - val_loss: 6.7376 - val_accuracy: 0.0214\n",
            "Epoch 16/2000\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 4.8306 - accuracy: 0.0491 - val_loss: 6.7959 - val_accuracy: 0.0250\n",
            "Epoch 17/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 4.7342 - accuracy: 0.0500 - val_loss: 6.8615 - val_accuracy: 0.0214\n",
            "Epoch 18/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 4.6456 - accuracy: 0.0562 - val_loss: 6.9496 - val_accuracy: 0.0214\n",
            "Epoch 19/2000\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 4.5663 - accuracy: 0.0527 - val_loss: 7.0544 - val_accuracy: 0.0250\n",
            "Epoch 20/2000\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 4.4897 - accuracy: 0.0571 - val_loss: 7.1255 - val_accuracy: 0.0143\n",
            "Epoch 21/2000\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 4.4297 - accuracy: 0.0607 - val_loss: 7.2222 - val_accuracy: 0.0286\n",
            "Epoch 22/2000\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 4.3647 - accuracy: 0.0554 - val_loss: 7.3100 - val_accuracy: 0.0286\n",
            "Epoch 23/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 4.3128 - accuracy: 0.0527 - val_loss: 7.3938 - val_accuracy: 0.0321\n",
            "Epoch 24/2000\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 4.2563 - accuracy: 0.0714 - val_loss: 7.4717 - val_accuracy: 0.0286\n",
            "Epoch 25/2000\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 4.2110 - accuracy: 0.0768 - val_loss: 7.5950 - val_accuracy: 0.0250\n",
            "Epoch 26/2000\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 4.1681 - accuracy: 0.0714 - val_loss: 7.7352 - val_accuracy: 0.0393\n",
            "Epoch 27/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 4.1194 - accuracy: 0.0795 - val_loss: 7.7849 - val_accuracy: 0.0464\n",
            "Epoch 28/2000\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 4.0830 - accuracy: 0.0911 - val_loss: 7.9163 - val_accuracy: 0.0393\n",
            "Epoch 29/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 4.0464 - accuracy: 0.0786 - val_loss: 8.0154 - val_accuracy: 0.0393\n",
            "Epoch 30/2000\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 4.0262 - accuracy: 0.0884 - val_loss: 8.1155 - val_accuracy: 0.0464\n",
            "Epoch 31/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 3.9885 - accuracy: 0.0964 - val_loss: 8.1875 - val_accuracy: 0.0464\n",
            "Epoch 32/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 3.9537 - accuracy: 0.0973 - val_loss: 8.2552 - val_accuracy: 0.0393\n",
            "Epoch 33/2000\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 3.9366 - accuracy: 0.0946 - val_loss: 8.3711 - val_accuracy: 0.0571\n",
            "Epoch 34/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 3.9082 - accuracy: 0.1018 - val_loss: 8.4433 - val_accuracy: 0.0393\n",
            "Epoch 35/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 3.8917 - accuracy: 0.0821 - val_loss: 8.5667 - val_accuracy: 0.0536\n",
            "Epoch 36/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 3.8607 - accuracy: 0.1161 - val_loss: 8.6029 - val_accuracy: 0.0536\n",
            "Epoch 37/2000\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 3.8510 - accuracy: 0.1018 - val_loss: 8.6865 - val_accuracy: 0.0464\n",
            "Epoch 38/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 3.8184 - accuracy: 0.1125 - val_loss: 8.8030 - val_accuracy: 0.0536\n",
            "Epoch 39/2000\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 3.8002 - accuracy: 0.1063 - val_loss: 8.7758 - val_accuracy: 0.0500\n",
            "Epoch 40/2000\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 3.7790 - accuracy: 0.1152 - val_loss: 8.9063 - val_accuracy: 0.0393\n",
            "Epoch 41/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 3.7740 - accuracy: 0.1080 - val_loss: 9.0429 - val_accuracy: 0.0607\n",
            "Epoch 42/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 3.7662 - accuracy: 0.1134 - val_loss: 9.1047 - val_accuracy: 0.0464\n",
            "Epoch 43/2000\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 3.7564 - accuracy: 0.1071 - val_loss: 9.0221 - val_accuracy: 0.0429\n",
            "Epoch 44/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 3.7161 - accuracy: 0.1330 - val_loss: 9.1342 - val_accuracy: 0.0679\n",
            "Epoch 45/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 3.7005 - accuracy: 0.1250 - val_loss: 9.2053 - val_accuracy: 0.0643\n",
            "Epoch 46/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 3.6729 - accuracy: 0.1286 - val_loss: 9.2698 - val_accuracy: 0.0607\n",
            "Epoch 47/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 3.6633 - accuracy: 0.1312 - val_loss: 9.3531 - val_accuracy: 0.0571\n",
            "Epoch 48/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 3.6619 - accuracy: 0.1339 - val_loss: 9.3588 - val_accuracy: 0.0571\n",
            "Epoch 49/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 3.6434 - accuracy: 0.1321 - val_loss: 9.3976 - val_accuracy: 0.0679\n",
            "Epoch 50/2000\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 3.6147 - accuracy: 0.1268 - val_loss: 9.5840 - val_accuracy: 0.0714\n",
            "Epoch 51/2000\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 3.6289 - accuracy: 0.1232 - val_loss: 9.5244 - val_accuracy: 0.0750\n",
            "Epoch 52/2000\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 3.6121 - accuracy: 0.1393 - val_loss: 9.6455 - val_accuracy: 0.0679\n",
            "Epoch 53/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 3.5967 - accuracy: 0.1411 - val_loss: 9.6937 - val_accuracy: 0.0821\n",
            "Epoch 54/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 3.5768 - accuracy: 0.1500 - val_loss: 9.7110 - val_accuracy: 0.0786\n",
            "Epoch 55/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 3.5564 - accuracy: 0.1446 - val_loss: 9.8039 - val_accuracy: 0.0679\n",
            "Epoch 56/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 3.5448 - accuracy: 0.1348 - val_loss: 9.8568 - val_accuracy: 0.0643\n",
            "Epoch 57/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 3.5423 - accuracy: 0.1420 - val_loss: 9.9393 - val_accuracy: 0.0750\n",
            "Epoch 58/2000\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 3.5273 - accuracy: 0.1491 - val_loss: 9.9740 - val_accuracy: 0.0643\n",
            "Epoch 59/2000\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 3.5209 - accuracy: 0.1473 - val_loss: 10.0126 - val_accuracy: 0.0750\n",
            "Epoch 60/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 3.5060 - accuracy: 0.1455 - val_loss: 10.0775 - val_accuracy: 0.0929\n",
            "Epoch 61/2000\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 3.4922 - accuracy: 0.1437 - val_loss: 10.1264 - val_accuracy: 0.0750\n",
            "Epoch 62/2000\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 3.4884 - accuracy: 0.1455 - val_loss: 10.1227 - val_accuracy: 0.0643\n",
            "Epoch 63/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 3.4596 - accuracy: 0.1580 - val_loss: 10.2457 - val_accuracy: 0.0714\n",
            "Epoch 64/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 3.4556 - accuracy: 0.1437 - val_loss: 10.3094 - val_accuracy: 0.1000\n",
            "Epoch 65/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 3.4439 - accuracy: 0.1705 - val_loss: 10.4033 - val_accuracy: 0.0857\n",
            "Epoch 66/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 3.4418 - accuracy: 0.1545 - val_loss: 10.3456 - val_accuracy: 0.0786\n",
            "Epoch 67/2000\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 3.4249 - accuracy: 0.1527 - val_loss: 10.4010 - val_accuracy: 0.0857\n",
            "Epoch 68/2000\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 3.4122 - accuracy: 0.1652 - val_loss: 10.4734 - val_accuracy: 0.0821\n",
            "Epoch 69/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 3.4220 - accuracy: 0.1598 - val_loss: 10.4723 - val_accuracy: 0.0964\n",
            "Epoch 70/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 3.3973 - accuracy: 0.1616 - val_loss: 10.5735 - val_accuracy: 0.0893\n",
            "Epoch 71/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 3.3696 - accuracy: 0.1705 - val_loss: 10.5717 - val_accuracy: 0.0929\n",
            "Epoch 72/2000\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 3.3869 - accuracy: 0.1571 - val_loss: 10.6060 - val_accuracy: 0.0964\n",
            "Epoch 73/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 3.3586 - accuracy: 0.1643 - val_loss: 10.6990 - val_accuracy: 0.0893\n",
            "Epoch 74/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 3.3584 - accuracy: 0.1688 - val_loss: 10.7045 - val_accuracy: 0.0679\n",
            "Epoch 75/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 3.3340 - accuracy: 0.1732 - val_loss: 10.7856 - val_accuracy: 0.1071\n",
            "Epoch 76/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 3.3419 - accuracy: 0.1714 - val_loss: 10.8072 - val_accuracy: 0.1000\n",
            "Epoch 77/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 3.3311 - accuracy: 0.1821 - val_loss: 10.9131 - val_accuracy: 0.0857\n",
            "Epoch 78/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 3.3258 - accuracy: 0.1696 - val_loss: 10.9008 - val_accuracy: 0.0929\n",
            "Epoch 79/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 3.3173 - accuracy: 0.1634 - val_loss: 10.9008 - val_accuracy: 0.0893\n",
            "Epoch 80/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 3.3233 - accuracy: 0.1696 - val_loss: 10.9893 - val_accuracy: 0.1214\n",
            "Epoch 81/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 3.2921 - accuracy: 0.1929 - val_loss: 11.1080 - val_accuracy: 0.0929\n",
            "Epoch 82/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 3.2913 - accuracy: 0.1839 - val_loss: 11.0536 - val_accuracy: 0.0964\n",
            "Epoch 83/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 3.2852 - accuracy: 0.1741 - val_loss: 11.1123 - val_accuracy: 0.1036\n",
            "Epoch 84/2000\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 3.2876 - accuracy: 0.1723 - val_loss: 11.1560 - val_accuracy: 0.1071\n",
            "Epoch 85/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 3.2651 - accuracy: 0.1884 - val_loss: 11.2073 - val_accuracy: 0.0964\n",
            "Epoch 86/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 3.2686 - accuracy: 0.1839 - val_loss: 11.1386 - val_accuracy: 0.1250\n",
            "Epoch 87/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 3.2443 - accuracy: 0.1750 - val_loss: 11.2226 - val_accuracy: 0.1107\n",
            "Epoch 88/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 3.2377 - accuracy: 0.2018 - val_loss: 11.2752 - val_accuracy: 0.1036\n",
            "Epoch 89/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 3.2245 - accuracy: 0.1964 - val_loss: 11.3721 - val_accuracy: 0.1143\n",
            "Epoch 90/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 3.2240 - accuracy: 0.1866 - val_loss: 11.3602 - val_accuracy: 0.1036\n",
            "Epoch 91/2000\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 3.2077 - accuracy: 0.1750 - val_loss: 11.3978 - val_accuracy: 0.1179\n",
            "Epoch 92/2000\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 3.1984 - accuracy: 0.1911 - val_loss: 11.5018 - val_accuracy: 0.0821\n",
            "Epoch 93/2000\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 3.2161 - accuracy: 0.1813 - val_loss: 11.5085 - val_accuracy: 0.0857\n",
            "Epoch 94/2000\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 3.1993 - accuracy: 0.1795 - val_loss: 11.5060 - val_accuracy: 0.0964\n",
            "Epoch 95/2000\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 3.1786 - accuracy: 0.2009 - val_loss: 11.5358 - val_accuracy: 0.1250\n",
            "Epoch 96/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 3.1920 - accuracy: 0.1937 - val_loss: 11.5493 - val_accuracy: 0.1179\n",
            "Epoch 97/2000\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 3.1765 - accuracy: 0.2009 - val_loss: 11.6718 - val_accuracy: 0.1179\n",
            "Epoch 98/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 3.1809 - accuracy: 0.1786 - val_loss: 11.6617 - val_accuracy: 0.1071\n",
            "Epoch 99/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 3.1767 - accuracy: 0.2027 - val_loss: 11.6967 - val_accuracy: 0.0786\n",
            "Epoch 100/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 3.1672 - accuracy: 0.1884 - val_loss: 11.7102 - val_accuracy: 0.1143\n",
            "Epoch 101/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 3.1675 - accuracy: 0.1786 - val_loss: 11.7332 - val_accuracy: 0.1214\n",
            "Epoch 102/2000\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 3.1415 - accuracy: 0.1991 - val_loss: 11.7197 - val_accuracy: 0.0964\n",
            "Epoch 103/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 3.1419 - accuracy: 0.1937 - val_loss: 11.7488 - val_accuracy: 0.1107\n",
            "Epoch 104/2000\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 3.1239 - accuracy: 0.2125 - val_loss: 11.8912 - val_accuracy: 0.1286\n",
            "Epoch 105/2000\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 3.1162 - accuracy: 0.2214 - val_loss: 11.9113 - val_accuracy: 0.1107\n",
            "Epoch 106/2000\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 3.1124 - accuracy: 0.1902 - val_loss: 11.8562 - val_accuracy: 0.1286\n",
            "Epoch 107/2000\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 3.1213 - accuracy: 0.1946 - val_loss: 11.9204 - val_accuracy: 0.1107\n",
            "Epoch 108/2000\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 3.1109 - accuracy: 0.2161 - val_loss: 11.9510 - val_accuracy: 0.1286\n",
            "Epoch 109/2000\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 3.0888 - accuracy: 0.2071 - val_loss: 11.9549 - val_accuracy: 0.1214\n",
            "Epoch 110/2000\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 3.0889 - accuracy: 0.2071 - val_loss: 12.0880 - val_accuracy: 0.1286\n",
            "Epoch 111/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 3.0930 - accuracy: 0.2152 - val_loss: 12.0039 - val_accuracy: 0.1250\n",
            "Epoch 112/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 3.0840 - accuracy: 0.2107 - val_loss: 12.1490 - val_accuracy: 0.1107\n",
            "Epoch 113/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 3.0772 - accuracy: 0.2080 - val_loss: 12.0675 - val_accuracy: 0.1393\n",
            "Epoch 114/2000\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 3.0749 - accuracy: 0.2179 - val_loss: 12.1795 - val_accuracy: 0.1143\n",
            "Epoch 115/2000\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 3.0673 - accuracy: 0.2205 - val_loss: 12.2003 - val_accuracy: 0.1607\n",
            "Epoch 116/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 3.0608 - accuracy: 0.2250 - val_loss: 12.2796 - val_accuracy: 0.1036\n",
            "Epoch 117/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 3.0584 - accuracy: 0.2107 - val_loss: 12.2178 - val_accuracy: 0.1393\n",
            "Epoch 118/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 3.0401 - accuracy: 0.1991 - val_loss: 12.2388 - val_accuracy: 0.1393\n",
            "Epoch 119/2000\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 3.0321 - accuracy: 0.2357 - val_loss: 12.2864 - val_accuracy: 0.1464\n",
            "Epoch 120/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 3.0404 - accuracy: 0.2062 - val_loss: 12.4211 - val_accuracy: 0.1214\n",
            "Epoch 121/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 3.0324 - accuracy: 0.2196 - val_loss: 12.3422 - val_accuracy: 0.1357\n",
            "Epoch 122/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 3.0272 - accuracy: 0.2152 - val_loss: 12.3116 - val_accuracy: 0.1286\n",
            "Epoch 123/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 3.0064 - accuracy: 0.2054 - val_loss: 12.5025 - val_accuracy: 0.1286\n",
            "Epoch 124/2000\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 3.0146 - accuracy: 0.2232 - val_loss: 12.3771 - val_accuracy: 0.1571\n",
            "Epoch 125/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 3.0027 - accuracy: 0.2062 - val_loss: 12.4215 - val_accuracy: 0.1500\n",
            "Epoch 126/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 2.9946 - accuracy: 0.2241 - val_loss: 12.4729 - val_accuracy: 0.1357\n",
            "Epoch 127/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 2.9845 - accuracy: 0.2339 - val_loss: 12.5681 - val_accuracy: 0.1179\n",
            "Epoch 128/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 2.9877 - accuracy: 0.2161 - val_loss: 12.6183 - val_accuracy: 0.1393\n",
            "Epoch 129/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 2.9815 - accuracy: 0.2366 - val_loss: 12.5584 - val_accuracy: 0.1357\n",
            "Epoch 130/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 2.9739 - accuracy: 0.2214 - val_loss: 12.6354 - val_accuracy: 0.1214\n",
            "Epoch 131/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 2.9691 - accuracy: 0.2250 - val_loss: 12.6703 - val_accuracy: 0.1429\n",
            "Epoch 132/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 2.9599 - accuracy: 0.2446 - val_loss: 12.6945 - val_accuracy: 0.1179\n",
            "Epoch 133/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 2.9740 - accuracy: 0.2384 - val_loss: 12.7148 - val_accuracy: 0.1464\n",
            "Epoch 134/2000\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 2.9560 - accuracy: 0.2357 - val_loss: 12.7396 - val_accuracy: 0.1500\n",
            "Epoch 135/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 2.9372 - accuracy: 0.2446 - val_loss: 12.8020 - val_accuracy: 0.1143\n",
            "Epoch 136/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 2.9367 - accuracy: 0.2250 - val_loss: 12.7698 - val_accuracy: 0.1536\n",
            "Epoch 137/2000\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 2.9343 - accuracy: 0.2313 - val_loss: 12.8541 - val_accuracy: 0.1571\n",
            "Epoch 138/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 2.9417 - accuracy: 0.2259 - val_loss: 12.8979 - val_accuracy: 0.1357\n",
            "Epoch 139/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 2.9347 - accuracy: 0.2321 - val_loss: 12.9806 - val_accuracy: 0.1464\n",
            "Epoch 140/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 2.9220 - accuracy: 0.2339 - val_loss: 12.9507 - val_accuracy: 0.1143\n",
            "Epoch 141/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 2.9306 - accuracy: 0.2330 - val_loss: 12.9873 - val_accuracy: 0.1393\n",
            "Epoch 142/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 2.9305 - accuracy: 0.2313 - val_loss: 12.9853 - val_accuracy: 0.1321\n",
            "Epoch 143/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 2.9260 - accuracy: 0.2313 - val_loss: 13.0298 - val_accuracy: 0.1429\n",
            "Epoch 144/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 2.9266 - accuracy: 0.2348 - val_loss: 12.9746 - val_accuracy: 0.1393\n",
            "Epoch 145/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 2.8802 - accuracy: 0.2589 - val_loss: 13.0854 - val_accuracy: 0.1571\n",
            "Epoch 146/2000\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 2.8867 - accuracy: 0.2402 - val_loss: 13.0895 - val_accuracy: 0.1429\n",
            "Epoch 147/2000\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 2.8749 - accuracy: 0.2429 - val_loss: 13.1919 - val_accuracy: 0.1643\n",
            "Epoch 148/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 2.8718 - accuracy: 0.2420 - val_loss: 13.0637 - val_accuracy: 0.1536\n",
            "Epoch 149/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 2.8799 - accuracy: 0.2571 - val_loss: 13.2531 - val_accuracy: 0.1357\n",
            "Epoch 150/2000\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 2.8804 - accuracy: 0.2384 - val_loss: 13.1810 - val_accuracy: 0.1643\n",
            "Epoch 151/2000\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 2.8812 - accuracy: 0.2384 - val_loss: 13.2037 - val_accuracy: 0.1607\n",
            "Epoch 152/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 2.8767 - accuracy: 0.2393 - val_loss: 13.3368 - val_accuracy: 0.1536\n",
            "Epoch 153/2000\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 2.8632 - accuracy: 0.2420 - val_loss: 13.2813 - val_accuracy: 0.1750\n",
            "Epoch 154/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 2.8448 - accuracy: 0.2518 - val_loss: 13.2837 - val_accuracy: 0.1464\n",
            "Epoch 155/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 2.8432 - accuracy: 0.2616 - val_loss: 13.3391 - val_accuracy: 0.1821\n",
            "Epoch 156/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 2.8385 - accuracy: 0.2554 - val_loss: 13.3423 - val_accuracy: 0.1607\n",
            "Epoch 157/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 2.8403 - accuracy: 0.2696 - val_loss: 13.3930 - val_accuracy: 0.1893\n",
            "Epoch 158/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 2.8184 - accuracy: 0.2714 - val_loss: 13.3596 - val_accuracy: 0.1607\n",
            "Epoch 159/2000\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 2.8625 - accuracy: 0.2304 - val_loss: 13.5308 - val_accuracy: 0.1464\n",
            "Epoch 160/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 2.8397 - accuracy: 0.2679 - val_loss: 13.5876 - val_accuracy: 0.1393\n",
            "Epoch 161/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 2.8254 - accuracy: 0.2652 - val_loss: 13.4589 - val_accuracy: 0.1464\n",
            "Epoch 162/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 2.8020 - accuracy: 0.2670 - val_loss: 13.5404 - val_accuracy: 0.1536\n",
            "Epoch 163/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 2.8222 - accuracy: 0.2679 - val_loss: 13.5214 - val_accuracy: 0.1643\n",
            "Epoch 164/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 2.7975 - accuracy: 0.2589 - val_loss: 13.5845 - val_accuracy: 0.1393\n",
            "Epoch 165/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 2.7957 - accuracy: 0.2536 - val_loss: 13.6522 - val_accuracy: 0.1643\n",
            "Epoch 166/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 2.7880 - accuracy: 0.2661 - val_loss: 13.5563 - val_accuracy: 0.1786\n",
            "Epoch 167/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 2.7831 - accuracy: 0.2670 - val_loss: 13.6445 - val_accuracy: 0.1429\n",
            "Epoch 168/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 2.7788 - accuracy: 0.2643 - val_loss: 13.7034 - val_accuracy: 0.1643\n",
            "Epoch 169/2000\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 2.7975 - accuracy: 0.2643 - val_loss: 13.6953 - val_accuracy: 0.1643\n",
            "Epoch 170/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 2.7718 - accuracy: 0.2714 - val_loss: 13.7015 - val_accuracy: 0.1750\n",
            "Epoch 171/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 2.7669 - accuracy: 0.2750 - val_loss: 13.7751 - val_accuracy: 0.1786\n",
            "Epoch 172/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 2.7576 - accuracy: 0.2812 - val_loss: 13.7357 - val_accuracy: 0.1821\n",
            "Epoch 173/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 2.7747 - accuracy: 0.2580 - val_loss: 13.8306 - val_accuracy: 0.1964\n",
            "Epoch 174/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 2.7631 - accuracy: 0.2723 - val_loss: 13.8582 - val_accuracy: 0.2000\n",
            "Epoch 175/2000\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 2.7637 - accuracy: 0.2705 - val_loss: 13.9007 - val_accuracy: 0.1464\n",
            "Epoch 176/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 2.7415 - accuracy: 0.2750 - val_loss: 13.8943 - val_accuracy: 0.1857\n",
            "Epoch 177/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 2.7299 - accuracy: 0.2750 - val_loss: 13.9147 - val_accuracy: 0.2036\n",
            "Epoch 178/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 2.7402 - accuracy: 0.2786 - val_loss: 13.9595 - val_accuracy: 0.1464\n",
            "Epoch 179/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 2.7281 - accuracy: 0.2634 - val_loss: 13.9684 - val_accuracy: 0.2000\n",
            "Epoch 180/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 2.7212 - accuracy: 0.2821 - val_loss: 14.0551 - val_accuracy: 0.1750\n",
            "Epoch 181/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 2.7258 - accuracy: 0.2812 - val_loss: 14.0546 - val_accuracy: 0.1821\n",
            "Epoch 182/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 2.7176 - accuracy: 0.2839 - val_loss: 14.0976 - val_accuracy: 0.1929\n",
            "Epoch 183/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 2.7263 - accuracy: 0.2848 - val_loss: 14.1582 - val_accuracy: 0.1821\n",
            "Epoch 184/2000\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 2.7205 - accuracy: 0.2875 - val_loss: 14.1313 - val_accuracy: 0.1893\n",
            "Epoch 185/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 2.7133 - accuracy: 0.2893 - val_loss: 14.1977 - val_accuracy: 0.1786\n",
            "Epoch 186/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 2.6990 - accuracy: 0.2946 - val_loss: 14.2182 - val_accuracy: 0.1821\n",
            "Epoch 187/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 2.7073 - accuracy: 0.2937 - val_loss: 14.1753 - val_accuracy: 0.1929\n",
            "Epoch 188/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 2.6780 - accuracy: 0.2884 - val_loss: 14.2257 - val_accuracy: 0.1679\n",
            "Epoch 189/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 2.6748 - accuracy: 0.3125 - val_loss: 14.2628 - val_accuracy: 0.2000\n",
            "Epoch 190/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 2.7008 - accuracy: 0.2804 - val_loss: 14.3112 - val_accuracy: 0.1929\n",
            "Epoch 191/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 2.6780 - accuracy: 0.2946 - val_loss: 14.3797 - val_accuracy: 0.1750\n",
            "Epoch 192/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 2.6741 - accuracy: 0.3143 - val_loss: 14.4321 - val_accuracy: 0.1786\n",
            "Epoch 193/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 2.6698 - accuracy: 0.2795 - val_loss: 14.4638 - val_accuracy: 0.1821\n",
            "Epoch 194/2000\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 2.6837 - accuracy: 0.2937 - val_loss: 14.3617 - val_accuracy: 0.2107\n",
            "Epoch 195/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 2.6636 - accuracy: 0.3009 - val_loss: 14.4866 - val_accuracy: 0.1714\n",
            "Epoch 196/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 2.6652 - accuracy: 0.3036 - val_loss: 14.4464 - val_accuracy: 0.1929\n",
            "Epoch 197/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 2.6644 - accuracy: 0.2839 - val_loss: 14.4432 - val_accuracy: 0.1857\n",
            "Epoch 198/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 2.6416 - accuracy: 0.2982 - val_loss: 14.4681 - val_accuracy: 0.1964\n",
            "Epoch 199/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 2.6479 - accuracy: 0.3009 - val_loss: 14.5456 - val_accuracy: 0.1750\n",
            "Epoch 200/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 2.6652 - accuracy: 0.2902 - val_loss: 14.5122 - val_accuracy: 0.2000\n",
            "Epoch 201/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 2.6400 - accuracy: 0.2991 - val_loss: 14.5492 - val_accuracy: 0.1857\n",
            "Epoch 202/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 2.6401 - accuracy: 0.2946 - val_loss: 14.5686 - val_accuracy: 0.2071\n",
            "Epoch 203/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 2.6174 - accuracy: 0.3170 - val_loss: 14.7679 - val_accuracy: 0.1750\n",
            "Epoch 204/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 2.6383 - accuracy: 0.2955 - val_loss: 14.6610 - val_accuracy: 0.2071\n",
            "Epoch 205/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 2.6351 - accuracy: 0.3054 - val_loss: 14.6897 - val_accuracy: 0.2000\n",
            "Epoch 206/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 2.6217 - accuracy: 0.2964 - val_loss: 14.6937 - val_accuracy: 0.1893\n",
            "Epoch 207/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 2.6164 - accuracy: 0.3170 - val_loss: 14.7033 - val_accuracy: 0.2250\n",
            "Epoch 208/2000\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 2.6129 - accuracy: 0.2911 - val_loss: 14.7368 - val_accuracy: 0.2071\n",
            "Epoch 209/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 2.5829 - accuracy: 0.3143 - val_loss: 14.8223 - val_accuracy: 0.2107\n",
            "Epoch 210/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 2.6038 - accuracy: 0.2982 - val_loss: 14.7993 - val_accuracy: 0.1750\n",
            "Epoch 211/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 2.6083 - accuracy: 0.3000 - val_loss: 14.8903 - val_accuracy: 0.2143\n",
            "Epoch 212/2000\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 2.6129 - accuracy: 0.3241 - val_loss: 14.8127 - val_accuracy: 0.1893\n",
            "Epoch 213/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 2.5917 - accuracy: 0.3125 - val_loss: 14.8153 - val_accuracy: 0.1929\n",
            "Epoch 214/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 2.5638 - accuracy: 0.3089 - val_loss: 14.9468 - val_accuracy: 0.2071\n",
            "Epoch 215/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 2.5803 - accuracy: 0.3187 - val_loss: 14.9313 - val_accuracy: 0.1964\n",
            "Epoch 216/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 2.5972 - accuracy: 0.3080 - val_loss: 14.8261 - val_accuracy: 0.1750\n",
            "Epoch 217/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 2.5974 - accuracy: 0.3187 - val_loss: 14.9205 - val_accuracy: 0.2107\n",
            "Epoch 218/2000\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 2.5795 - accuracy: 0.3089 - val_loss: 15.0761 - val_accuracy: 0.1857\n",
            "Epoch 219/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 2.5806 - accuracy: 0.3027 - val_loss: 15.0626 - val_accuracy: 0.2071\n",
            "Epoch 220/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 2.5636 - accuracy: 0.3205 - val_loss: 14.9879 - val_accuracy: 0.2214\n",
            "Epoch 221/2000\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 2.5743 - accuracy: 0.3125 - val_loss: 15.0129 - val_accuracy: 0.2036\n",
            "Epoch 222/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 2.5531 - accuracy: 0.2964 - val_loss: 15.0374 - val_accuracy: 0.1929\n",
            "Epoch 223/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 2.5400 - accuracy: 0.3366 - val_loss: 15.0920 - val_accuracy: 0.1893\n",
            "Epoch 224/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 2.5401 - accuracy: 0.3232 - val_loss: 15.1146 - val_accuracy: 0.2000\n",
            "Epoch 225/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 2.5621 - accuracy: 0.3205 - val_loss: 15.1472 - val_accuracy: 0.2143\n",
            "Epoch 226/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 2.5417 - accuracy: 0.3214 - val_loss: 15.0983 - val_accuracy: 0.2000\n",
            "Epoch 227/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 2.5337 - accuracy: 0.3330 - val_loss: 15.1103 - val_accuracy: 0.2286\n",
            "Epoch 228/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 2.5175 - accuracy: 0.3330 - val_loss: 15.1678 - val_accuracy: 0.2143\n",
            "Epoch 229/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 2.5042 - accuracy: 0.3330 - val_loss: 15.2188 - val_accuracy: 0.2250\n",
            "Epoch 230/2000\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 2.5183 - accuracy: 0.3339 - val_loss: 15.2110 - val_accuracy: 0.2000\n",
            "Epoch 231/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 2.5139 - accuracy: 0.3304 - val_loss: 15.2568 - val_accuracy: 0.2214\n",
            "Epoch 232/2000\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 2.5053 - accuracy: 0.3366 - val_loss: 15.2841 - val_accuracy: 0.2357\n",
            "Epoch 233/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 2.5124 - accuracy: 0.3161 - val_loss: 15.3667 - val_accuracy: 0.1964\n",
            "Epoch 234/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 2.4934 - accuracy: 0.3473 - val_loss: 15.3568 - val_accuracy: 0.2214\n",
            "Epoch 235/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 2.5021 - accuracy: 0.3161 - val_loss: 15.4347 - val_accuracy: 0.2143\n",
            "Epoch 236/2000\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 2.5030 - accuracy: 0.3384 - val_loss: 15.3579 - val_accuracy: 0.2250\n",
            "Epoch 237/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 2.4992 - accuracy: 0.3446 - val_loss: 15.4083 - val_accuracy: 0.2429\n",
            "Epoch 238/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 2.4781 - accuracy: 0.3509 - val_loss: 15.3775 - val_accuracy: 0.2286\n",
            "Epoch 239/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 2.4913 - accuracy: 0.3348 - val_loss: 15.4782 - val_accuracy: 0.2250\n",
            "Epoch 240/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 2.4686 - accuracy: 0.3571 - val_loss: 15.4804 - val_accuracy: 0.2107\n",
            "Epoch 241/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 2.4868 - accuracy: 0.3438 - val_loss: 15.5170 - val_accuracy: 0.1893\n",
            "Epoch 242/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 2.4484 - accuracy: 0.3446 - val_loss: 15.5675 - val_accuracy: 0.2179\n",
            "Epoch 243/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 2.4649 - accuracy: 0.3438 - val_loss: 15.5834 - val_accuracy: 0.1929\n",
            "Epoch 244/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 2.4886 - accuracy: 0.3536 - val_loss: 15.5891 - val_accuracy: 0.2214\n",
            "Epoch 245/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 2.4784 - accuracy: 0.3339 - val_loss: 15.5492 - val_accuracy: 0.2071\n",
            "Epoch 246/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 2.4546 - accuracy: 0.3366 - val_loss: 15.5587 - val_accuracy: 0.2429\n",
            "Epoch 247/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 2.4537 - accuracy: 0.3420 - val_loss: 15.7343 - val_accuracy: 0.1929\n",
            "Epoch 248/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 2.4593 - accuracy: 0.3455 - val_loss: 15.7590 - val_accuracy: 0.2143\n",
            "Epoch 249/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 2.4416 - accuracy: 0.3473 - val_loss: 15.7814 - val_accuracy: 0.2250\n",
            "Epoch 250/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 2.4574 - accuracy: 0.3473 - val_loss: 15.7876 - val_accuracy: 0.2429\n",
            "Epoch 251/2000\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 2.4474 - accuracy: 0.3607 - val_loss: 15.7405 - val_accuracy: 0.2071\n",
            "Epoch 252/2000\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 2.4225 - accuracy: 0.3348 - val_loss: 15.8008 - val_accuracy: 0.2321\n",
            "Epoch 253/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 2.4369 - accuracy: 0.3491 - val_loss: 15.8045 - val_accuracy: 0.2321\n",
            "Epoch 254/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 2.4260 - accuracy: 0.3491 - val_loss: 15.8539 - val_accuracy: 0.2250\n",
            "Epoch 255/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 2.4440 - accuracy: 0.3357 - val_loss: 15.9214 - val_accuracy: 0.2393\n",
            "Epoch 256/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 2.4365 - accuracy: 0.3607 - val_loss: 15.8155 - val_accuracy: 0.2250\n",
            "Epoch 257/2000\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 2.4186 - accuracy: 0.3482 - val_loss: 15.8394 - val_accuracy: 0.2250\n",
            "Epoch 258/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 2.3952 - accuracy: 0.3705 - val_loss: 15.8827 - val_accuracy: 0.2286\n",
            "Epoch 259/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 2.4025 - accuracy: 0.3571 - val_loss: 15.8891 - val_accuracy: 0.2393\n",
            "Epoch 260/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 2.4120 - accuracy: 0.3518 - val_loss: 15.9396 - val_accuracy: 0.2179\n",
            "Epoch 261/2000\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 2.4101 - accuracy: 0.3625 - val_loss: 15.9478 - val_accuracy: 0.2286\n",
            "Epoch 262/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 2.4186 - accuracy: 0.3393 - val_loss: 16.0332 - val_accuracy: 0.2071\n",
            "Epoch 263/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 2.4137 - accuracy: 0.3464 - val_loss: 15.9858 - val_accuracy: 0.2214\n",
            "Epoch 264/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 2.4109 - accuracy: 0.3723 - val_loss: 16.0177 - val_accuracy: 0.2321\n",
            "Epoch 265/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 2.4140 - accuracy: 0.3518 - val_loss: 16.0074 - val_accuracy: 0.2214\n",
            "Epoch 266/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 2.3942 - accuracy: 0.3607 - val_loss: 16.0440 - val_accuracy: 0.2286\n",
            "Epoch 267/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 2.3878 - accuracy: 0.3679 - val_loss: 16.0057 - val_accuracy: 0.2286\n",
            "Epoch 268/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 2.3711 - accuracy: 0.3705 - val_loss: 16.0437 - val_accuracy: 0.2214\n",
            "Epoch 269/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 2.3704 - accuracy: 0.3696 - val_loss: 16.1063 - val_accuracy: 0.2464\n",
            "Epoch 270/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 2.3848 - accuracy: 0.3473 - val_loss: 16.1471 - val_accuracy: 0.2321\n",
            "Epoch 271/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 2.3776 - accuracy: 0.3723 - val_loss: 16.1770 - val_accuracy: 0.2286\n",
            "Epoch 272/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 2.3658 - accuracy: 0.3732 - val_loss: 16.0511 - val_accuracy: 0.2250\n",
            "Epoch 273/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 2.3427 - accuracy: 0.3777 - val_loss: 16.2071 - val_accuracy: 0.2571\n",
            "Epoch 274/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 2.3609 - accuracy: 0.3857 - val_loss: 16.1833 - val_accuracy: 0.2179\n",
            "Epoch 275/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 2.3531 - accuracy: 0.3634 - val_loss: 16.1370 - val_accuracy: 0.2286\n",
            "Epoch 276/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 2.3534 - accuracy: 0.3812 - val_loss: 16.2044 - val_accuracy: 0.2214\n",
            "Epoch 277/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 2.3403 - accuracy: 0.3696 - val_loss: 16.2574 - val_accuracy: 0.2643\n",
            "Epoch 278/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 2.3291 - accuracy: 0.3848 - val_loss: 16.3639 - val_accuracy: 0.2429\n",
            "Epoch 279/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 2.3242 - accuracy: 0.3875 - val_loss: 16.3389 - val_accuracy: 0.2393\n",
            "Epoch 280/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 2.3230 - accuracy: 0.3839 - val_loss: 16.2819 - val_accuracy: 0.2000\n",
            "Epoch 281/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 2.3276 - accuracy: 0.3866 - val_loss: 16.3649 - val_accuracy: 0.2464\n",
            "Epoch 282/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 2.3148 - accuracy: 0.3804 - val_loss: 16.4031 - val_accuracy: 0.2429\n",
            "Epoch 283/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 2.3180 - accuracy: 0.3866 - val_loss: 16.4353 - val_accuracy: 0.2500\n",
            "Epoch 284/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 2.2879 - accuracy: 0.4071 - val_loss: 16.4443 - val_accuracy: 0.2536\n",
            "Epoch 285/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 2.3159 - accuracy: 0.3929 - val_loss: 16.4993 - val_accuracy: 0.2679\n",
            "Epoch 286/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 2.3206 - accuracy: 0.3804 - val_loss: 16.4190 - val_accuracy: 0.2429\n",
            "Epoch 287/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 2.2982 - accuracy: 0.3920 - val_loss: 16.5914 - val_accuracy: 0.2321\n",
            "Epoch 288/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 2.2965 - accuracy: 0.4009 - val_loss: 16.5885 - val_accuracy: 0.2500\n",
            "Epoch 289/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 2.2975 - accuracy: 0.3866 - val_loss: 16.4869 - val_accuracy: 0.2321\n",
            "Epoch 290/2000\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 2.2825 - accuracy: 0.4000 - val_loss: 16.5731 - val_accuracy: 0.2357\n",
            "Epoch 291/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 2.2827 - accuracy: 0.4018 - val_loss: 16.5511 - val_accuracy: 0.2607\n",
            "Epoch 292/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 2.2749 - accuracy: 0.3848 - val_loss: 16.6957 - val_accuracy: 0.2643\n",
            "Epoch 293/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 2.2945 - accuracy: 0.3884 - val_loss: 16.6289 - val_accuracy: 0.2286\n",
            "Epoch 294/2000\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 2.2848 - accuracy: 0.4036 - val_loss: 16.5818 - val_accuracy: 0.2571\n",
            "Epoch 295/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 2.2724 - accuracy: 0.3839 - val_loss: 16.6373 - val_accuracy: 0.2607\n",
            "Epoch 296/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 2.2778 - accuracy: 0.3857 - val_loss: 16.7060 - val_accuracy: 0.2393\n",
            "Epoch 297/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 2.2700 - accuracy: 0.3920 - val_loss: 16.6898 - val_accuracy: 0.2571\n",
            "Epoch 298/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 2.2714 - accuracy: 0.3839 - val_loss: 16.6799 - val_accuracy: 0.2321\n",
            "Epoch 299/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 2.2525 - accuracy: 0.4080 - val_loss: 16.7847 - val_accuracy: 0.2286\n",
            "Epoch 300/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 2.2593 - accuracy: 0.3982 - val_loss: 16.7631 - val_accuracy: 0.2786\n",
            "Epoch 301/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 2.2436 - accuracy: 0.4116 - val_loss: 16.8412 - val_accuracy: 0.2250\n",
            "Epoch 302/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 2.2513 - accuracy: 0.3955 - val_loss: 16.7462 - val_accuracy: 0.2393\n",
            "Epoch 303/2000\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 2.2545 - accuracy: 0.3902 - val_loss: 16.8458 - val_accuracy: 0.2607\n",
            "Epoch 304/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 2.2466 - accuracy: 0.3920 - val_loss: 16.7457 - val_accuracy: 0.2536\n",
            "Epoch 305/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 2.2216 - accuracy: 0.3955 - val_loss: 16.8395 - val_accuracy: 0.2929\n",
            "Epoch 306/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 2.2311 - accuracy: 0.3973 - val_loss: 16.8527 - val_accuracy: 0.2607\n",
            "Epoch 307/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 2.2577 - accuracy: 0.3732 - val_loss: 16.8195 - val_accuracy: 0.2750\n",
            "Epoch 308/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 2.2250 - accuracy: 0.4054 - val_loss: 16.9474 - val_accuracy: 0.2964\n",
            "Epoch 309/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 2.2254 - accuracy: 0.3902 - val_loss: 16.9190 - val_accuracy: 0.2429\n",
            "Epoch 310/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 2.1914 - accuracy: 0.4339 - val_loss: 16.9123 - val_accuracy: 0.2929\n",
            "Epoch 311/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 2.2113 - accuracy: 0.4089 - val_loss: 17.0416 - val_accuracy: 0.2571\n",
            "Epoch 312/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 2.2293 - accuracy: 0.4143 - val_loss: 16.9919 - val_accuracy: 0.2643\n",
            "Epoch 313/2000\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 2.2006 - accuracy: 0.4223 - val_loss: 16.9985 - val_accuracy: 0.2429\n",
            "Epoch 314/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 2.1984 - accuracy: 0.4277 - val_loss: 17.0842 - val_accuracy: 0.2536\n",
            "Epoch 315/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 2.1907 - accuracy: 0.4071 - val_loss: 17.1035 - val_accuracy: 0.2607\n",
            "Epoch 316/2000\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 2.1812 - accuracy: 0.4375 - val_loss: 17.0609 - val_accuracy: 0.2536\n",
            "Epoch 317/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 2.1890 - accuracy: 0.4027 - val_loss: 17.1464 - val_accuracy: 0.2821\n",
            "Epoch 318/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 2.1924 - accuracy: 0.4116 - val_loss: 17.0915 - val_accuracy: 0.2821\n",
            "Epoch 319/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 2.1911 - accuracy: 0.4205 - val_loss: 17.1200 - val_accuracy: 0.2857\n",
            "Epoch 320/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 2.1966 - accuracy: 0.4277 - val_loss: 17.2131 - val_accuracy: 0.2893\n",
            "Epoch 321/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 2.1776 - accuracy: 0.4179 - val_loss: 17.1091 - val_accuracy: 0.2964\n",
            "Epoch 322/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 2.1658 - accuracy: 0.4357 - val_loss: 17.2733 - val_accuracy: 0.2750\n",
            "Epoch 323/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 2.1567 - accuracy: 0.4473 - val_loss: 17.2003 - val_accuracy: 0.3000\n",
            "Epoch 324/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 2.1679 - accuracy: 0.4187 - val_loss: 17.1996 - val_accuracy: 0.2464\n",
            "Epoch 325/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 2.1781 - accuracy: 0.4313 - val_loss: 17.1948 - val_accuracy: 0.2679\n",
            "Epoch 326/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 2.1592 - accuracy: 0.4268 - val_loss: 17.1836 - val_accuracy: 0.2464\n",
            "Epoch 327/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 2.1660 - accuracy: 0.4277 - val_loss: 17.1889 - val_accuracy: 0.3286\n",
            "Epoch 328/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 2.1394 - accuracy: 0.4509 - val_loss: 17.3064 - val_accuracy: 0.2964\n",
            "Epoch 329/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 2.1338 - accuracy: 0.4366 - val_loss: 17.4521 - val_accuracy: 0.3036\n",
            "Epoch 330/2000\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 2.1645 - accuracy: 0.4268 - val_loss: 17.4444 - val_accuracy: 0.2714\n",
            "Epoch 331/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 2.1451 - accuracy: 0.4232 - val_loss: 17.2968 - val_accuracy: 0.2500\n",
            "Epoch 332/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 2.1496 - accuracy: 0.4223 - val_loss: 17.3620 - val_accuracy: 0.2857\n",
            "Epoch 333/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 2.1216 - accuracy: 0.4500 - val_loss: 17.3547 - val_accuracy: 0.2786\n",
            "Epoch 334/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 2.1227 - accuracy: 0.4250 - val_loss: 17.2905 - val_accuracy: 0.3143\n",
            "Epoch 335/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 2.1131 - accuracy: 0.4330 - val_loss: 17.3871 - val_accuracy: 0.2786\n",
            "Epoch 336/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 2.1166 - accuracy: 0.4259 - val_loss: 17.3496 - val_accuracy: 0.3036\n",
            "Epoch 337/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 2.1364 - accuracy: 0.4179 - val_loss: 17.4053 - val_accuracy: 0.2893\n",
            "Epoch 338/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 2.0980 - accuracy: 0.4482 - val_loss: 17.3165 - val_accuracy: 0.3000\n",
            "Epoch 339/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 2.1020 - accuracy: 0.4455 - val_loss: 17.3860 - val_accuracy: 0.3000\n",
            "Epoch 340/2000\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 2.1030 - accuracy: 0.4616 - val_loss: 17.5366 - val_accuracy: 0.2964\n",
            "Epoch 341/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 2.1203 - accuracy: 0.4214 - val_loss: 17.3762 - val_accuracy: 0.2607\n",
            "Epoch 342/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 2.1042 - accuracy: 0.4563 - val_loss: 17.5378 - val_accuracy: 0.2857\n",
            "Epoch 343/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 2.1039 - accuracy: 0.4464 - val_loss: 17.6114 - val_accuracy: 0.2821\n",
            "Epoch 344/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 2.1097 - accuracy: 0.4500 - val_loss: 17.4838 - val_accuracy: 0.2893\n",
            "Epoch 345/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 2.0889 - accuracy: 0.4366 - val_loss: 17.4369 - val_accuracy: 0.3036\n",
            "Epoch 346/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 2.0719 - accuracy: 0.4571 - val_loss: 17.5038 - val_accuracy: 0.2786\n",
            "Epoch 347/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 2.0742 - accuracy: 0.4625 - val_loss: 17.5721 - val_accuracy: 0.3036\n",
            "Epoch 348/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 2.0564 - accuracy: 0.4473 - val_loss: 17.5472 - val_accuracy: 0.3071\n",
            "Epoch 349/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 2.0561 - accuracy: 0.4500 - val_loss: 17.5322 - val_accuracy: 0.3143\n",
            "Epoch 350/2000\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 2.0720 - accuracy: 0.4545 - val_loss: 17.6229 - val_accuracy: 0.3071\n",
            "Epoch 351/2000\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 2.0694 - accuracy: 0.4509 - val_loss: 17.6584 - val_accuracy: 0.2964\n",
            "Epoch 352/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 2.0314 - accuracy: 0.4643 - val_loss: 17.6702 - val_accuracy: 0.2964\n",
            "Epoch 353/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 2.0560 - accuracy: 0.4375 - val_loss: 17.7776 - val_accuracy: 0.2643\n",
            "Epoch 354/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 2.0873 - accuracy: 0.4411 - val_loss: 17.6001 - val_accuracy: 0.3357\n",
            "Epoch 355/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 2.0477 - accuracy: 0.4437 - val_loss: 17.7321 - val_accuracy: 0.3036\n",
            "Epoch 356/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 2.0302 - accuracy: 0.4473 - val_loss: 17.6870 - val_accuracy: 0.2857\n",
            "Epoch 357/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 2.0173 - accuracy: 0.4652 - val_loss: 17.6553 - val_accuracy: 0.3107\n",
            "Epoch 358/2000\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 2.0174 - accuracy: 0.4714 - val_loss: 17.7109 - val_accuracy: 0.3143\n",
            "Epoch 359/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 2.0260 - accuracy: 0.4652 - val_loss: 17.8868 - val_accuracy: 0.2964\n",
            "Epoch 360/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 2.0322 - accuracy: 0.4464 - val_loss: 17.8319 - val_accuracy: 0.2786\n",
            "Epoch 361/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 2.0062 - accuracy: 0.4741 - val_loss: 17.7735 - val_accuracy: 0.3036\n",
            "Epoch 362/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.9902 - accuracy: 0.4723 - val_loss: 17.8351 - val_accuracy: 0.2893\n",
            "Epoch 363/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 2.0197 - accuracy: 0.4446 - val_loss: 17.8040 - val_accuracy: 0.3321\n",
            "Epoch 364/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.9943 - accuracy: 0.4661 - val_loss: 17.7793 - val_accuracy: 0.3071\n",
            "Epoch 365/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.9870 - accuracy: 0.4821 - val_loss: 17.8048 - val_accuracy: 0.3250\n",
            "Epoch 366/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.9896 - accuracy: 0.4705 - val_loss: 17.8780 - val_accuracy: 0.3000\n",
            "Epoch 367/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.9981 - accuracy: 0.4688 - val_loss: 17.9651 - val_accuracy: 0.2929\n",
            "Epoch 368/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 2.0092 - accuracy: 0.4563 - val_loss: 17.9261 - val_accuracy: 0.2964\n",
            "Epoch 369/2000\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 1.9745 - accuracy: 0.4732 - val_loss: 17.8579 - val_accuracy: 0.3536\n",
            "Epoch 370/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.9772 - accuracy: 0.4768 - val_loss: 18.0220 - val_accuracy: 0.3036\n",
            "Epoch 371/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.9658 - accuracy: 0.4705 - val_loss: 17.9715 - val_accuracy: 0.3286\n",
            "Epoch 372/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.9782 - accuracy: 0.4741 - val_loss: 17.9482 - val_accuracy: 0.3286\n",
            "Epoch 373/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.9857 - accuracy: 0.4866 - val_loss: 17.9649 - val_accuracy: 0.3750\n",
            "Epoch 374/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.9680 - accuracy: 0.4741 - val_loss: 18.1761 - val_accuracy: 0.3179\n",
            "Epoch 375/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.9518 - accuracy: 0.5080 - val_loss: 18.1580 - val_accuracy: 0.3143\n",
            "Epoch 376/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.9546 - accuracy: 0.4696 - val_loss: 18.1184 - val_accuracy: 0.2929\n",
            "Epoch 377/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.9545 - accuracy: 0.4777 - val_loss: 18.0561 - val_accuracy: 0.3143\n",
            "Epoch 378/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.9654 - accuracy: 0.4750 - val_loss: 18.1941 - val_accuracy: 0.3250\n",
            "Epoch 379/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.9668 - accuracy: 0.4812 - val_loss: 18.3242 - val_accuracy: 0.3286\n",
            "Epoch 380/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.9406 - accuracy: 0.4839 - val_loss: 18.1381 - val_accuracy: 0.3357\n",
            "Epoch 381/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.9213 - accuracy: 0.4821 - val_loss: 18.2405 - val_accuracy: 0.3500\n",
            "Epoch 382/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.9179 - accuracy: 0.5045 - val_loss: 18.2671 - val_accuracy: 0.3464\n",
            "Epoch 383/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.9353 - accuracy: 0.4875 - val_loss: 18.2333 - val_accuracy: 0.3071\n",
            "Epoch 384/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.9306 - accuracy: 0.4955 - val_loss: 18.2892 - val_accuracy: 0.3107\n",
            "Epoch 385/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.9057 - accuracy: 0.4920 - val_loss: 18.2937 - val_accuracy: 0.3107\n",
            "Epoch 386/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.9058 - accuracy: 0.4946 - val_loss: 18.2553 - val_accuracy: 0.3571\n",
            "Epoch 387/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.8984 - accuracy: 0.5152 - val_loss: 18.3485 - val_accuracy: 0.3179\n",
            "Epoch 388/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.9192 - accuracy: 0.4991 - val_loss: 18.4029 - val_accuracy: 0.3500\n",
            "Epoch 389/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.9298 - accuracy: 0.4964 - val_loss: 18.3701 - val_accuracy: 0.3393\n",
            "Epoch 390/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.8920 - accuracy: 0.5116 - val_loss: 18.3518 - val_accuracy: 0.3321\n",
            "Epoch 391/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.9064 - accuracy: 0.4750 - val_loss: 18.4395 - val_accuracy: 0.3357\n",
            "Epoch 392/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.8867 - accuracy: 0.4982 - val_loss: 18.3693 - val_accuracy: 0.3357\n",
            "Epoch 393/2000\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 1.9048 - accuracy: 0.4920 - val_loss: 18.3984 - val_accuracy: 0.3286\n",
            "Epoch 394/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.8944 - accuracy: 0.5071 - val_loss: 18.4624 - val_accuracy: 0.3393\n",
            "Epoch 395/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.8803 - accuracy: 0.5098 - val_loss: 18.5356 - val_accuracy: 0.3321\n",
            "Epoch 396/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.8698 - accuracy: 0.5054 - val_loss: 18.5348 - val_accuracy: 0.3036\n",
            "Epoch 397/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.8847 - accuracy: 0.5143 - val_loss: 18.6150 - val_accuracy: 0.3250\n",
            "Epoch 398/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.9103 - accuracy: 0.4839 - val_loss: 18.5091 - val_accuracy: 0.3321\n",
            "Epoch 399/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.8652 - accuracy: 0.5259 - val_loss: 18.5237 - val_accuracy: 0.3214\n",
            "Epoch 400/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.8966 - accuracy: 0.5000 - val_loss: 18.7243 - val_accuracy: 0.3107\n",
            "Epoch 401/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.8720 - accuracy: 0.5161 - val_loss: 18.6232 - val_accuracy: 0.3571\n",
            "Epoch 402/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.8408 - accuracy: 0.5295 - val_loss: 18.7100 - val_accuracy: 0.3607\n",
            "Epoch 403/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.8413 - accuracy: 0.5277 - val_loss: 18.6529 - val_accuracy: 0.3571\n",
            "Epoch 404/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.8405 - accuracy: 0.5179 - val_loss: 18.6880 - val_accuracy: 0.3393\n",
            "Epoch 405/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.8547 - accuracy: 0.5286 - val_loss: 18.6923 - val_accuracy: 0.3357\n",
            "Epoch 406/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.8353 - accuracy: 0.5339 - val_loss: 18.8170 - val_accuracy: 0.3143\n",
            "Epoch 407/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.8403 - accuracy: 0.5054 - val_loss: 18.7689 - val_accuracy: 0.3357\n",
            "Epoch 408/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.8363 - accuracy: 0.5232 - val_loss: 18.7765 - val_accuracy: 0.3607\n",
            "Epoch 409/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.8353 - accuracy: 0.5009 - val_loss: 18.8628 - val_accuracy: 0.3393\n",
            "Epoch 410/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.8201 - accuracy: 0.5348 - val_loss: 18.8189 - val_accuracy: 0.3679\n",
            "Epoch 411/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.8081 - accuracy: 0.5321 - val_loss: 18.8688 - val_accuracy: 0.3357\n",
            "Epoch 412/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.8226 - accuracy: 0.5312 - val_loss: 18.9415 - val_accuracy: 0.3286\n",
            "Epoch 413/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.8339 - accuracy: 0.5045 - val_loss: 18.9873 - val_accuracy: 0.3607\n",
            "Epoch 414/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.8339 - accuracy: 0.5161 - val_loss: 18.9673 - val_accuracy: 0.3607\n",
            "Epoch 415/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.8463 - accuracy: 0.5179 - val_loss: 19.0488 - val_accuracy: 0.3500\n",
            "Epoch 416/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.8040 - accuracy: 0.5464 - val_loss: 19.0255 - val_accuracy: 0.3393\n",
            "Epoch 417/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.7878 - accuracy: 0.5518 - val_loss: 18.9578 - val_accuracy: 0.3964\n",
            "Epoch 418/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.7741 - accuracy: 0.5241 - val_loss: 19.0083 - val_accuracy: 0.3464\n",
            "Epoch 419/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.8080 - accuracy: 0.5241 - val_loss: 19.1422 - val_accuracy: 0.3536\n",
            "Epoch 420/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.8096 - accuracy: 0.5250 - val_loss: 19.0933 - val_accuracy: 0.3607\n",
            "Epoch 421/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.7939 - accuracy: 0.5304 - val_loss: 19.1298 - val_accuracy: 0.3571\n",
            "Epoch 422/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.7827 - accuracy: 0.5402 - val_loss: 19.1205 - val_accuracy: 0.3750\n",
            "Epoch 423/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.7991 - accuracy: 0.5357 - val_loss: 19.1288 - val_accuracy: 0.3929\n",
            "Epoch 424/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.7676 - accuracy: 0.5589 - val_loss: 19.2149 - val_accuracy: 0.3607\n",
            "Epoch 425/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.7856 - accuracy: 0.5268 - val_loss: 19.3045 - val_accuracy: 0.3571\n",
            "Epoch 426/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.7956 - accuracy: 0.5411 - val_loss: 19.3614 - val_accuracy: 0.3357\n",
            "Epoch 427/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.7693 - accuracy: 0.5411 - val_loss: 19.3663 - val_accuracy: 0.3500\n",
            "Epoch 428/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.7701 - accuracy: 0.5420 - val_loss: 19.3828 - val_accuracy: 0.3321\n",
            "Epoch 429/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.7737 - accuracy: 0.5509 - val_loss: 19.3939 - val_accuracy: 0.3571\n",
            "Epoch 430/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.8061 - accuracy: 0.5277 - val_loss: 19.3891 - val_accuracy: 0.3857\n",
            "Epoch 431/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.7646 - accuracy: 0.5536 - val_loss: 19.3431 - val_accuracy: 0.3714\n",
            "Epoch 432/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.7591 - accuracy: 0.5411 - val_loss: 19.3524 - val_accuracy: 0.3536\n",
            "Epoch 433/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.7591 - accuracy: 0.5402 - val_loss: 19.4067 - val_accuracy: 0.3786\n",
            "Epoch 434/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.7184 - accuracy: 0.5634 - val_loss: 19.3917 - val_accuracy: 0.3786\n",
            "Epoch 435/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.7493 - accuracy: 0.5437 - val_loss: 19.4302 - val_accuracy: 0.3607\n",
            "Epoch 436/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.7661 - accuracy: 0.5482 - val_loss: 19.4605 - val_accuracy: 0.3821\n",
            "Epoch 437/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.7630 - accuracy: 0.5268 - val_loss: 19.4685 - val_accuracy: 0.3929\n",
            "Epoch 438/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.7478 - accuracy: 0.5196 - val_loss: 19.6349 - val_accuracy: 0.3393\n",
            "Epoch 439/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.7380 - accuracy: 0.5580 - val_loss: 19.6007 - val_accuracy: 0.3500\n",
            "Epoch 440/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.7307 - accuracy: 0.5562 - val_loss: 19.5717 - val_accuracy: 0.4036\n",
            "Epoch 441/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.7302 - accuracy: 0.5500 - val_loss: 19.7584 - val_accuracy: 0.3286\n",
            "Epoch 442/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.7608 - accuracy: 0.5321 - val_loss: 19.7039 - val_accuracy: 0.3571\n",
            "Epoch 443/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.7238 - accuracy: 0.5366 - val_loss: 19.6723 - val_accuracy: 0.3786\n",
            "Epoch 444/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.7190 - accuracy: 0.5491 - val_loss: 19.6914 - val_accuracy: 0.3536\n",
            "Epoch 445/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.7212 - accuracy: 0.5518 - val_loss: 19.7310 - val_accuracy: 0.3679\n",
            "Epoch 446/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.7243 - accuracy: 0.5554 - val_loss: 19.7288 - val_accuracy: 0.3643\n",
            "Epoch 447/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.7245 - accuracy: 0.5500 - val_loss: 19.7955 - val_accuracy: 0.3750\n",
            "Epoch 448/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.7281 - accuracy: 0.5554 - val_loss: 19.7334 - val_accuracy: 0.4036\n",
            "Epoch 449/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.7077 - accuracy: 0.5580 - val_loss: 19.8178 - val_accuracy: 0.3500\n",
            "Epoch 450/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.6959 - accuracy: 0.5589 - val_loss: 19.7394 - val_accuracy: 0.3786\n",
            "Epoch 451/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.6954 - accuracy: 0.5670 - val_loss: 19.7334 - val_accuracy: 0.3786\n",
            "Epoch 452/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.7112 - accuracy: 0.5536 - val_loss: 19.8599 - val_accuracy: 0.3893\n",
            "Epoch 453/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.6907 - accuracy: 0.5670 - val_loss: 19.9898 - val_accuracy: 0.3357\n",
            "Epoch 454/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.7092 - accuracy: 0.5473 - val_loss: 19.7786 - val_accuracy: 0.3821\n",
            "Epoch 455/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.6853 - accuracy: 0.5795 - val_loss: 19.9692 - val_accuracy: 0.3750\n",
            "Epoch 456/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.6952 - accuracy: 0.5670 - val_loss: 19.9736 - val_accuracy: 0.4000\n",
            "Epoch 457/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.6870 - accuracy: 0.5670 - val_loss: 19.9087 - val_accuracy: 0.3821\n",
            "Epoch 458/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.6684 - accuracy: 0.5670 - val_loss: 20.0539 - val_accuracy: 0.3929\n",
            "Epoch 459/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.6809 - accuracy: 0.5732 - val_loss: 20.0612 - val_accuracy: 0.3786\n",
            "Epoch 460/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.6857 - accuracy: 0.5402 - val_loss: 19.9598 - val_accuracy: 0.3643\n",
            "Epoch 461/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.6478 - accuracy: 0.5830 - val_loss: 20.0526 - val_accuracy: 0.3643\n",
            "Epoch 462/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.6630 - accuracy: 0.5813 - val_loss: 20.0200 - val_accuracy: 0.3821\n",
            "Epoch 463/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.6590 - accuracy: 0.5661 - val_loss: 19.9740 - val_accuracy: 0.3821\n",
            "Epoch 464/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.6478 - accuracy: 0.5830 - val_loss: 20.1358 - val_accuracy: 0.3571\n",
            "Epoch 465/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.6735 - accuracy: 0.5795 - val_loss: 20.0964 - val_accuracy: 0.3643\n",
            "Epoch 466/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.6556 - accuracy: 0.5759 - val_loss: 20.2021 - val_accuracy: 0.3893\n",
            "Epoch 467/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.6756 - accuracy: 0.5670 - val_loss: 20.2244 - val_accuracy: 0.3750\n",
            "Epoch 468/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.6429 - accuracy: 0.5804 - val_loss: 20.2433 - val_accuracy: 0.3964\n",
            "Epoch 469/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.6606 - accuracy: 0.5723 - val_loss: 20.1351 - val_accuracy: 0.3679\n",
            "Epoch 470/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.6360 - accuracy: 0.5795 - val_loss: 20.2949 - val_accuracy: 0.3607\n",
            "Epoch 471/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.6300 - accuracy: 0.5857 - val_loss: 20.2704 - val_accuracy: 0.4000\n",
            "Epoch 472/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.6327 - accuracy: 0.5696 - val_loss: 20.2937 - val_accuracy: 0.3929\n",
            "Epoch 473/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.6298 - accuracy: 0.5786 - val_loss: 20.2760 - val_accuracy: 0.3857\n",
            "Epoch 474/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.6312 - accuracy: 0.5759 - val_loss: 20.3730 - val_accuracy: 0.3929\n",
            "Epoch 475/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.6306 - accuracy: 0.5884 - val_loss: 20.3413 - val_accuracy: 0.3893\n",
            "Epoch 476/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.6094 - accuracy: 0.6107 - val_loss: 20.3222 - val_accuracy: 0.4071\n",
            "Epoch 477/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.6126 - accuracy: 0.5804 - val_loss: 20.4345 - val_accuracy: 0.3571\n",
            "Epoch 478/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.5905 - accuracy: 0.5938 - val_loss: 20.4297 - val_accuracy: 0.3929\n",
            "Epoch 479/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.6238 - accuracy: 0.5643 - val_loss: 20.4643 - val_accuracy: 0.3857\n",
            "Epoch 480/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.6019 - accuracy: 0.6000 - val_loss: 20.5525 - val_accuracy: 0.4143\n",
            "Epoch 481/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.6028 - accuracy: 0.5929 - val_loss: 20.6432 - val_accuracy: 0.4071\n",
            "Epoch 482/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.6183 - accuracy: 0.5884 - val_loss: 20.5760 - val_accuracy: 0.3750\n",
            "Epoch 483/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.6085 - accuracy: 0.5848 - val_loss: 20.6858 - val_accuracy: 0.3786\n",
            "Epoch 484/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.6058 - accuracy: 0.6054 - val_loss: 20.5683 - val_accuracy: 0.4286\n",
            "Epoch 485/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.5988 - accuracy: 0.5893 - val_loss: 20.5136 - val_accuracy: 0.4000\n",
            "Epoch 486/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.6004 - accuracy: 0.6009 - val_loss: 20.6687 - val_accuracy: 0.4179\n",
            "Epoch 487/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.6237 - accuracy: 0.5741 - val_loss: 20.7279 - val_accuracy: 0.3750\n",
            "Epoch 488/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.6202 - accuracy: 0.5696 - val_loss: 20.7945 - val_accuracy: 0.4107\n",
            "Epoch 489/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.5791 - accuracy: 0.5911 - val_loss: 20.6898 - val_accuracy: 0.4286\n",
            "Epoch 490/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.5967 - accuracy: 0.6045 - val_loss: 20.6762 - val_accuracy: 0.4071\n",
            "Epoch 491/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.5919 - accuracy: 0.5911 - val_loss: 20.7477 - val_accuracy: 0.3750\n",
            "Epoch 492/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.5948 - accuracy: 0.5902 - val_loss: 20.6873 - val_accuracy: 0.3893\n",
            "Epoch 493/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.5713 - accuracy: 0.5813 - val_loss: 20.7157 - val_accuracy: 0.3750\n",
            "Epoch 494/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.5896 - accuracy: 0.5929 - val_loss: 20.8324 - val_accuracy: 0.3964\n",
            "Epoch 495/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.6050 - accuracy: 0.5795 - val_loss: 20.9706 - val_accuracy: 0.3786\n",
            "Epoch 496/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.6158 - accuracy: 0.5848 - val_loss: 20.9534 - val_accuracy: 0.3821\n",
            "Epoch 497/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.5921 - accuracy: 0.5911 - val_loss: 20.8277 - val_accuracy: 0.4321\n",
            "Epoch 498/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.5803 - accuracy: 0.6018 - val_loss: 20.9461 - val_accuracy: 0.4000\n",
            "Epoch 499/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.5743 - accuracy: 0.6152 - val_loss: 21.0156 - val_accuracy: 0.4036\n",
            "Epoch 500/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.5423 - accuracy: 0.6134 - val_loss: 20.9719 - val_accuracy: 0.4321\n",
            "Epoch 501/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.5509 - accuracy: 0.6107 - val_loss: 20.9386 - val_accuracy: 0.4071\n",
            "Epoch 502/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.5441 - accuracy: 0.6179 - val_loss: 21.0375 - val_accuracy: 0.3964\n",
            "Epoch 503/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.5441 - accuracy: 0.6054 - val_loss: 20.9865 - val_accuracy: 0.3964\n",
            "Epoch 504/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.5522 - accuracy: 0.6152 - val_loss: 21.0925 - val_accuracy: 0.3786\n",
            "Epoch 505/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.5350 - accuracy: 0.6223 - val_loss: 21.0993 - val_accuracy: 0.4036\n",
            "Epoch 506/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.5538 - accuracy: 0.5991 - val_loss: 21.0980 - val_accuracy: 0.4036\n",
            "Epoch 507/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.5583 - accuracy: 0.6116 - val_loss: 21.1491 - val_accuracy: 0.3964\n",
            "Epoch 508/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.5325 - accuracy: 0.6000 - val_loss: 21.1474 - val_accuracy: 0.3714\n",
            "Epoch 509/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.5440 - accuracy: 0.6062 - val_loss: 21.1222 - val_accuracy: 0.4036\n",
            "Epoch 510/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.5399 - accuracy: 0.6143 - val_loss: 21.2034 - val_accuracy: 0.3893\n",
            "Epoch 511/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.5416 - accuracy: 0.6152 - val_loss: 21.1949 - val_accuracy: 0.4036\n",
            "Epoch 512/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.5284 - accuracy: 0.6054 - val_loss: 21.2567 - val_accuracy: 0.4036\n",
            "Epoch 513/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.5358 - accuracy: 0.6321 - val_loss: 21.1738 - val_accuracy: 0.4321\n",
            "Epoch 514/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.5101 - accuracy: 0.6339 - val_loss: 21.2415 - val_accuracy: 0.4321\n",
            "Epoch 515/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.5208 - accuracy: 0.6134 - val_loss: 21.3768 - val_accuracy: 0.3857\n",
            "Epoch 516/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.5524 - accuracy: 0.5920 - val_loss: 21.3310 - val_accuracy: 0.4250\n",
            "Epoch 517/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.5432 - accuracy: 0.6080 - val_loss: 21.2880 - val_accuracy: 0.3893\n",
            "Epoch 518/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.5323 - accuracy: 0.5982 - val_loss: 21.3048 - val_accuracy: 0.4321\n",
            "Epoch 519/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.5052 - accuracy: 0.6045 - val_loss: 21.3932 - val_accuracy: 0.4179\n",
            "Epoch 520/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.5261 - accuracy: 0.6036 - val_loss: 21.3287 - val_accuracy: 0.4036\n",
            "Epoch 521/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.5218 - accuracy: 0.6054 - val_loss: 21.3760 - val_accuracy: 0.4286\n",
            "Epoch 522/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.5065 - accuracy: 0.6161 - val_loss: 21.5452 - val_accuracy: 0.3750\n",
            "Epoch 523/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.5085 - accuracy: 0.6196 - val_loss: 21.4558 - val_accuracy: 0.4429\n",
            "Epoch 524/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.5028 - accuracy: 0.6143 - val_loss: 21.4154 - val_accuracy: 0.3893\n",
            "Epoch 525/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.5022 - accuracy: 0.6205 - val_loss: 21.4443 - val_accuracy: 0.4143\n",
            "Epoch 526/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.5032 - accuracy: 0.6232 - val_loss: 21.5336 - val_accuracy: 0.4036\n",
            "Epoch 527/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.5147 - accuracy: 0.6152 - val_loss: 21.4955 - val_accuracy: 0.4321\n",
            "Epoch 528/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.5128 - accuracy: 0.6089 - val_loss: 21.5438 - val_accuracy: 0.3964\n",
            "Epoch 529/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.5068 - accuracy: 0.6027 - val_loss: 21.6523 - val_accuracy: 0.3857\n",
            "Epoch 530/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.4785 - accuracy: 0.6438 - val_loss: 21.5778 - val_accuracy: 0.4321\n",
            "Epoch 531/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.4772 - accuracy: 0.6098 - val_loss: 21.5631 - val_accuracy: 0.3893\n",
            "Epoch 532/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.4848 - accuracy: 0.6116 - val_loss: 21.6403 - val_accuracy: 0.4179\n",
            "Epoch 533/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.4828 - accuracy: 0.6232 - val_loss: 21.7001 - val_accuracy: 0.4143\n",
            "Epoch 534/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.4972 - accuracy: 0.6089 - val_loss: 21.7534 - val_accuracy: 0.4250\n",
            "Epoch 535/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.5180 - accuracy: 0.6080 - val_loss: 21.7304 - val_accuracy: 0.4250\n",
            "Epoch 536/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.4811 - accuracy: 0.6223 - val_loss: 21.7700 - val_accuracy: 0.4286\n",
            "Epoch 537/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.4739 - accuracy: 0.6098 - val_loss: 21.6456 - val_accuracy: 0.4179\n",
            "Epoch 538/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.4610 - accuracy: 0.6348 - val_loss: 21.7772 - val_accuracy: 0.4500\n",
            "Epoch 539/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.4528 - accuracy: 0.6429 - val_loss: 21.7145 - val_accuracy: 0.4250\n",
            "Epoch 540/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.4669 - accuracy: 0.6259 - val_loss: 21.8577 - val_accuracy: 0.4143\n",
            "Epoch 541/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.4630 - accuracy: 0.6375 - val_loss: 21.8072 - val_accuracy: 0.4214\n",
            "Epoch 542/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.4566 - accuracy: 0.6223 - val_loss: 21.7074 - val_accuracy: 0.4214\n",
            "Epoch 543/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.4782 - accuracy: 0.6196 - val_loss: 21.9033 - val_accuracy: 0.4107\n",
            "Epoch 544/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.4431 - accuracy: 0.6277 - val_loss: 21.8503 - val_accuracy: 0.4000\n",
            "Epoch 545/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.4588 - accuracy: 0.6375 - val_loss: 21.7909 - val_accuracy: 0.4286\n",
            "Epoch 546/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.4310 - accuracy: 0.6455 - val_loss: 21.8131 - val_accuracy: 0.4429\n",
            "Epoch 547/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.4075 - accuracy: 0.6438 - val_loss: 21.9003 - val_accuracy: 0.4357\n",
            "Epoch 548/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.4160 - accuracy: 0.6384 - val_loss: 21.7842 - val_accuracy: 0.4321\n",
            "Epoch 549/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.4359 - accuracy: 0.6411 - val_loss: 21.9914 - val_accuracy: 0.4107\n",
            "Epoch 550/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.4449 - accuracy: 0.6313 - val_loss: 22.0486 - val_accuracy: 0.4071\n",
            "Epoch 551/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.4376 - accuracy: 0.6339 - val_loss: 22.0502 - val_accuracy: 0.4357\n",
            "Epoch 552/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.4084 - accuracy: 0.6482 - val_loss: 22.0524 - val_accuracy: 0.4179\n",
            "Epoch 553/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.4440 - accuracy: 0.6179 - val_loss: 22.0578 - val_accuracy: 0.4286\n",
            "Epoch 554/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.4277 - accuracy: 0.6438 - val_loss: 22.0605 - val_accuracy: 0.4429\n",
            "Epoch 555/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.4397 - accuracy: 0.6223 - val_loss: 22.1234 - val_accuracy: 0.4536\n",
            "Epoch 556/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.5015 - accuracy: 0.6152 - val_loss: 22.0483 - val_accuracy: 0.3893\n",
            "Epoch 557/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.4485 - accuracy: 0.6286 - val_loss: 22.3177 - val_accuracy: 0.4250\n",
            "Epoch 558/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.4374 - accuracy: 0.6313 - val_loss: 22.2499 - val_accuracy: 0.4214\n",
            "Epoch 559/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.4174 - accuracy: 0.6464 - val_loss: 22.1554 - val_accuracy: 0.4036\n",
            "Epoch 560/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.4198 - accuracy: 0.6464 - val_loss: 22.2832 - val_accuracy: 0.4214\n",
            "Epoch 561/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.4379 - accuracy: 0.6330 - val_loss: 22.1459 - val_accuracy: 0.4286\n",
            "Epoch 562/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.3921 - accuracy: 0.6509 - val_loss: 22.3191 - val_accuracy: 0.4250\n",
            "Epoch 563/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.3878 - accuracy: 0.6545 - val_loss: 22.2081 - val_accuracy: 0.4500\n",
            "Epoch 564/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.3870 - accuracy: 0.6554 - val_loss: 22.3111 - val_accuracy: 0.4250\n",
            "Epoch 565/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.3749 - accuracy: 0.6554 - val_loss: 22.1902 - val_accuracy: 0.4464\n",
            "Epoch 566/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.4117 - accuracy: 0.6446 - val_loss: 22.4396 - val_accuracy: 0.4500\n",
            "Epoch 567/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.4019 - accuracy: 0.6500 - val_loss: 22.4077 - val_accuracy: 0.4214\n",
            "Epoch 568/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.4186 - accuracy: 0.6313 - val_loss: 22.4165 - val_accuracy: 0.4286\n",
            "Epoch 569/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.4219 - accuracy: 0.6375 - val_loss: 22.2729 - val_accuracy: 0.4250\n",
            "Epoch 570/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.4041 - accuracy: 0.6491 - val_loss: 22.4176 - val_accuracy: 0.4536\n",
            "Epoch 571/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.4146 - accuracy: 0.6321 - val_loss: 22.4326 - val_accuracy: 0.4429\n",
            "Epoch 572/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.3849 - accuracy: 0.6562 - val_loss: 22.4559 - val_accuracy: 0.4429\n",
            "Epoch 573/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.3736 - accuracy: 0.6607 - val_loss: 22.4588 - val_accuracy: 0.4393\n",
            "Epoch 574/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.3806 - accuracy: 0.6473 - val_loss: 22.3899 - val_accuracy: 0.4393\n",
            "Epoch 575/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.3800 - accuracy: 0.6580 - val_loss: 22.5910 - val_accuracy: 0.4321\n",
            "Epoch 576/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.3979 - accuracy: 0.6357 - val_loss: 22.4999 - val_accuracy: 0.4357\n",
            "Epoch 577/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.3586 - accuracy: 0.6714 - val_loss: 22.5298 - val_accuracy: 0.4357\n",
            "Epoch 578/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.3598 - accuracy: 0.6696 - val_loss: 22.6730 - val_accuracy: 0.4429\n",
            "Epoch 579/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.3584 - accuracy: 0.6643 - val_loss: 22.5844 - val_accuracy: 0.4357\n",
            "Epoch 580/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.3657 - accuracy: 0.6670 - val_loss: 22.5684 - val_accuracy: 0.4500\n",
            "Epoch 581/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.3850 - accuracy: 0.6357 - val_loss: 22.6216 - val_accuracy: 0.4143\n",
            "Epoch 582/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.3642 - accuracy: 0.6482 - val_loss: 22.7296 - val_accuracy: 0.4393\n",
            "Epoch 583/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.4267 - accuracy: 0.6223 - val_loss: 22.7532 - val_accuracy: 0.4321\n",
            "Epoch 584/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.3927 - accuracy: 0.6634 - val_loss: 22.6294 - val_accuracy: 0.4250\n",
            "Epoch 585/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.3933 - accuracy: 0.6241 - val_loss: 22.7500 - val_accuracy: 0.4393\n",
            "Epoch 586/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.4025 - accuracy: 0.6455 - val_loss: 22.7483 - val_accuracy: 0.4393\n",
            "Epoch 587/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.3589 - accuracy: 0.6500 - val_loss: 22.8054 - val_accuracy: 0.4321\n",
            "Epoch 588/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.3627 - accuracy: 0.6482 - val_loss: 22.7020 - val_accuracy: 0.4786\n",
            "Epoch 589/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.3482 - accuracy: 0.6580 - val_loss: 22.7415 - val_accuracy: 0.4571\n",
            "Epoch 590/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.3410 - accuracy: 0.6786 - val_loss: 22.8747 - val_accuracy: 0.4393\n",
            "Epoch 591/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.3456 - accuracy: 0.6607 - val_loss: 22.8104 - val_accuracy: 0.4286\n",
            "Epoch 592/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.3601 - accuracy: 0.6625 - val_loss: 22.8006 - val_accuracy: 0.4929\n",
            "Epoch 593/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.3746 - accuracy: 0.6473 - val_loss: 22.9505 - val_accuracy: 0.4357\n",
            "Epoch 594/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.3487 - accuracy: 0.6607 - val_loss: 23.0243 - val_accuracy: 0.4643\n",
            "Epoch 595/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.3587 - accuracy: 0.6607 - val_loss: 22.9492 - val_accuracy: 0.4321\n",
            "Epoch 596/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.3385 - accuracy: 0.6732 - val_loss: 22.8587 - val_accuracy: 0.4536\n",
            "Epoch 597/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.3387 - accuracy: 0.6723 - val_loss: 22.9253 - val_accuracy: 0.4607\n",
            "Epoch 598/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.3365 - accuracy: 0.6536 - val_loss: 23.0252 - val_accuracy: 0.4714\n",
            "Epoch 599/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.3541 - accuracy: 0.6545 - val_loss: 23.0139 - val_accuracy: 0.4500\n",
            "Epoch 600/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.3476 - accuracy: 0.6500 - val_loss: 23.0023 - val_accuracy: 0.4500\n",
            "Epoch 601/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.3075 - accuracy: 0.6821 - val_loss: 23.0604 - val_accuracy: 0.4214\n",
            "Epoch 602/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.3168 - accuracy: 0.6670 - val_loss: 23.0228 - val_accuracy: 0.4571\n",
            "Epoch 603/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.3344 - accuracy: 0.6625 - val_loss: 23.1073 - val_accuracy: 0.4286\n",
            "Epoch 604/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.3122 - accuracy: 0.6768 - val_loss: 23.1026 - val_accuracy: 0.4714\n",
            "Epoch 605/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.3020 - accuracy: 0.6643 - val_loss: 23.0527 - val_accuracy: 0.4464\n",
            "Epoch 606/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.3189 - accuracy: 0.6768 - val_loss: 23.2679 - val_accuracy: 0.4607\n",
            "Epoch 607/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.3551 - accuracy: 0.6625 - val_loss: 23.1160 - val_accuracy: 0.4464\n",
            "Epoch 608/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.3167 - accuracy: 0.6857 - val_loss: 23.2638 - val_accuracy: 0.4464\n",
            "Epoch 609/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.3235 - accuracy: 0.6616 - val_loss: 23.1112 - val_accuracy: 0.4429\n",
            "Epoch 610/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.3058 - accuracy: 0.6696 - val_loss: 23.1908 - val_accuracy: 0.4429\n",
            "Epoch 611/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.3320 - accuracy: 0.6607 - val_loss: 23.3218 - val_accuracy: 0.4571\n",
            "Epoch 612/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.3254 - accuracy: 0.6545 - val_loss: 23.4132 - val_accuracy: 0.4214\n",
            "Epoch 613/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.3038 - accuracy: 0.6723 - val_loss: 23.2507 - val_accuracy: 0.4500\n",
            "Epoch 614/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.3344 - accuracy: 0.6554 - val_loss: 23.1871 - val_accuracy: 0.4500\n",
            "Epoch 615/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.3065 - accuracy: 0.6696 - val_loss: 23.3014 - val_accuracy: 0.4429\n",
            "Epoch 616/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.3019 - accuracy: 0.6536 - val_loss: 23.3448 - val_accuracy: 0.4500\n",
            "Epoch 617/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.3478 - accuracy: 0.6625 - val_loss: 23.3653 - val_accuracy: 0.4393\n",
            "Epoch 618/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.2866 - accuracy: 0.6804 - val_loss: 23.2143 - val_accuracy: 0.4571\n",
            "Epoch 619/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.2889 - accuracy: 0.6812 - val_loss: 23.3273 - val_accuracy: 0.4679\n",
            "Epoch 620/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.3118 - accuracy: 0.6607 - val_loss: 23.4159 - val_accuracy: 0.4357\n",
            "Epoch 621/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.3053 - accuracy: 0.6723 - val_loss: 23.4138 - val_accuracy: 0.4464\n",
            "Epoch 622/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.2952 - accuracy: 0.6625 - val_loss: 23.4210 - val_accuracy: 0.4714\n",
            "Epoch 623/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.2913 - accuracy: 0.6741 - val_loss: 23.5021 - val_accuracy: 0.4321\n",
            "Epoch 624/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.2756 - accuracy: 0.6786 - val_loss: 23.5266 - val_accuracy: 0.4357\n",
            "Epoch 625/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.3015 - accuracy: 0.6750 - val_loss: 23.2974 - val_accuracy: 0.4643\n",
            "Epoch 626/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.3276 - accuracy: 0.6536 - val_loss: 23.6207 - val_accuracy: 0.4357\n",
            "Epoch 627/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.3250 - accuracy: 0.6580 - val_loss: 23.5483 - val_accuracy: 0.4643\n",
            "Epoch 628/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.3105 - accuracy: 0.6768 - val_loss: 23.5776 - val_accuracy: 0.4357\n",
            "Epoch 629/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.3269 - accuracy: 0.6661 - val_loss: 23.6092 - val_accuracy: 0.4393\n",
            "Epoch 630/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.3037 - accuracy: 0.6866 - val_loss: 23.5548 - val_accuracy: 0.4786\n",
            "Epoch 631/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.3113 - accuracy: 0.6723 - val_loss: 23.6596 - val_accuracy: 0.4571\n",
            "Epoch 632/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.3165 - accuracy: 0.6679 - val_loss: 23.5525 - val_accuracy: 0.4607\n",
            "Epoch 633/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.2721 - accuracy: 0.6848 - val_loss: 23.7217 - val_accuracy: 0.4429\n",
            "Epoch 634/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.2568 - accuracy: 0.6857 - val_loss: 23.6317 - val_accuracy: 0.4679\n",
            "Epoch 635/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.2697 - accuracy: 0.6804 - val_loss: 23.7422 - val_accuracy: 0.4321\n",
            "Epoch 636/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.2666 - accuracy: 0.6812 - val_loss: 23.7426 - val_accuracy: 0.4429\n",
            "Epoch 637/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.2614 - accuracy: 0.6982 - val_loss: 23.6364 - val_accuracy: 0.4786\n",
            "Epoch 638/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.2431 - accuracy: 0.6973 - val_loss: 23.6140 - val_accuracy: 0.4643\n",
            "Epoch 639/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.2753 - accuracy: 0.6723 - val_loss: 23.7000 - val_accuracy: 0.4786\n",
            "Epoch 640/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.2675 - accuracy: 0.6830 - val_loss: 23.7907 - val_accuracy: 0.4500\n",
            "Epoch 641/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.2715 - accuracy: 0.6759 - val_loss: 23.7803 - val_accuracy: 0.4500\n",
            "Epoch 642/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.2746 - accuracy: 0.6670 - val_loss: 23.8427 - val_accuracy: 0.4571\n",
            "Epoch 643/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.2811 - accuracy: 0.6759 - val_loss: 23.6990 - val_accuracy: 0.4643\n",
            "Epoch 644/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.2756 - accuracy: 0.6857 - val_loss: 23.8144 - val_accuracy: 0.4679\n",
            "Epoch 645/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.2533 - accuracy: 0.6893 - val_loss: 23.8368 - val_accuracy: 0.4571\n",
            "Epoch 646/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.2546 - accuracy: 0.6786 - val_loss: 23.7904 - val_accuracy: 0.4679\n",
            "Epoch 647/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.2561 - accuracy: 0.6723 - val_loss: 23.8946 - val_accuracy: 0.4750\n",
            "Epoch 648/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.2756 - accuracy: 0.6768 - val_loss: 23.9335 - val_accuracy: 0.4571\n",
            "Epoch 649/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.3030 - accuracy: 0.6562 - val_loss: 23.8793 - val_accuracy: 0.4643\n",
            "Epoch 650/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.2648 - accuracy: 0.6705 - val_loss: 23.8922 - val_accuracy: 0.4536\n",
            "Epoch 651/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.2664 - accuracy: 0.6723 - val_loss: 23.9501 - val_accuracy: 0.4857\n",
            "Epoch 652/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.2511 - accuracy: 0.6875 - val_loss: 23.8505 - val_accuracy: 0.4536\n",
            "Epoch 653/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.2299 - accuracy: 0.6920 - val_loss: 24.0112 - val_accuracy: 0.4429\n",
            "Epoch 654/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.2480 - accuracy: 0.6893 - val_loss: 23.9358 - val_accuracy: 0.4429\n",
            "Epoch 655/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.2562 - accuracy: 0.6875 - val_loss: 23.9148 - val_accuracy: 0.4964\n",
            "Epoch 656/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.2549 - accuracy: 0.6875 - val_loss: 23.9508 - val_accuracy: 0.4571\n",
            "Epoch 657/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.2555 - accuracy: 0.6911 - val_loss: 23.9864 - val_accuracy: 0.4679\n",
            "Epoch 658/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.2531 - accuracy: 0.6839 - val_loss: 24.0438 - val_accuracy: 0.4571\n",
            "Epoch 659/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.2465 - accuracy: 0.6732 - val_loss: 24.0666 - val_accuracy: 0.4536\n",
            "Epoch 660/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.2729 - accuracy: 0.6643 - val_loss: 24.1102 - val_accuracy: 0.4714\n",
            "Epoch 661/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.2632 - accuracy: 0.6679 - val_loss: 24.1693 - val_accuracy: 0.4679\n",
            "Epoch 662/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.2595 - accuracy: 0.6768 - val_loss: 24.1148 - val_accuracy: 0.4250\n",
            "Epoch 663/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.2711 - accuracy: 0.6705 - val_loss: 24.1179 - val_accuracy: 0.4643\n",
            "Epoch 664/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.2642 - accuracy: 0.6795 - val_loss: 24.0424 - val_accuracy: 0.4643\n",
            "Epoch 665/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.2524 - accuracy: 0.6830 - val_loss: 24.2496 - val_accuracy: 0.4464\n",
            "Epoch 666/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.2674 - accuracy: 0.6732 - val_loss: 24.2324 - val_accuracy: 0.4571\n",
            "Epoch 667/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.2687 - accuracy: 0.6670 - val_loss: 24.0584 - val_accuracy: 0.4714\n",
            "Epoch 668/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.2145 - accuracy: 0.6929 - val_loss: 24.1331 - val_accuracy: 0.4964\n",
            "Epoch 669/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.2114 - accuracy: 0.6964 - val_loss: 24.2912 - val_accuracy: 0.4571\n",
            "Epoch 670/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.2341 - accuracy: 0.6902 - val_loss: 24.0806 - val_accuracy: 0.5000\n",
            "Epoch 671/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.2382 - accuracy: 0.6920 - val_loss: 24.1528 - val_accuracy: 0.4643\n",
            "Epoch 672/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.2250 - accuracy: 0.6875 - val_loss: 24.1713 - val_accuracy: 0.4929\n",
            "Epoch 673/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.1842 - accuracy: 0.7125 - val_loss: 24.1586 - val_accuracy: 0.4393\n",
            "Epoch 674/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.2089 - accuracy: 0.6884 - val_loss: 24.1966 - val_accuracy: 0.4821\n",
            "Epoch 675/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.2082 - accuracy: 0.7054 - val_loss: 24.1834 - val_accuracy: 0.4786\n",
            "Epoch 676/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.1907 - accuracy: 0.6973 - val_loss: 24.3447 - val_accuracy: 0.4464\n",
            "Epoch 677/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.2211 - accuracy: 0.7054 - val_loss: 24.4011 - val_accuracy: 0.4500\n",
            "Epoch 678/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.1987 - accuracy: 0.6973 - val_loss: 24.2793 - val_accuracy: 0.4714\n",
            "Epoch 679/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.1741 - accuracy: 0.7027 - val_loss: 24.2554 - val_accuracy: 0.4786\n",
            "Epoch 680/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.1932 - accuracy: 0.6964 - val_loss: 24.3442 - val_accuracy: 0.4893\n",
            "Epoch 681/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.1992 - accuracy: 0.7000 - val_loss: 24.4946 - val_accuracy: 0.4857\n",
            "Epoch 682/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.2267 - accuracy: 0.6884 - val_loss: 24.4184 - val_accuracy: 0.4643\n",
            "Epoch 683/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.2252 - accuracy: 0.6670 - val_loss: 24.3502 - val_accuracy: 0.4714\n",
            "Epoch 684/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.2158 - accuracy: 0.6920 - val_loss: 24.3295 - val_accuracy: 0.4643\n",
            "Epoch 685/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.1855 - accuracy: 0.6938 - val_loss: 24.4272 - val_accuracy: 0.4714\n",
            "Epoch 686/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.1792 - accuracy: 0.7107 - val_loss: 24.4163 - val_accuracy: 0.4893\n",
            "Epoch 687/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.2359 - accuracy: 0.6768 - val_loss: 24.6290 - val_accuracy: 0.4500\n",
            "Epoch 688/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.2229 - accuracy: 0.6821 - val_loss: 24.4575 - val_accuracy: 0.4286\n",
            "Epoch 689/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.1934 - accuracy: 0.6955 - val_loss: 24.4536 - val_accuracy: 0.4786\n",
            "Epoch 690/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.1731 - accuracy: 0.7188 - val_loss: 24.4473 - val_accuracy: 0.4893\n",
            "Epoch 691/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.1681 - accuracy: 0.7125 - val_loss: 24.5165 - val_accuracy: 0.4929\n",
            "Epoch 692/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.1479 - accuracy: 0.7125 - val_loss: 24.4614 - val_accuracy: 0.5000\n",
            "Epoch 693/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.1580 - accuracy: 0.7089 - val_loss: 24.4687 - val_accuracy: 0.4821\n",
            "Epoch 694/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.1912 - accuracy: 0.6875 - val_loss: 24.5890 - val_accuracy: 0.4857\n",
            "Epoch 695/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.1917 - accuracy: 0.7063 - val_loss: 24.7124 - val_accuracy: 0.4607\n",
            "Epoch 696/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.2073 - accuracy: 0.6866 - val_loss: 24.7174 - val_accuracy: 0.4786\n",
            "Epoch 697/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.2022 - accuracy: 0.6938 - val_loss: 24.7402 - val_accuracy: 0.4500\n",
            "Epoch 698/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.1772 - accuracy: 0.6955 - val_loss: 24.5894 - val_accuracy: 0.5000\n",
            "Epoch 699/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.1647 - accuracy: 0.7071 - val_loss: 24.6727 - val_accuracy: 0.4893\n",
            "Epoch 700/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.1503 - accuracy: 0.7170 - val_loss: 24.7538 - val_accuracy: 0.4786\n",
            "Epoch 701/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.1456 - accuracy: 0.7134 - val_loss: 24.6092 - val_accuracy: 0.4750\n",
            "Epoch 702/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.1237 - accuracy: 0.7071 - val_loss: 24.8060 - val_accuracy: 0.4679\n",
            "Epoch 703/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.1598 - accuracy: 0.7205 - val_loss: 24.7904 - val_accuracy: 0.4964\n",
            "Epoch 704/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.1382 - accuracy: 0.7214 - val_loss: 24.7934 - val_accuracy: 0.4714\n",
            "Epoch 705/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.2007 - accuracy: 0.6732 - val_loss: 25.3084 - val_accuracy: 0.4179\n",
            "Epoch 706/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.2574 - accuracy: 0.6732 - val_loss: 24.9556 - val_accuracy: 0.4750\n",
            "Epoch 707/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.2277 - accuracy: 0.6804 - val_loss: 24.8383 - val_accuracy: 0.5000\n",
            "Epoch 708/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.1694 - accuracy: 0.7027 - val_loss: 24.8409 - val_accuracy: 0.4857\n",
            "Epoch 709/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.1696 - accuracy: 0.7000 - val_loss: 24.9830 - val_accuracy: 0.4750\n",
            "Epoch 710/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.2371 - accuracy: 0.6830 - val_loss: 24.8513 - val_accuracy: 0.4857\n",
            "Epoch 711/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.1629 - accuracy: 0.7125 - val_loss: 24.9219 - val_accuracy: 0.4750\n",
            "Epoch 712/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.1471 - accuracy: 0.7125 - val_loss: 24.8649 - val_accuracy: 0.4679\n",
            "Epoch 713/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.1270 - accuracy: 0.7161 - val_loss: 24.9105 - val_accuracy: 0.4679\n",
            "Epoch 714/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.1392 - accuracy: 0.7054 - val_loss: 24.9425 - val_accuracy: 0.4821\n",
            "Epoch 715/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.1280 - accuracy: 0.7241 - val_loss: 24.9829 - val_accuracy: 0.4750\n",
            "Epoch 716/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.1497 - accuracy: 0.7143 - val_loss: 24.9845 - val_accuracy: 0.4893\n",
            "Epoch 717/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.1387 - accuracy: 0.7170 - val_loss: 24.9800 - val_accuracy: 0.4893\n",
            "Epoch 718/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.1200 - accuracy: 0.7268 - val_loss: 25.0360 - val_accuracy: 0.4679\n",
            "Epoch 719/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.1224 - accuracy: 0.7152 - val_loss: 25.0612 - val_accuracy: 0.4679\n",
            "Epoch 720/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.1575 - accuracy: 0.6830 - val_loss: 25.0352 - val_accuracy: 0.4786\n",
            "Epoch 721/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.1335 - accuracy: 0.7143 - val_loss: 25.0196 - val_accuracy: 0.4714\n",
            "Epoch 722/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.1265 - accuracy: 0.7179 - val_loss: 25.0776 - val_accuracy: 0.4714\n",
            "Epoch 723/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.1301 - accuracy: 0.6991 - val_loss: 25.0908 - val_accuracy: 0.4893\n",
            "Epoch 724/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.1469 - accuracy: 0.7134 - val_loss: 25.1221 - val_accuracy: 0.4714\n",
            "Epoch 725/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.1518 - accuracy: 0.6893 - val_loss: 25.1468 - val_accuracy: 0.4964\n",
            "Epoch 726/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.1444 - accuracy: 0.7134 - val_loss: 25.2315 - val_accuracy: 0.4464\n",
            "Epoch 727/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.1948 - accuracy: 0.6955 - val_loss: 25.3065 - val_accuracy: 0.4786\n",
            "Epoch 728/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.1798 - accuracy: 0.7027 - val_loss: 25.2415 - val_accuracy: 0.4964\n",
            "Epoch 729/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.1659 - accuracy: 0.7000 - val_loss: 25.2623 - val_accuracy: 0.4786\n",
            "Epoch 730/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.1426 - accuracy: 0.7134 - val_loss: 25.3038 - val_accuracy: 0.4750\n",
            "Epoch 731/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.1526 - accuracy: 0.7125 - val_loss: 25.2832 - val_accuracy: 0.4679\n",
            "Epoch 732/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.1469 - accuracy: 0.6938 - val_loss: 25.2801 - val_accuracy: 0.5107\n",
            "Epoch 733/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.1600 - accuracy: 0.7071 - val_loss: 25.2620 - val_accuracy: 0.4643\n",
            "Epoch 734/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.1347 - accuracy: 0.7161 - val_loss: 25.3502 - val_accuracy: 0.4964\n",
            "Epoch 735/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.1468 - accuracy: 0.7071 - val_loss: 25.2167 - val_accuracy: 0.4607\n",
            "Epoch 736/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.1365 - accuracy: 0.7080 - val_loss: 25.4961 - val_accuracy: 0.5000\n",
            "Epoch 737/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.1500 - accuracy: 0.6946 - val_loss: 25.2592 - val_accuracy: 0.4893\n",
            "Epoch 738/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.1345 - accuracy: 0.7125 - val_loss: 25.1338 - val_accuracy: 0.5179\n",
            "Epoch 739/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.1237 - accuracy: 0.7232 - val_loss: 25.4702 - val_accuracy: 0.5071\n",
            "Epoch 740/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.1017 - accuracy: 0.7214 - val_loss: 25.2045 - val_accuracy: 0.5071\n",
            "Epoch 741/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.1220 - accuracy: 0.7152 - val_loss: 25.4045 - val_accuracy: 0.5071\n",
            "Epoch 742/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.0924 - accuracy: 0.7250 - val_loss: 25.4843 - val_accuracy: 0.5107\n",
            "Epoch 743/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.1200 - accuracy: 0.7018 - val_loss: 25.6588 - val_accuracy: 0.4786\n",
            "Epoch 744/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.1207 - accuracy: 0.7188 - val_loss: 25.4810 - val_accuracy: 0.4821\n",
            "Epoch 745/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.1262 - accuracy: 0.7152 - val_loss: 25.5197 - val_accuracy: 0.4893\n",
            "Epoch 746/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.1383 - accuracy: 0.7054 - val_loss: 25.5228 - val_accuracy: 0.4821\n",
            "Epoch 747/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.0888 - accuracy: 0.7330 - val_loss: 25.3335 - val_accuracy: 0.4857\n",
            "Epoch 748/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.0915 - accuracy: 0.7205 - val_loss: 25.4571 - val_accuracy: 0.4929\n",
            "Epoch 749/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.1151 - accuracy: 0.7018 - val_loss: 25.5258 - val_accuracy: 0.5071\n",
            "Epoch 750/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.1075 - accuracy: 0.7357 - val_loss: 25.5474 - val_accuracy: 0.5143\n",
            "Epoch 751/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.0904 - accuracy: 0.7330 - val_loss: 25.5135 - val_accuracy: 0.5000\n",
            "Epoch 752/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.0745 - accuracy: 0.7304 - val_loss: 25.5195 - val_accuracy: 0.5107\n",
            "Epoch 753/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.0682 - accuracy: 0.7393 - val_loss: 25.5046 - val_accuracy: 0.5036\n",
            "Epoch 754/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.0644 - accuracy: 0.7348 - val_loss: 25.6379 - val_accuracy: 0.4964\n",
            "Epoch 755/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.0963 - accuracy: 0.7143 - val_loss: 25.7444 - val_accuracy: 0.4643\n",
            "Epoch 756/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.0801 - accuracy: 0.7223 - val_loss: 25.6336 - val_accuracy: 0.4964\n",
            "Epoch 757/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.1134 - accuracy: 0.7134 - val_loss: 25.7206 - val_accuracy: 0.5179\n",
            "Epoch 758/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.1084 - accuracy: 0.7134 - val_loss: 25.7414 - val_accuracy: 0.4929\n",
            "Epoch 759/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.0899 - accuracy: 0.7259 - val_loss: 25.7426 - val_accuracy: 0.4750\n",
            "Epoch 760/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.0887 - accuracy: 0.7179 - val_loss: 25.7870 - val_accuracy: 0.4750\n",
            "Epoch 761/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.1243 - accuracy: 0.7232 - val_loss: 25.9090 - val_accuracy: 0.4714\n",
            "Epoch 762/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.1875 - accuracy: 0.6786 - val_loss: 25.9673 - val_accuracy: 0.5143\n",
            "Epoch 763/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.1168 - accuracy: 0.7080 - val_loss: 25.9733 - val_accuracy: 0.4893\n",
            "Epoch 764/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.1158 - accuracy: 0.7134 - val_loss: 25.7780 - val_accuracy: 0.5071\n",
            "Epoch 765/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.0609 - accuracy: 0.7366 - val_loss: 25.7475 - val_accuracy: 0.5036\n",
            "Epoch 766/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.0891 - accuracy: 0.7241 - val_loss: 25.7463 - val_accuracy: 0.4893\n",
            "Epoch 767/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.0844 - accuracy: 0.7330 - val_loss: 25.7841 - val_accuracy: 0.4857\n",
            "Epoch 768/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.1216 - accuracy: 0.7107 - val_loss: 25.8881 - val_accuracy: 0.4857\n",
            "Epoch 769/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.0755 - accuracy: 0.7295 - val_loss: 26.0456 - val_accuracy: 0.4750\n",
            "Epoch 770/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.0773 - accuracy: 0.7232 - val_loss: 25.9699 - val_accuracy: 0.5071\n",
            "Epoch 771/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.0560 - accuracy: 0.7348 - val_loss: 25.9557 - val_accuracy: 0.4893\n",
            "Epoch 772/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.0363 - accuracy: 0.7384 - val_loss: 26.0519 - val_accuracy: 0.4893\n",
            "Epoch 773/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.0641 - accuracy: 0.7241 - val_loss: 25.9117 - val_accuracy: 0.4893\n",
            "Epoch 774/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.0611 - accuracy: 0.7321 - val_loss: 26.0020 - val_accuracy: 0.4964\n",
            "Epoch 775/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.1804 - accuracy: 0.6759 - val_loss: 26.0299 - val_accuracy: 0.4893\n",
            "Epoch 776/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.1197 - accuracy: 0.7071 - val_loss: 26.0572 - val_accuracy: 0.4893\n",
            "Epoch 777/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.1182 - accuracy: 0.7071 - val_loss: 26.0737 - val_accuracy: 0.5000\n",
            "Epoch 778/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.0542 - accuracy: 0.7277 - val_loss: 26.0822 - val_accuracy: 0.4786\n",
            "Epoch 779/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.0694 - accuracy: 0.7348 - val_loss: 26.0237 - val_accuracy: 0.4786\n",
            "Epoch 780/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.0381 - accuracy: 0.7295 - val_loss: 26.0234 - val_accuracy: 0.5179\n",
            "Epoch 781/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.0503 - accuracy: 0.7286 - val_loss: 26.0707 - val_accuracy: 0.5000\n",
            "Epoch 782/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.0899 - accuracy: 0.7188 - val_loss: 26.1255 - val_accuracy: 0.4857\n",
            "Epoch 783/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.0732 - accuracy: 0.7143 - val_loss: 26.1225 - val_accuracy: 0.5036\n",
            "Epoch 784/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.0691 - accuracy: 0.7321 - val_loss: 26.0460 - val_accuracy: 0.5071\n",
            "Epoch 785/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.0590 - accuracy: 0.7259 - val_loss: 26.0641 - val_accuracy: 0.5179\n",
            "Epoch 786/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.0843 - accuracy: 0.7277 - val_loss: 26.0687 - val_accuracy: 0.4607\n",
            "Epoch 787/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.0675 - accuracy: 0.7214 - val_loss: 26.1056 - val_accuracy: 0.5071\n",
            "Epoch 788/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.0987 - accuracy: 0.7134 - val_loss: 26.3296 - val_accuracy: 0.4893\n",
            "Epoch 789/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.0705 - accuracy: 0.7286 - val_loss: 26.1901 - val_accuracy: 0.4857\n",
            "Epoch 790/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.0125 - accuracy: 0.7339 - val_loss: 26.1555 - val_accuracy: 0.4893\n",
            "Epoch 791/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.0494 - accuracy: 0.7312 - val_loss: 26.2144 - val_accuracy: 0.5071\n",
            "Epoch 792/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.0690 - accuracy: 0.7170 - val_loss: 26.2016 - val_accuracy: 0.4857\n",
            "Epoch 793/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.0251 - accuracy: 0.7375 - val_loss: 26.2641 - val_accuracy: 0.5071\n",
            "Epoch 794/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.0451 - accuracy: 0.7170 - val_loss: 26.2224 - val_accuracy: 0.5036\n",
            "Epoch 795/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.0310 - accuracy: 0.7411 - val_loss: 26.3326 - val_accuracy: 0.5036\n",
            "Epoch 796/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.0248 - accuracy: 0.7509 - val_loss: 26.3553 - val_accuracy: 0.4786\n",
            "Epoch 797/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.0388 - accuracy: 0.7366 - val_loss: 26.3853 - val_accuracy: 0.4964\n",
            "Epoch 798/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.0117 - accuracy: 0.7509 - val_loss: 26.4531 - val_accuracy: 0.4929\n",
            "Epoch 799/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.0334 - accuracy: 0.7429 - val_loss: 26.3388 - val_accuracy: 0.5071\n",
            "Epoch 800/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.0279 - accuracy: 0.7402 - val_loss: 26.4828 - val_accuracy: 0.5036\n",
            "Epoch 801/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.0366 - accuracy: 0.7223 - val_loss: 26.4962 - val_accuracy: 0.5071\n",
            "Epoch 802/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.0395 - accuracy: 0.7321 - val_loss: 26.4784 - val_accuracy: 0.4857\n",
            "Epoch 803/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.0126 - accuracy: 0.7437 - val_loss: 26.6274 - val_accuracy: 0.5036\n",
            "Epoch 804/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.0515 - accuracy: 0.7277 - val_loss: 26.4481 - val_accuracy: 0.4786\n",
            "Epoch 805/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.0919 - accuracy: 0.7116 - val_loss: 26.5212 - val_accuracy: 0.4964\n",
            "Epoch 806/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.0690 - accuracy: 0.7054 - val_loss: 26.4290 - val_accuracy: 0.5036\n",
            "Epoch 807/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.0968 - accuracy: 0.7179 - val_loss: 26.5117 - val_accuracy: 0.5357\n",
            "Epoch 808/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.0808 - accuracy: 0.7188 - val_loss: 26.6476 - val_accuracy: 0.5036\n",
            "Epoch 809/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.0691 - accuracy: 0.7259 - val_loss: 26.6034 - val_accuracy: 0.5107\n",
            "Epoch 810/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.0379 - accuracy: 0.7420 - val_loss: 26.5757 - val_accuracy: 0.5071\n",
            "Epoch 811/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.0406 - accuracy: 0.7223 - val_loss: 26.7572 - val_accuracy: 0.4964\n",
            "Epoch 812/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.0641 - accuracy: 0.7125 - val_loss: 26.6424 - val_accuracy: 0.4964\n",
            "Epoch 813/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.0616 - accuracy: 0.7188 - val_loss: 26.6061 - val_accuracy: 0.4929\n",
            "Epoch 814/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.0152 - accuracy: 0.7402 - val_loss: 26.5605 - val_accuracy: 0.5179\n",
            "Epoch 815/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.0115 - accuracy: 0.7500 - val_loss: 26.6069 - val_accuracy: 0.4964\n",
            "Epoch 816/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.0399 - accuracy: 0.7393 - val_loss: 26.6066 - val_accuracy: 0.5179\n",
            "Epoch 817/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.9933 - accuracy: 0.7437 - val_loss: 26.7260 - val_accuracy: 0.5036\n",
            "Epoch 818/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.9908 - accuracy: 0.7518 - val_loss: 26.8430 - val_accuracy: 0.4857\n",
            "Epoch 819/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.0001 - accuracy: 0.7500 - val_loss: 26.6480 - val_accuracy: 0.4857\n",
            "Epoch 820/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.0069 - accuracy: 0.7339 - val_loss: 26.8078 - val_accuracy: 0.5286\n",
            "Epoch 821/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.0004 - accuracy: 0.7357 - val_loss: 26.7828 - val_accuracy: 0.4857\n",
            "Epoch 822/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.0009 - accuracy: 0.7446 - val_loss: 26.7412 - val_accuracy: 0.5179\n",
            "Epoch 823/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.9904 - accuracy: 0.7393 - val_loss: 26.8542 - val_accuracy: 0.4929\n",
            "Epoch 824/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.0150 - accuracy: 0.7366 - val_loss: 26.6943 - val_accuracy: 0.5036\n",
            "Epoch 825/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.0177 - accuracy: 0.7437 - val_loss: 26.9025 - val_accuracy: 0.4929\n",
            "Epoch 826/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.9859 - accuracy: 0.7473 - val_loss: 27.0085 - val_accuracy: 0.5179\n",
            "Epoch 827/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.0174 - accuracy: 0.7384 - val_loss: 26.8571 - val_accuracy: 0.4750\n",
            "Epoch 828/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.0345 - accuracy: 0.7152 - val_loss: 26.9220 - val_accuracy: 0.4821\n",
            "Epoch 829/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.0271 - accuracy: 0.7482 - val_loss: 26.8930 - val_accuracy: 0.5071\n",
            "Epoch 830/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.9871 - accuracy: 0.7545 - val_loss: 26.8584 - val_accuracy: 0.5036\n",
            "Epoch 831/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.9570 - accuracy: 0.7518 - val_loss: 26.9433 - val_accuracy: 0.5071\n",
            "Epoch 832/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.0016 - accuracy: 0.7500 - val_loss: 27.0034 - val_accuracy: 0.5107\n",
            "Epoch 833/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.0243 - accuracy: 0.7455 - val_loss: 27.1709 - val_accuracy: 0.5000\n",
            "Epoch 834/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.0002 - accuracy: 0.7384 - val_loss: 26.9955 - val_accuracy: 0.5036\n",
            "Epoch 835/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.9957 - accuracy: 0.7375 - val_loss: 27.1154 - val_accuracy: 0.4929\n",
            "Epoch 836/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.0148 - accuracy: 0.7473 - val_loss: 27.1078 - val_accuracy: 0.4929\n",
            "Epoch 837/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.0179 - accuracy: 0.7304 - val_loss: 27.0205 - val_accuracy: 0.4964\n",
            "Epoch 838/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.9872 - accuracy: 0.7500 - val_loss: 27.0741 - val_accuracy: 0.5179\n",
            "Epoch 839/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.9834 - accuracy: 0.7420 - val_loss: 27.3008 - val_accuracy: 0.5214\n",
            "Epoch 840/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.0076 - accuracy: 0.7393 - val_loss: 27.0479 - val_accuracy: 0.5036\n",
            "Epoch 841/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.0271 - accuracy: 0.7321 - val_loss: 27.2073 - val_accuracy: 0.5179\n",
            "Epoch 842/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.0038 - accuracy: 0.7455 - val_loss: 27.1898 - val_accuracy: 0.5000\n",
            "Epoch 843/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.0111 - accuracy: 0.7402 - val_loss: 27.5130 - val_accuracy: 0.4857\n",
            "Epoch 844/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.1127 - accuracy: 0.7045 - val_loss: 27.1014 - val_accuracy: 0.5107\n",
            "Epoch 845/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.0388 - accuracy: 0.7259 - val_loss: 27.2431 - val_accuracy: 0.4964\n",
            "Epoch 846/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.9788 - accuracy: 0.7527 - val_loss: 27.1362 - val_accuracy: 0.5429\n",
            "Epoch 847/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.9562 - accuracy: 0.7455 - val_loss: 27.1484 - val_accuracy: 0.5036\n",
            "Epoch 848/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.9567 - accuracy: 0.7732 - val_loss: 27.1859 - val_accuracy: 0.5071\n",
            "Epoch 849/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.9655 - accuracy: 0.7589 - val_loss: 27.2267 - val_accuracy: 0.5321\n",
            "Epoch 850/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.9742 - accuracy: 0.7518 - val_loss: 27.3065 - val_accuracy: 0.5143\n",
            "Epoch 851/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.9980 - accuracy: 0.7500 - val_loss: 27.2492 - val_accuracy: 0.5143\n",
            "Epoch 852/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.0178 - accuracy: 0.7455 - val_loss: 27.3476 - val_accuracy: 0.5107\n",
            "Epoch 853/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.9715 - accuracy: 0.7473 - val_loss: 27.3260 - val_accuracy: 0.5179\n",
            "Epoch 854/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.0070 - accuracy: 0.7339 - val_loss: 27.3745 - val_accuracy: 0.5214\n",
            "Epoch 855/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.0228 - accuracy: 0.7420 - val_loss: 27.2931 - val_accuracy: 0.5036\n",
            "Epoch 856/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.0187 - accuracy: 0.7446 - val_loss: 27.2857 - val_accuracy: 0.5500\n",
            "Epoch 857/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.9499 - accuracy: 0.7768 - val_loss: 27.4678 - val_accuracy: 0.5036\n",
            "Epoch 858/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.9433 - accuracy: 0.7643 - val_loss: 27.5890 - val_accuracy: 0.5000\n",
            "Epoch 859/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.9776 - accuracy: 0.7527 - val_loss: 27.5064 - val_accuracy: 0.5179\n",
            "Epoch 860/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.9709 - accuracy: 0.7455 - val_loss: 27.3918 - val_accuracy: 0.5179\n",
            "Epoch 861/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.9642 - accuracy: 0.7634 - val_loss: 27.5103 - val_accuracy: 0.5036\n",
            "Epoch 862/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.9813 - accuracy: 0.7455 - val_loss: 27.4484 - val_accuracy: 0.5000\n",
            "Epoch 863/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.9612 - accuracy: 0.7536 - val_loss: 27.3667 - val_accuracy: 0.5036\n",
            "Epoch 864/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.9643 - accuracy: 0.7607 - val_loss: 27.6672 - val_accuracy: 0.5143\n",
            "Epoch 865/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.9845 - accuracy: 0.7437 - val_loss: 27.6283 - val_accuracy: 0.5071\n",
            "Epoch 866/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.0279 - accuracy: 0.7179 - val_loss: 27.4860 - val_accuracy: 0.5357\n",
            "Epoch 867/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.9835 - accuracy: 0.7598 - val_loss: 27.5600 - val_accuracy: 0.5214\n",
            "Epoch 868/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.9665 - accuracy: 0.7545 - val_loss: 27.7454 - val_accuracy: 0.5357\n",
            "Epoch 869/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.9450 - accuracy: 0.7723 - val_loss: 27.6192 - val_accuracy: 0.5071\n",
            "Epoch 870/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.9308 - accuracy: 0.7723 - val_loss: 27.6475 - val_accuracy: 0.5143\n",
            "Epoch 871/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.9757 - accuracy: 0.7446 - val_loss: 27.5846 - val_accuracy: 0.5321\n",
            "Epoch 872/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.9484 - accuracy: 0.7491 - val_loss: 27.5071 - val_accuracy: 0.5214\n",
            "Epoch 873/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.9325 - accuracy: 0.7563 - val_loss: 27.6079 - val_accuracy: 0.5179\n",
            "Epoch 874/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.9322 - accuracy: 0.7589 - val_loss: 27.5976 - val_accuracy: 0.5214\n",
            "Epoch 875/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.9276 - accuracy: 0.7598 - val_loss: 27.6902 - val_accuracy: 0.5357\n",
            "Epoch 876/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.9321 - accuracy: 0.7545 - val_loss: 27.5858 - val_accuracy: 0.4821\n",
            "Epoch 877/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.0274 - accuracy: 0.7321 - val_loss: 27.7159 - val_accuracy: 0.4893\n",
            "Epoch 878/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.9931 - accuracy: 0.7366 - val_loss: 27.7288 - val_accuracy: 0.5321\n",
            "Epoch 879/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.9295 - accuracy: 0.7634 - val_loss: 27.8300 - val_accuracy: 0.5357\n",
            "Epoch 880/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.9450 - accuracy: 0.7482 - val_loss: 27.7413 - val_accuracy: 0.5393\n",
            "Epoch 881/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.9198 - accuracy: 0.7563 - val_loss: 27.7690 - val_accuracy: 0.5357\n",
            "Epoch 882/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.9316 - accuracy: 0.7589 - val_loss: 27.7712 - val_accuracy: 0.5464\n",
            "Epoch 883/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.9183 - accuracy: 0.7536 - val_loss: 27.7595 - val_accuracy: 0.5286\n",
            "Epoch 884/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.9657 - accuracy: 0.7500 - val_loss: 27.9217 - val_accuracy: 0.5429\n",
            "Epoch 885/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.9465 - accuracy: 0.7652 - val_loss: 28.0649 - val_accuracy: 0.5000\n",
            "Epoch 886/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.0072 - accuracy: 0.7241 - val_loss: 27.9607 - val_accuracy: 0.5250\n",
            "Epoch 887/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.0385 - accuracy: 0.7277 - val_loss: 27.9342 - val_accuracy: 0.4821\n",
            "Epoch 888/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.9631 - accuracy: 0.7429 - val_loss: 27.9819 - val_accuracy: 0.5321\n",
            "Epoch 889/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.0416 - accuracy: 0.7205 - val_loss: 27.9321 - val_accuracy: 0.5036\n",
            "Epoch 890/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.0366 - accuracy: 0.7125 - val_loss: 28.0434 - val_accuracy: 0.5286\n",
            "Epoch 891/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.9495 - accuracy: 0.7518 - val_loss: 27.9189 - val_accuracy: 0.5321\n",
            "Epoch 892/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.9420 - accuracy: 0.7420 - val_loss: 27.9695 - val_accuracy: 0.5071\n",
            "Epoch 893/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.9502 - accuracy: 0.7437 - val_loss: 27.9446 - val_accuracy: 0.5214\n",
            "Epoch 894/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.9513 - accuracy: 0.7607 - val_loss: 28.0187 - val_accuracy: 0.5107\n",
            "Epoch 895/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.9607 - accuracy: 0.7420 - val_loss: 27.9916 - val_accuracy: 0.5286\n",
            "Epoch 896/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.9444 - accuracy: 0.7518 - val_loss: 28.0476 - val_accuracy: 0.5357\n",
            "Epoch 897/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.9547 - accuracy: 0.7411 - val_loss: 27.9499 - val_accuracy: 0.5250\n",
            "Epoch 898/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.9409 - accuracy: 0.7527 - val_loss: 28.1031 - val_accuracy: 0.5250\n",
            "Epoch 899/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.9428 - accuracy: 0.7536 - val_loss: 28.0128 - val_accuracy: 0.5429\n",
            "Epoch 900/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.9207 - accuracy: 0.7848 - val_loss: 28.0702 - val_accuracy: 0.5036\n",
            "Epoch 901/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.9113 - accuracy: 0.7589 - val_loss: 28.0568 - val_accuracy: 0.5500\n",
            "Epoch 902/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.8955 - accuracy: 0.7777 - val_loss: 27.9864 - val_accuracy: 0.5429\n",
            "Epoch 903/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.8639 - accuracy: 0.7688 - val_loss: 28.0760 - val_accuracy: 0.5286\n",
            "Epoch 904/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.8856 - accuracy: 0.7875 - val_loss: 28.1456 - val_accuracy: 0.5143\n",
            "Epoch 905/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.8966 - accuracy: 0.7804 - val_loss: 28.2120 - val_accuracy: 0.5214\n",
            "Epoch 906/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.9070 - accuracy: 0.7652 - val_loss: 28.2169 - val_accuracy: 0.5357\n",
            "Epoch 907/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.9087 - accuracy: 0.7830 - val_loss: 28.1708 - val_accuracy: 0.5321\n",
            "Epoch 908/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.9163 - accuracy: 0.7741 - val_loss: 28.1890 - val_accuracy: 0.5429\n",
            "Epoch 909/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.9383 - accuracy: 0.7643 - val_loss: 28.1550 - val_accuracy: 0.5250\n",
            "Epoch 910/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.9218 - accuracy: 0.7643 - val_loss: 28.1895 - val_accuracy: 0.5500\n",
            "Epoch 911/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.9055 - accuracy: 0.7750 - val_loss: 28.2133 - val_accuracy: 0.5143\n",
            "Epoch 912/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.8975 - accuracy: 0.7679 - val_loss: 28.1942 - val_accuracy: 0.5357\n",
            "Epoch 913/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.9353 - accuracy: 0.7589 - val_loss: 28.4039 - val_accuracy: 0.5286\n",
            "Epoch 914/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.9177 - accuracy: 0.7679 - val_loss: 28.3915 - val_accuracy: 0.5429\n",
            "Epoch 915/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.9235 - accuracy: 0.7643 - val_loss: 28.4095 - val_accuracy: 0.5321\n",
            "Epoch 916/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.8989 - accuracy: 0.7643 - val_loss: 28.3388 - val_accuracy: 0.5321\n",
            "Epoch 917/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.9160 - accuracy: 0.7661 - val_loss: 28.4670 - val_accuracy: 0.4929\n",
            "Epoch 918/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.9539 - accuracy: 0.7384 - val_loss: 28.2388 - val_accuracy: 0.5607\n",
            "Epoch 919/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.9291 - accuracy: 0.7696 - val_loss: 28.4862 - val_accuracy: 0.5500\n",
            "Epoch 920/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.9152 - accuracy: 0.7571 - val_loss: 28.5229 - val_accuracy: 0.5036\n",
            "Epoch 921/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.9244 - accuracy: 0.7661 - val_loss: 28.5378 - val_accuracy: 0.5321\n",
            "Epoch 922/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.8963 - accuracy: 0.7732 - val_loss: 28.3922 - val_accuracy: 0.5607\n",
            "Epoch 923/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.9154 - accuracy: 0.7661 - val_loss: 28.4370 - val_accuracy: 0.5286\n",
            "Epoch 924/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.9323 - accuracy: 0.7509 - val_loss: 28.3866 - val_accuracy: 0.5321\n",
            "Epoch 925/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.9286 - accuracy: 0.7571 - val_loss: 28.5194 - val_accuracy: 0.5500\n",
            "Epoch 926/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.9251 - accuracy: 0.7563 - val_loss: 28.5522 - val_accuracy: 0.5250\n",
            "Epoch 927/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.9221 - accuracy: 0.7518 - val_loss: 28.5315 - val_accuracy: 0.5321\n",
            "Epoch 928/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.8895 - accuracy: 0.7696 - val_loss: 28.6107 - val_accuracy: 0.5500\n",
            "Epoch 929/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.9014 - accuracy: 0.7643 - val_loss: 28.4719 - val_accuracy: 0.5357\n",
            "Epoch 930/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.9183 - accuracy: 0.7598 - val_loss: 28.5407 - val_accuracy: 0.5250\n",
            "Epoch 931/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.8935 - accuracy: 0.7607 - val_loss: 28.5326 - val_accuracy: 0.5500\n",
            "Epoch 932/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.8895 - accuracy: 0.7848 - val_loss: 28.6195 - val_accuracy: 0.5429\n",
            "Epoch 933/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.9197 - accuracy: 0.7571 - val_loss: 28.7434 - val_accuracy: 0.5250\n",
            "Epoch 934/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.9879 - accuracy: 0.7339 - val_loss: 28.7365 - val_accuracy: 0.5321\n",
            "Epoch 935/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.9568 - accuracy: 0.7536 - val_loss: 28.7296 - val_accuracy: 0.5321\n",
            "Epoch 936/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.9541 - accuracy: 0.7464 - val_loss: 28.5629 - val_accuracy: 0.5286\n",
            "Epoch 937/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.9053 - accuracy: 0.7661 - val_loss: 28.6503 - val_accuracy: 0.5500\n",
            "Epoch 938/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.8565 - accuracy: 0.7884 - val_loss: 28.5786 - val_accuracy: 0.5357\n",
            "Epoch 939/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.8689 - accuracy: 0.7705 - val_loss: 28.7129 - val_accuracy: 0.5214\n",
            "Epoch 940/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.8756 - accuracy: 0.7866 - val_loss: 28.6642 - val_accuracy: 0.5107\n",
            "Epoch 941/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.8702 - accuracy: 0.7661 - val_loss: 28.7318 - val_accuracy: 0.5321\n",
            "Epoch 942/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.8743 - accuracy: 0.7759 - val_loss: 28.7685 - val_accuracy: 0.5464\n",
            "Epoch 943/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.9022 - accuracy: 0.7786 - val_loss: 28.7289 - val_accuracy: 0.5357\n",
            "Epoch 944/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.8939 - accuracy: 0.7714 - val_loss: 28.8603 - val_accuracy: 0.5179\n",
            "Epoch 945/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.9130 - accuracy: 0.7634 - val_loss: 28.7949 - val_accuracy: 0.5357\n",
            "Epoch 946/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.9034 - accuracy: 0.7679 - val_loss: 28.7131 - val_accuracy: 0.5179\n",
            "Epoch 947/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.9245 - accuracy: 0.7482 - val_loss: 28.6205 - val_accuracy: 0.5429\n",
            "Epoch 948/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.8654 - accuracy: 0.7616 - val_loss: 28.7772 - val_accuracy: 0.5500\n",
            "Epoch 949/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.8881 - accuracy: 0.7759 - val_loss: 28.8099 - val_accuracy: 0.5536\n",
            "Epoch 950/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.9127 - accuracy: 0.7580 - val_loss: 28.8299 - val_accuracy: 0.5429\n",
            "Epoch 951/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.9119 - accuracy: 0.7670 - val_loss: 28.7516 - val_accuracy: 0.5643\n",
            "Epoch 952/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.8779 - accuracy: 0.7777 - val_loss: 28.8984 - val_accuracy: 0.5286\n",
            "Epoch 953/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.8562 - accuracy: 0.7679 - val_loss: 28.8009 - val_accuracy: 0.5321\n",
            "Epoch 954/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.8585 - accuracy: 0.7839 - val_loss: 28.8540 - val_accuracy: 0.5607\n",
            "Epoch 955/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.8587 - accuracy: 0.7768 - val_loss: 28.9064 - val_accuracy: 0.5643\n",
            "Epoch 956/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.8533 - accuracy: 0.7839 - val_loss: 28.8752 - val_accuracy: 0.5321\n",
            "Epoch 957/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.8524 - accuracy: 0.7661 - val_loss: 29.0047 - val_accuracy: 0.5607\n",
            "Epoch 958/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.8651 - accuracy: 0.7795 - val_loss: 28.7902 - val_accuracy: 0.5286\n",
            "Epoch 959/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.8473 - accuracy: 0.7777 - val_loss: 28.8748 - val_accuracy: 0.5607\n",
            "Epoch 960/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.8608 - accuracy: 0.7732 - val_loss: 29.0204 - val_accuracy: 0.5607\n",
            "Epoch 961/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.8943 - accuracy: 0.7830 - val_loss: 29.0328 - val_accuracy: 0.5750\n",
            "Epoch 962/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.9031 - accuracy: 0.7634 - val_loss: 29.0195 - val_accuracy: 0.5071\n",
            "Epoch 963/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.8723 - accuracy: 0.7652 - val_loss: 29.0247 - val_accuracy: 0.5286\n",
            "Epoch 964/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.8744 - accuracy: 0.7750 - val_loss: 29.0152 - val_accuracy: 0.5464\n",
            "Epoch 965/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.8771 - accuracy: 0.7795 - val_loss: 29.1532 - val_accuracy: 0.5393\n",
            "Epoch 966/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.8780 - accuracy: 0.7777 - val_loss: 29.0061 - val_accuracy: 0.5429\n",
            "Epoch 967/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.8927 - accuracy: 0.7634 - val_loss: 29.1520 - val_accuracy: 0.5429\n",
            "Epoch 968/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.8583 - accuracy: 0.7804 - val_loss: 29.0202 - val_accuracy: 0.5464\n",
            "Epoch 969/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.8382 - accuracy: 0.7812 - val_loss: 29.0724 - val_accuracy: 0.5500\n",
            "Epoch 970/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.8484 - accuracy: 0.7937 - val_loss: 29.0410 - val_accuracy: 0.5714\n",
            "Epoch 971/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.8584 - accuracy: 0.7812 - val_loss: 29.0340 - val_accuracy: 0.5536\n",
            "Epoch 972/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.8545 - accuracy: 0.7866 - val_loss: 29.1706 - val_accuracy: 0.5179\n",
            "Epoch 973/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.8812 - accuracy: 0.7634 - val_loss: 29.1084 - val_accuracy: 0.5607\n",
            "Epoch 974/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.8865 - accuracy: 0.7580 - val_loss: 29.2271 - val_accuracy: 0.5464\n",
            "Epoch 975/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.8590 - accuracy: 0.7786 - val_loss: 29.3648 - val_accuracy: 0.5607\n",
            "Epoch 976/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.9019 - accuracy: 0.7634 - val_loss: 29.2638 - val_accuracy: 0.5464\n",
            "Epoch 977/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.8456 - accuracy: 0.7795 - val_loss: 29.1867 - val_accuracy: 0.5500\n",
            "Epoch 978/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.8522 - accuracy: 0.7839 - val_loss: 29.1927 - val_accuracy: 0.5500\n",
            "Epoch 979/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.8360 - accuracy: 0.7857 - val_loss: 29.1982 - val_accuracy: 0.5786\n",
            "Epoch 980/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.9123 - accuracy: 0.7625 - val_loss: 29.2143 - val_accuracy: 0.5607\n",
            "Epoch 981/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.8698 - accuracy: 0.7670 - val_loss: 29.6698 - val_accuracy: 0.5393\n",
            "Epoch 982/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.8850 - accuracy: 0.7563 - val_loss: 29.3373 - val_accuracy: 0.5679\n",
            "Epoch 983/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.8624 - accuracy: 0.7875 - val_loss: 29.3130 - val_accuracy: 0.5536\n",
            "Epoch 984/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.8917 - accuracy: 0.7634 - val_loss: 29.2668 - val_accuracy: 0.5286\n",
            "Epoch 985/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.8737 - accuracy: 0.7902 - val_loss: 29.4845 - val_accuracy: 0.5500\n",
            "Epoch 986/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.8105 - accuracy: 0.7929 - val_loss: 29.3100 - val_accuracy: 0.5286\n",
            "Epoch 987/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.8328 - accuracy: 0.7786 - val_loss: 29.2974 - val_accuracy: 0.5893\n",
            "Epoch 988/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.8391 - accuracy: 0.7893 - val_loss: 29.5086 - val_accuracy: 0.5500\n",
            "Epoch 989/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.8270 - accuracy: 0.7893 - val_loss: 29.4765 - val_accuracy: 0.5429\n",
            "Epoch 990/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.8411 - accuracy: 0.7786 - val_loss: 29.4560 - val_accuracy: 0.5464\n",
            "Epoch 991/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.8672 - accuracy: 0.7768 - val_loss: 29.5945 - val_accuracy: 0.5500\n",
            "Epoch 992/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.8159 - accuracy: 0.7866 - val_loss: 29.3998 - val_accuracy: 0.5429\n",
            "Epoch 993/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.8299 - accuracy: 0.7946 - val_loss: 29.6664 - val_accuracy: 0.5214\n",
            "Epoch 994/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.8611 - accuracy: 0.7679 - val_loss: 29.7173 - val_accuracy: 0.5357\n",
            "Epoch 995/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.8565 - accuracy: 0.7804 - val_loss: 29.5471 - val_accuracy: 0.5250\n",
            "Epoch 996/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.8886 - accuracy: 0.7688 - val_loss: 29.6239 - val_accuracy: 0.5821\n",
            "Epoch 997/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.8755 - accuracy: 0.7750 - val_loss: 29.5623 - val_accuracy: 0.5464\n",
            "Epoch 998/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.8598 - accuracy: 0.7777 - val_loss: 29.4967 - val_accuracy: 0.5643\n",
            "Epoch 999/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.8488 - accuracy: 0.7839 - val_loss: 29.6691 - val_accuracy: 0.5571\n",
            "Epoch 1000/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.8760 - accuracy: 0.7679 - val_loss: 29.6770 - val_accuracy: 0.5000\n",
            "Epoch 1001/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.8572 - accuracy: 0.7598 - val_loss: 29.8040 - val_accuracy: 0.5179\n",
            "Epoch 1002/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.8680 - accuracy: 0.7777 - val_loss: 29.8629 - val_accuracy: 0.5500\n",
            "Epoch 1003/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.8184 - accuracy: 0.7982 - val_loss: 29.7343 - val_accuracy: 0.5607\n",
            "Epoch 1004/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.8244 - accuracy: 0.7920 - val_loss: 29.5807 - val_accuracy: 0.5679\n",
            "Epoch 1005/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.8062 - accuracy: 0.8000 - val_loss: 29.6381 - val_accuracy: 0.5607\n",
            "Epoch 1006/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.8190 - accuracy: 0.7893 - val_loss: 29.6647 - val_accuracy: 0.5571\n",
            "Epoch 1007/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.8430 - accuracy: 0.7732 - val_loss: 29.8583 - val_accuracy: 0.5321\n",
            "Epoch 1008/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.8602 - accuracy: 0.7750 - val_loss: 29.6679 - val_accuracy: 0.5536\n",
            "Epoch 1009/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.8400 - accuracy: 0.7804 - val_loss: 29.7869 - val_accuracy: 0.5536\n",
            "Epoch 1010/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.8608 - accuracy: 0.7679 - val_loss: 29.7052 - val_accuracy: 0.5607\n",
            "Epoch 1011/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.8696 - accuracy: 0.7661 - val_loss: 29.6765 - val_accuracy: 0.5679\n",
            "Epoch 1012/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.8961 - accuracy: 0.7652 - val_loss: 29.9378 - val_accuracy: 0.5643\n",
            "Epoch 1013/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.8681 - accuracy: 0.7768 - val_loss: 29.8291 - val_accuracy: 0.5857\n",
            "Epoch 1014/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.8490 - accuracy: 0.7804 - val_loss: 29.8355 - val_accuracy: 0.5214\n",
            "Epoch 1015/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.8678 - accuracy: 0.7768 - val_loss: 29.9424 - val_accuracy: 0.5393\n",
            "Epoch 1016/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.9616 - accuracy: 0.7509 - val_loss: 29.7939 - val_accuracy: 0.5321\n",
            "Epoch 1017/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.9081 - accuracy: 0.7500 - val_loss: 29.9417 - val_accuracy: 0.5571\n",
            "Epoch 1018/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.8775 - accuracy: 0.7759 - val_loss: 30.0869 - val_accuracy: 0.5714\n",
            "Epoch 1019/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.8672 - accuracy: 0.7705 - val_loss: 29.8953 - val_accuracy: 0.5464\n",
            "Epoch 1020/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.8320 - accuracy: 0.7821 - val_loss: 29.8733 - val_accuracy: 0.5607\n",
            "Epoch 1021/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.8428 - accuracy: 0.7714 - val_loss: 29.9087 - val_accuracy: 0.5964\n",
            "Epoch 1022/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.8167 - accuracy: 0.7902 - val_loss: 29.8572 - val_accuracy: 0.5536\n",
            "Epoch 1023/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.8014 - accuracy: 0.7875 - val_loss: 29.7362 - val_accuracy: 0.5643\n",
            "Epoch 1024/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.7890 - accuracy: 0.7946 - val_loss: 29.8328 - val_accuracy: 0.5643\n",
            "Epoch 1025/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.8159 - accuracy: 0.7893 - val_loss: 29.9009 - val_accuracy: 0.5429\n",
            "Epoch 1026/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.8227 - accuracy: 0.7911 - val_loss: 30.0977 - val_accuracy: 0.5357\n",
            "Epoch 1027/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.8236 - accuracy: 0.7857 - val_loss: 29.9368 - val_accuracy: 0.5464\n",
            "Epoch 1028/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.8535 - accuracy: 0.7741 - val_loss: 29.9143 - val_accuracy: 0.5679\n",
            "Epoch 1029/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.8482 - accuracy: 0.7714 - val_loss: 30.0963 - val_accuracy: 0.5321\n",
            "Epoch 1030/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.8547 - accuracy: 0.7625 - val_loss: 30.1399 - val_accuracy: 0.5821\n",
            "Epoch 1031/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.8195 - accuracy: 0.7929 - val_loss: 30.0610 - val_accuracy: 0.5429\n",
            "Epoch 1032/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.8461 - accuracy: 0.7839 - val_loss: 30.0750 - val_accuracy: 0.5536\n",
            "Epoch 1033/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.8341 - accuracy: 0.7875 - val_loss: 30.0556 - val_accuracy: 0.5464\n",
            "Epoch 1034/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.7951 - accuracy: 0.7973 - val_loss: 29.9813 - val_accuracy: 0.5643\n",
            "Epoch 1035/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.7923 - accuracy: 0.7964 - val_loss: 30.0726 - val_accuracy: 0.5429\n",
            "Epoch 1036/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.7935 - accuracy: 0.8000 - val_loss: 30.0732 - val_accuracy: 0.5750\n",
            "Epoch 1037/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.7912 - accuracy: 0.7857 - val_loss: 30.0912 - val_accuracy: 0.5714\n",
            "Epoch 1038/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.8078 - accuracy: 0.7973 - val_loss: 30.0304 - val_accuracy: 0.5786\n",
            "Epoch 1039/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.7511 - accuracy: 0.8223 - val_loss: 30.1609 - val_accuracy: 0.6000\n",
            "Epoch 1040/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.7873 - accuracy: 0.8116 - val_loss: 30.1686 - val_accuracy: 0.5821\n",
            "Epoch 1041/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.7959 - accuracy: 0.7911 - val_loss: 30.1833 - val_accuracy: 0.5571\n",
            "Epoch 1042/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.8352 - accuracy: 0.7795 - val_loss: 30.2713 - val_accuracy: 0.5679\n",
            "Epoch 1043/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.8622 - accuracy: 0.7768 - val_loss: 30.4131 - val_accuracy: 0.5214\n",
            "Epoch 1044/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.9292 - accuracy: 0.7473 - val_loss: 30.3102 - val_accuracy: 0.5071\n",
            "Epoch 1045/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.9232 - accuracy: 0.7375 - val_loss: 30.4492 - val_accuracy: 0.5393\n",
            "Epoch 1046/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.9154 - accuracy: 0.7616 - val_loss: 30.4320 - val_accuracy: 0.5286\n",
            "Epoch 1047/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.8696 - accuracy: 0.7786 - val_loss: 30.2763 - val_accuracy: 0.5286\n",
            "Epoch 1048/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.8548 - accuracy: 0.7688 - val_loss: 30.1273 - val_accuracy: 0.5643\n",
            "Epoch 1049/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7937 - accuracy: 0.8143 - val_loss: 30.1817 - val_accuracy: 0.6071\n",
            "Epoch 1050/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.7805 - accuracy: 0.8000 - val_loss: 30.2436 - val_accuracy: 0.5643\n",
            "Epoch 1051/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.7828 - accuracy: 0.8098 - val_loss: 30.3303 - val_accuracy: 0.5821\n",
            "Epoch 1052/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.7847 - accuracy: 0.7973 - val_loss: 30.3575 - val_accuracy: 0.5321\n",
            "Epoch 1053/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.8265 - accuracy: 0.7866 - val_loss: 30.3821 - val_accuracy: 0.5714\n",
            "Epoch 1054/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.7894 - accuracy: 0.8125 - val_loss: 30.3553 - val_accuracy: 0.5679\n",
            "Epoch 1055/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.8122 - accuracy: 0.7973 - val_loss: 30.3632 - val_accuracy: 0.5643\n",
            "Epoch 1056/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.8031 - accuracy: 0.7946 - val_loss: 30.3180 - val_accuracy: 0.5857\n",
            "Epoch 1057/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.7784 - accuracy: 0.8143 - val_loss: 30.3135 - val_accuracy: 0.5750\n",
            "Epoch 1058/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.8115 - accuracy: 0.7812 - val_loss: 30.4846 - val_accuracy: 0.5964\n",
            "Epoch 1059/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.7977 - accuracy: 0.8036 - val_loss: 30.3915 - val_accuracy: 0.5929\n",
            "Epoch 1060/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.7669 - accuracy: 0.8062 - val_loss: 30.4111 - val_accuracy: 0.5821\n",
            "Epoch 1061/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7534 - accuracy: 0.8027 - val_loss: 30.3654 - val_accuracy: 0.5750\n",
            "Epoch 1062/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.7626 - accuracy: 0.7982 - val_loss: 30.4103 - val_accuracy: 0.5607\n",
            "Epoch 1063/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7745 - accuracy: 0.8098 - val_loss: 30.4592 - val_accuracy: 0.5714\n",
            "Epoch 1064/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.7788 - accuracy: 0.7964 - val_loss: 30.5903 - val_accuracy: 0.5571\n",
            "Epoch 1065/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7702 - accuracy: 0.8116 - val_loss: 30.6427 - val_accuracy: 0.5857\n",
            "Epoch 1066/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.8500 - accuracy: 0.7884 - val_loss: 30.5555 - val_accuracy: 0.5821\n",
            "Epoch 1067/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.8228 - accuracy: 0.7812 - val_loss: 30.5717 - val_accuracy: 0.5429\n",
            "Epoch 1068/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.8262 - accuracy: 0.7902 - val_loss: 30.5993 - val_accuracy: 0.5821\n",
            "Epoch 1069/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.8125 - accuracy: 0.7866 - val_loss: 30.7297 - val_accuracy: 0.5536\n",
            "Epoch 1070/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7859 - accuracy: 0.7937 - val_loss: 30.5390 - val_accuracy: 0.5643\n",
            "Epoch 1071/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.7671 - accuracy: 0.8143 - val_loss: 30.7537 - val_accuracy: 0.5464\n",
            "Epoch 1072/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.7816 - accuracy: 0.7866 - val_loss: 30.5660 - val_accuracy: 0.5750\n",
            "Epoch 1073/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.7860 - accuracy: 0.7884 - val_loss: 30.6789 - val_accuracy: 0.5643\n",
            "Epoch 1074/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.7995 - accuracy: 0.7857 - val_loss: 30.6441 - val_accuracy: 0.5714\n",
            "Epoch 1075/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.7618 - accuracy: 0.8018 - val_loss: 30.6274 - val_accuracy: 0.5857\n",
            "Epoch 1076/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.7388 - accuracy: 0.8045 - val_loss: 30.6660 - val_accuracy: 0.5786\n",
            "Epoch 1077/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.7312 - accuracy: 0.8232 - val_loss: 30.5691 - val_accuracy: 0.5821\n",
            "Epoch 1078/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.7595 - accuracy: 0.8089 - val_loss: 30.7257 - val_accuracy: 0.5607\n",
            "Epoch 1079/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.7443 - accuracy: 0.8018 - val_loss: 30.7395 - val_accuracy: 0.5750\n",
            "Epoch 1080/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.7834 - accuracy: 0.8000 - val_loss: 30.8380 - val_accuracy: 0.5929\n",
            "Epoch 1081/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.7909 - accuracy: 0.7955 - val_loss: 30.8901 - val_accuracy: 0.5786\n",
            "Epoch 1082/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7657 - accuracy: 0.8071 - val_loss: 30.8072 - val_accuracy: 0.5679\n",
            "Epoch 1083/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.7799 - accuracy: 0.7857 - val_loss: 30.9449 - val_accuracy: 0.5679\n",
            "Epoch 1084/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.7638 - accuracy: 0.8241 - val_loss: 30.8338 - val_accuracy: 0.5929\n",
            "Epoch 1085/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7778 - accuracy: 0.7848 - val_loss: 30.9170 - val_accuracy: 0.5536\n",
            "Epoch 1086/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.7743 - accuracy: 0.7991 - val_loss: 30.9688 - val_accuracy: 0.5964\n",
            "Epoch 1087/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.7360 - accuracy: 0.8054 - val_loss: 30.8424 - val_accuracy: 0.5571\n",
            "Epoch 1088/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.7993 - accuracy: 0.8018 - val_loss: 31.2302 - val_accuracy: 0.5393\n",
            "Epoch 1089/2000\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.8838 - accuracy: 0.7768 - val_loss: 31.1021 - val_accuracy: 0.5571\n",
            "Epoch 1090/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.8228 - accuracy: 0.7741 - val_loss: 30.8267 - val_accuracy: 0.5643\n",
            "Epoch 1091/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.8784 - accuracy: 0.7857 - val_loss: 31.1698 - val_accuracy: 0.6036\n",
            "Epoch 1092/2000\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.8184 - accuracy: 0.7812 - val_loss: 30.9759 - val_accuracy: 0.5571\n",
            "Epoch 1093/2000\n",
            "21/23 [==========================>...] - ETA: 0s - loss: 0.8296 - accuracy: 0.7886"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ySRs51vcPIJX"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs_range = range(epochs)\n",
        "plt.figure(figsize=(8,5))\n",
        "plt.subplot(1,2,1)\n",
        "plt.plot(epochs_range, acc, label='train accuracy')\n",
        "plt.plot(epochs_range, val_acc, label='validatoin accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "plt.plot(epochs_range, loss, label='train loss')\n",
        "plt.plot(epochs_range, val_loss, label='validatoin loss')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('training and Validation Loss')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OjIwFhpdP_M7"
      },
      "source": [
        "test_true_labels[:10], test_preds[:10]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QnBAT76_R8yz"
      },
      "source": [
        "n, bins, patches = plt.hist(loss,30, density=True, facecolor='g', alpha=0.75)\n",
        "plt.title('Histogram of Entropy Loss')\n",
        "plt.xlabel('Entropy Loss')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LuBdzBr44AX4"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w1oealmO35TY"
      },
      "source": [
        "Here it seems the model is performing little better on validation data as well on the test data. In the avobe cell we see the model predicted modulus valued vs the true modulus value for 10 example integers.\n",
        "\n",
        "Here one thing to notice, even though the loss was increasing the accuracy was increasing as well. This is because of the entropy loss and accuracy are not inversely corellate to each other. \n",
        "\n",
        "One important thing to note as well is that the cross entropy is not a bounded loss. Which means that a single very wrong prediction can potentially make your loss \"blow up\". In that sense it is possible that there are one or a few outliers that are classified extremely badly and that are making the loss explode, but at the same time your model is still learning on the rest of the dataset or simply the model is overfitting."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uuUbRZnaqcaa"
      },
      "source": [
        "###Model 5:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fPVITV0aXW-U"
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "maxint = 2**11 - 49\n",
        "\n",
        "a = np.random.randint(1, maxint, 1400).reshape(-1,1)\n",
        "n = np.random.randint(1, maxint, 1400).reshape(-1,1)\n",
        "\n",
        "a_test = np.random.randint(1, maxint, 600).reshape(-1,1)\n",
        "n_test = np.random.randint(1, maxint, 600).reshape(-1,1)"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZUpZOhuDZ5kz"
      },
      "source": [
        "y = a%500\n",
        "y_test = a_test%500"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K1RIwTlhdu_O",
        "outputId": "ed85511d-c487-47d7-b643-f37360fb9e21"
      },
      "source": [
        "y.shape, y_test.shape"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((1400, 1), (600, 1))"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y_6Va623aEIk"
      },
      "source": [
        "def num2bin(num): \n",
        "  return [int(c) for c in '{:08b}'.format(num)]\n",
        "\n",
        "def bin2num(b):\n",
        "  return int(''.join([str(n) for n in b]),2)\n",
        "\n",
        "def list2bin(numlist):\n",
        "  return np.array([num2bin(num[0]) for num in numlist])\n",
        "\n",
        "def list2num(binlist):\n",
        "  return [bin2num(b) for b in binlist]\n",
        "\n",
        "a = list2bin(a)\n",
        "n = num2bin(500)\n",
        "\n",
        "a_test = list2bin(a_test)\n",
        "\n",
        "y = list2bin(y)\n",
        "y_test = list2bin(y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4SXa5nvnntcj"
      },
      "source": [
        "y_test.shape,y.shape, a.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TIHUkccWeo4H"
      },
      "source": [
        "X_train = a[:1100]\n",
        "X_val = a[1100:]\n",
        "y_train = y[:1100]\n",
        "y_val = y[1100:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-CaDHjcNfm1P"
      },
      "source": [
        "X_val.shape, X_train.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8zhIp3m3erUn"
      },
      "source": [
        "model = MLPClassifier()\n",
        "model.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "50QNbcO2evKj"
      },
      "source": [
        "y_val_pred = list2num(model.predict(X_val))\n",
        "y_val_true = list2num(y_val)\n",
        "y_val_pred[:16], y_val_true[:16]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rXNs4Y4KgC5P"
      },
      "source": [
        "r2_score(y_val_true, y_val_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uVkYeSrHgOV3"
      },
      "source": [
        "y_test_pred = list2num(model.predict(a_test))\n",
        "r2_score(list2num(y_test), y_test_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GKWjEjKD7xXH"
      },
      "source": [
        "### Model 6:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qr-RX47vx02b"
      },
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "ohe = OneHotEncoder()\n",
        "df_ohe_input = ohe.fit_transform(df_inputs.reshape(-1,1))\n",
        "df_labels = modular_fn(df_inputs.reshape(-1,1))\n",
        "\n",
        "df_ohe_labels = ohe.fit_transform(df_labels.reshape(-1,1))\n",
        "print(df_ohe_input.shape, df_ohe_labels.shape)\n",
        "\n",
        "#creating train and test dataset\n",
        "train_data_size = int(2000*0.7) # 70% is for training \n",
        "\n",
        "# training data\n",
        "train_inputs = df_ohe_input[:train_data_size]\n",
        "train_labels = df_ohe_labels[:train_data_size]\n",
        "\n",
        "# validation data\n",
        "valid_data_size = int(train_data_size*0.2)\n",
        "valid_inputs = train_inputs[:valid_data_size]\n",
        "valid_labels = train_labels[:valid_data_size]\n",
        "\n",
        "train_inputs = train_inputs[valid_data_size:]\n",
        "train_labels = train_labels[valid_data_size:]\n",
        "\n",
        "# test data\n",
        "test_inputs = df_ohe_input[train_data_size:]\n",
        "test_labels = df_ohe_labels[train_data_size:]\n",
        "\n",
        "print('Train data size {} \\nValidation data size {}\\ntest data size {}'\n",
        "      .format(train_inputs.shape, valid_inputs.shape, test_inputs.shape))\n",
        "\n",
        "model2 = MLPClassifier()\n",
        "model2.fit(train_inputs,\n",
        "           train_labels)\n",
        "\n",
        "y_val_pred = model.predict(valid_inputs)\n",
        "preds = [np.argmax(y_val_pred[i]) for i in range(len(y_val_pred))]\n",
        "true_preds = [np.argmax(valid_labels[i]) for i in range(valid_labels.shape[0])]\n",
        "print(preds[:10], true_preds[:10])\n",
        "\n",
        "r2_score(true_preds, preds)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}